[toc]



好的，我将**详细**解释您提供的《Compiling with Continuations》第十五章**“性能评估（Performance Evaluation）”**中的内容，特别是**14.3 Translation for the MIPS and SPARC**部分及其相关子节。这将包括对基准程序的描述、性能指标的解释以及这些指标对编译器优化的意义。以下是对这些内容的逐步详解，旨在帮助您全面理解性能评估的方法和结果。

---

## **第十五章 性能评估（Performance Evaluation）**

### **概述**

**性能评估**旨在确定编译器中各种优化和表示方法的实际效果。通过对真实程序进行测量，评估哪些优化对程序的运行速度和代码大小有显著影响。本章介绍了性能评估的方法、基准程序的选择以及评估结果的分析。

### **15.1 硬件（Hardware）**

尽管用户在本次请求中没有提供具体的内容，通常这一节会介绍用于性能评估的硬件环境，包括处理器型号、内存大小、缓存层次结构等。这些硬件特性会影响程序的执行速度和缓存效果，因此在评估时必须加以考虑。

### **15.2 各种优化的测量（Measurements of Individual Optimizations）**

这一节通常会介绍如何通过禁用特定的优化来评估每个优化对整体性能的贡献。通过逐一禁用优化并测量程序的运行时间、代码大小等指标，可以确定哪些优化最为重要。

### **15.3 参数调整（Tuning the Parameters）**

参数调整涉及编译器中可调节的参数，如寄存器分配策略、指令调度策略等。通过调整这些参数，可以进一步优化程序的性能和资源使用。

### **15.4 更多关于缓存（More about Caches）**

缓存性能对程序的运行速度有重大影响。这一节可能会深入探讨缓存命中率、缓存层次结构对性能的影响以及如何优化程序以提高缓存利用率。

### **15.5 编译时间（Compile Time）**

编译时间是评估编译器效率的重要指标之一。虽然本章主要关注生成代码的性能，但编译时间的长短也影响开发者的体验。

### **15.6 与其他编译器的比较（Comparison with Other Compilers）**

这一节可能会将本书中描述的编译器与其他现有编译器进行比较，评估其在性能、代码大小、编译速度等方面的优劣。

### **15.7 结论（Conclusions）**

总结整个性能评估的发现，指出哪些优化最为重要，哪些还有待改进，并可能提出未来的研究方向。

---

## **基准程序简介（Benchmark Programs Overview）**

为了评估编译器优化的有效性，选择了六个真实的基准程序。每个基准程序都有特定的用途和特性，能够代表不同类型的计算任务。以下是对这些基准程序的详细介绍：

### **基准程序描述（Figure 15.1）**

| **Key** | **Name**    | **Description**                                              |
| ------- | ----------- | ------------------------------------------------------------ |
| **l**   | **Life**    | **生命游戏**（Life），由 Chris Reade 编写，并在其书中描述，运行 50 代的滑翔机发射器（glider gun）。 |
| **x**   | **Lex**     | **词法分析器生成器**（Lexical Analyzer Generator），由 James S. Mattson 和 David R. Tarditi 实现，用于处理 Standard ML 的词法描述。 |
| **y**   | **Yacc**    | **LALR(1) 解析器生成器**（LALR(1) Parser Generator），由 David R. Tarditi 实现，用于处理 Standard ML 的语法。 |
| **k**   | **Knuth–B** | **Knuth–Bendix 完成算法**的实现，由 Gerard Huet 实现，用于处理几何学的一些公理。 |
| **s**   | **Simple**  | 一个 **球面流体动力学程序**（spherical fluid-dynamics program），作为一个“现实”的 FORTRAN 基准程序开发，随后被翻译成 ID 和 Standard ML。 |
| **v**   | **VLIW**    | **超长指令字**（Very-Long-Instruction-Word）指令调度器，由 John Danskin 编写。 |

### **基准程序统计数据（Figure 15.2）**

| **Key** | **Program** | **Source Lines** | **Compile Time** | **Code Size** | **Data Size** | **Non-GC Time** | **GC Time** | **System Time** |
| ------- | ----------- | ---------------- | ---------------- | ------------- | ------------- | --------------- | ----------- | --------------- |
| **l**   | **Life**    | 117              | 11.6s            | 16k           | 489k          | 21.1s           | 0.8s        | 0.38s           |
| **x**   | **Lex**     | 1223             | 71.5             | 84k           | 1033k         | 15.6            | 1.74        | 0.21            |
| **y**   | **Yacc**    | 5785             | 593.0            | 269k          | 1276k         | 4.41            | 2.04        | 0.47            |
| **k**   | **Knuth–B** | 439              | 29.1             | 35k           | 1619k         | 11.2            | 1.15        | 0.15            |
| **s**   | **Simple**  | 1002             | 87.1             | 75k           | 5391k         | 35.2            | 3.42        | 0.11            |
| **v**   | **VLIW**    | 3216             | 624.0            | 315k          | 3598k         | 28.2            | 2.19        | 0.28            |

#### **指标解释**

1. **Source Lines（源代码行数）**：
   - **定义**：程序源代码中非空行和非注释行的数量。
   - **意义**：反映程序的规模和复杂性。较多的源代码行数可能意味着更复杂的逻辑和更多的优化潜力。

2. **Compile Time（编译时间）**：
   - **定义**：编译程序所需的实际时间。
   - **意义**：评估编译器的效率。较长的编译时间可能影响开发周期，但通常与代码优化程度成正比。

3. **Code Size（代码大小）**：
   - **定义**：编译后生成的程序代码的字节数。
   - **意义**：较小的代码大小有助于减少存储需求和提高缓存命中率，从而提升运行速度。

4. **Data Size（数据大小）**：
   - **定义**：垃圾收集器观察到的程序运行期间的最大堆内存使用量（以千字节为单位）。
   - **意义**：反映程序的内存需求。较大的数据大小可能导致更多的垃圾收集次数，影响程序的运行速度。

5. **Non-GC Time（非垃圾收集时间）**：
   - **定义**：执行程序时，除垃圾收集和操作系统时间外所花费的 CPU 时间。
   - **意义**：主要反映程序的计算效率。较高的非 GC 时间表明程序在执行计算任务方面表现良好。

6. **GC Time（垃圾收集时间）**：
   - **定义**：执行垃圾收集所花费的 CPU 时间。
   - **意义**：反映垃圾收集的开销。较高的 GC 时间可能表示程序频繁进行垃圾收集，影响整体性能。

7. **System Time（系统时间）**：
   - **定义**：程序执行过程中由操作系统占用的时间。
   - **意义**：包括文件 I/O、系统调用等操作系统相关的开销。较高的系统时间可能表明程序依赖于大量的系统资源。

### **缓存效果（Figure 15.3）**

| **Key** | **Program**      | **Data size** | **Heap size** | **Effectiveness** |
| ------- | ---------------- | ------------- | ------------- | ----------------- |
| **l**   | **Life**         | 0.48 MB       | 2 MB          | 0.30              |
| **x**   | **Lex**          | 1.01 MB       | 3 MB          | 0.29              |
| **y**   | **Yacc**         | 1.25 MB       | 4 MB          | 0.62              |
| **k**   | **Knuth–Bendix** | 1.58 MB       | 8 MB          | 0.69              |
| **s**   | **Simple**       | 5.26 MB       | 16 MB         | 0.72              |
| **v**   | **VLIW**         | 3.51 MB       | 20 MB         | 0.42              |

#### **指标解释**

1. **Data Size（数据大小）**：
   - **定义**：程序在运行期间使用的内存数据量。
   - **意义**：反映程序的内存需求，影响缓存命中率和缓存性能。

2. **Heap Size（堆大小）**：
   - **定义**：程序运行期间堆内存的最大使用量。
   - **意义**：堆内存的大小影响垃圾收集的频率和开销。

3. **Effectiveness（缓存效果）**：
   - **定义**：每秒执行的指令数除以处理器的时钟频率。
   - **计算公式**：$$ \text{Cache Effectiveness} = \frac{\text{Instructions Executed per Second}}{\text{Clock Rate of the Machine}} $$
   - **意义**：反映了程序对缓存的利用效率。较高的缓存效果表明程序能够更有效地利用缓存，减少缓存未命中的次数，从而提升执行速度。

   **注意**：这个定义适用于 MIPS 架构，因为其流水线停顿主要由内存层次结构引起。对于其他机器，可能需要更复杂的定义。

---

## **14.3 MIPS 和 SPARC 机器的翻译（Translation for the MIPS and SPARC）**

### **寄存器结构与分配**

#### **MIPS 处理器的寄存器结构**

- **总寄存器数**：32 个。
- **特殊用途寄存器**：
  - **寄存器 `$0`**：始终保持值为零。
  - **寄存器 `$1`**：用于“分支与链接”（branch-and-link）指令的目标寄存器。
  - **寄存器 `$2` 和 `$3`**：由操作系统保留。
  - **寄存器 `$29`**：堆栈指针（Stack Pointer），用于信号处理。
  - **寄存器 `$28`**：全局指针（Global Pointer），用于 C 语言运行时系统。
  - **寄存器 `$26` 和 `$27`**：汇编器临时寄存器，用于构建某些惯用的指令组合。
  
#### **SPARC 处理器的寄存器结构**

- **寄存器窗口（Register Windows）**：
  - **每个窗口包含**：
    - **8 个输入寄存器**：用于接收过程的参数。
    - **8 个本地寄存器**：用于过程内部的局部变量。
    - **8 个输出寄存器**：用于传递参数给其他过程。
- **全局寄存器**：8 个全局寄存器。
- **窗口切换**：在过程调用时，输出寄存器成为新过程的输入寄存器，旧窗口的输入和本地寄存器保持不变，直到窗口切换回来。

#### **寄存器分配策略**

由于 SPARC 的寄存器窗口与编译器的模型不完全契合，编译器采取以下策略：

1. **不使用寄存器窗口**：
   - **方法**：将寄存器窗口视为 32 个通用寄存器，类似于 MIPS。
   - **保留寄存器**：
     - **不使用**：堆栈指针（`o6`）、帧指针（`i6`）、返回地址寄存器（`i7` 和 `o7`）。
     - **使用**：一个寄存器用于 PC-relative 寻址。

2. **寄存器用途分配**：
   - **保留寄存器**：`dataptr`、`datalimit`、`storeptr`、`exnptr`、`arithtemp` 以及其他临时寄存器，使用数据寄存器（如 D0–D7）。
   - **通用寄存器**：剩余的 16-18 个寄存器用于存储 CPS 变量。

### **14.3.1 PC-relative 寻址（PC-relative Addressing）**

#### **定义与重要性**

**PC-relative 寻址**是一种寻址模式，其中操作数的地址是相对于当前程序计数器（PC）的偏移量。这对于实现**位置无关代码（PIC）**至关重要，因为它允许代码在内存中的任意位置加载和执行，而无需依赖固定的绝对地址。

#### **实现方法**

1. **构造地址标签**：
   - 例如，假设需要构造一个闭包的记录，其中包含一个指向函数 `Label328` 的地址和一个自由变量在寄存器 13 中的值。
   - 抽象机器指令：
     ```sml
     record( [ (Label328, OFFp 0), (R13, OFFp 0) ], R4 )
     ```

2. **PC-relative 地址的计算**：
   - 由于整个编译单元的代码块可能被垃圾收集器移动，必须在程序中编码偏移量，而不是绝对地址。
   - 这种偏移量是引用指令地址与目标标签地址之间的差值。

3. **MIPS 和 SPARC 的 PC-relative 指令**：
   - **MIPS**：
     ```assembly
     beq $t0, $t1, L1_offset
     ```
     其中 `L1_offset` 是 `L1` 标签相对于当前 PC 的偏移量。
   - **SPARC**：
     ```assembly
     be L1_offset
     ```
     其中 `L1_offset` 是 `L1` 标签相对于当前 PC 的偏移量。

4. **编译器的角色**：
   - 计算目标标签与当前 PC 的偏移量，并将其嵌入跳转指令中。
   - 如果同一个函数中需要多个 PC-relative 地址，只需生成一个分支与链接指令（branch-and-link），并通过调整加法常数来构造多个偏移量。

#### **优势**

- **代码移动性**：支持代码在内存中的任意位置加载和执行，无需修改指令中的地址引用。
- **简化垃圾回收**：由于代码段可移动，垃圾回收器无需担心指令中的绝对地址引用。

#### **示例**

假设有一个跳转指令需要跳转到标签 `L1`：

- **MIPS**：
  ```assembly
  beq $t0, $t1, L1_offset
  ```
  其中 `L1_offset` 是 `L1` 标签相对于当前 PC 的偏移量。

- **SPARC**：
  ```assembly
  be L1_offset
  ```
  其中 `L1_offset` 是 `L1` 标签相对于当前 PC 的偏移量。

### **14.3.2 指令调度（Instruction Scheduling）**

#### **定义与重要性**

**指令调度（Instruction Scheduling）**是编译器优化的一个关键步骤，旨在重新排列指令的执行顺序，以充分利用处理器的指令流水线和并行执行能力，减少流水线停顿和提高执行效率。对于 MIPS 和 SPARC 这样的 RISC 架构，指令调度尤为重要，因为它们依赖于高效的流水线执行来实现高性能。

#### **实现方法**

1. **静态指令调度**
   - **方法**：在编译阶段，根据指令间的依赖关系和处理器的流水线特性，重新排列指令顺序。
   - **目标**：减少数据相关性引起的流水线停顿，提高指令级并行性。

2. **动态指令调度**
   - **方法**：利用处理器内部的硬件机制，在运行时动态优化指令的执行顺序。
   - **应用**：虽然静态调度在编译阶段已做优化，但动态调度可以进一步提升性能。

3. **调度策略**
   - **延迟槽填充（Delay Slot Filling）**：
     - **MIPS**：许多 MIPS 指令（如跳转指令）后有一个延迟槽（delay slot），编译器可以填充不依赖于前一指令结果的指令，以减少流水线停顿。
     - **SPARC**：类似地，SPARC 的分支指令也有延迟槽，编译器可以利用这一特性优化指令序列。
   - **循环展开（Loop Unrolling）**：
     - **方法**：将循环体内的指令重复多次，减少循环控制指令的数量，提高指令级并行性。
   - **指令重排（Instruction Reordering）**：
     - **方法**：根据指令间的依赖关系和处理器的执行单元，重新排列指令顺序，以充分利用处理器的并行执行能力。

#### **优化效果**

通过有效的指令调度，可以显著提高程序的执行效率，具体表现为：

- **减少流水线停顿**：通过填充延迟槽和重排指令顺序，减少指令之间的数据相关性引起的流水线停顿。
- **提高指令级并行性**：充分利用处理器的多个执行单元，同时执行多条指令，提升整体执行效率。
- **优化缓存命中率**：通过优化指令顺序，提高指令和数据的局部性，提升缓存命中率，减少内存访问延迟。

#### **示例**

考虑以下指令序列：

```assembly
add r7, r2, r4
load r3, M[r1+8]
add r7, r7, r3
load r8, M[r1+4]
```

**问题**：`r3` 是 `load` 指令的目标，`add r7, r7, r3` 需要使用 `r3` 的值，导致数据依赖，可能引发流水线停顿。

**优化**：通过重排指令顺序，插入无关指令，减少停顿。例如：

```assembly
add r7, r2, r4
load r8, M[r1+4]
add r7, r7, r3
load r3, M[r1+8]
```

这样，`load r8, M[r1+4]` 与 `add r7, r7, r3` 之间没有数据依赖，可以并行执行，减少流水线停顿。

#### **总结**

指令调度是提升 MIPS 和 SPARC 架构程序执行效率的关键优化策略。通过合理的静态指令调度和利用处理器的流水线特性，可以显著减少指令执行时间，提高程序的整体性能。

### **14.3.3 反别名（Anti-aliasing）**

#### **定义与重要性**

**反别名（Anti-aliasing）**在编译器优化中指的是防止不同变量或指针引用同一内存位置，避免由于别名导致的优化限制。有效的反别名技术可以提高寄存器分配和指令调度的效率，减少不必要的内存访问和数据冲突。

#### **实现方法**

1. **别名分析（Alias Analysis）**
   - **目标**：确定不同指针是否可能引用同一内存位置。
   - **方法**：
     - **静态分析**：在编译阶段，通过分析程序代码，推断指针的可能引用范围。
     - **动态分析**：在运行时，通过监控指针的实际引用，确定别名关系。

2. **反别名策略**
   - **避免共享寄存器**：确保不同变量或指针使用不同的寄存器，防止因寄存器共享导致的数据冲突。
   - **寄存器分配优化**：基于别名分析结果，优化寄存器分配策略，减少寄存器溢出和内存访问次数。

3. **优化策略**
   - **逃逸分析（Escape Analysis）**：分析指针是否会逃逸出当前作用域，确定其是否可能与其他指针别名。
   - **内存分配优化**：通过避免别名关系，优化内存分配策略，提高内存访问效率。

#### **具体应用**

在续延机器的指令翻译过程中，反别名技术主要应用于以下几个方面：

1. **寄存器分配**
   - **方法**：根据别名分析结果，避免将别名关系中的变量分配到同一个寄存器。
   - **效果**：减少数据冲突和寄存器溢出，提高寄存器利用率和程序执行效率。

2. **指令调度**
   - **方法**：通过识别可能的别名关系，优化指令执行顺序，避免因别名导致的流水线停顿。
   - **效果**：提高指令流水线的并行度和执行效率，减少流水线冲突。

#### **示例**

考虑以下代码片段：

```c
int *p = &x;
int *q = &y;
*p = *q + 1;
```

- **别名分析**：`p` 和 `q` 指向不同的内存位置（`x` 和 `y`），因此可以安全地将 `*p` 和 `*q` 分配到不同的寄存器。
- **寄存器分配优化**：将 `*p` 分配到寄存器 `R1`，`*q` 分配到寄存器 `R2`，避免数据冲突。

#### **总结**

反别名技术在机器代码生成过程中起到了关键作用，通过有效的别名分析和策略，优化了寄存器分配和指令调度，提升了程序的执行效率和性能。特别是在处理复杂的指针关系和数据依赖时，反别名技术能够显著减少优化的限制，充分发挥处理器的并行执行能力。

### **14.3.4 交替临时寄存器（Alternating Temporaries）**

#### **定义与重要性**

**交替临时寄存器（Alternating Temporaries）**是一种寄存器管理策略，旨在优化临时变量的使用，减少寄存器的溢出和重用冲突。通过交替使用临时寄存器，可以提高寄存器利用率，减少不必要的内存访问和寄存器移动指令。

#### **实现方法**

1. **临时寄存器池（Temporary Register Pool）**
   - **定义**：预留一组寄存器专门用于存储临时变量。
   - **管理策略**：
     - **轮流使用**：交替使用临时寄存器，确保每个临时变量都有独立的寄存器空间。
     - **寄存器重用**：在临时变量不再需要时，将寄存器重新分配给新的临时变量，最大限度地利用寄存器资源。

2. **寄存器分配规则**
   - **避免冲突**：确保同时存在的临时变量使用不同的寄存器，避免数据冲突。
   - **高效利用**：通过交替使用临时寄存器，减少寄存器的空闲时间，提高寄存器利用率。

3. **优化策略**
   - **指令重排**：根据临时寄存器的使用情况，重新排列指令顺序，减少寄存器移动指令。
   - **延迟寄存器分配**：尽量延迟临时寄存器的分配，直到临时变量真正需要使用时，再分配寄存器，减少寄存器的占用时间。

#### **具体应用**

在 MIPS 和 SPARC 机器的指令翻译过程中，交替临时寄存器策略主要应用于以下几个方面：

1. **临时变量管理**
   - **方法**：在生成指令时，临时变量的使用依次分配给临时寄存器池中的不同寄存器。
   - **效果**：减少寄存器溢出和临时变量的冲突，提高指令执行效率。

2. **指令优化**
   - **方法**：通过优化临时寄存器的使用顺序，减少不必要的寄存器移动和加载/存储操作。
   - **效果**：提高指令流水线的效率，减少指令数量和执行时间。

#### **示例**

考虑以下代码片段：

```c
int a = b + c;
int d = a * e;
int f = d - g;
```

- **寄存器分配**：
  - `a` 分配给临时寄存器 `R1`
  - `d` 分配给临时寄存器 `R2`
  - `f` 分配给临时寄存器 `R1`（交替使用，`R1` 在 `a` 已经被使用完毕后可以重用）

- **指令生成**：
  ```assembly
  ADD R1, R2, R1   ; a = b + c
  MULT R1, R3, R2  ; d = a * e
  SUB R1, R4, R1   ; f = d - g
  ```

**优化效果**：
- 通过交替使用 `R1` 和 `R2`，减少了对单个临时寄存器的依赖，避免了数据冲突和流水线停顿。
- 提高了寄存器利用率，减少了寄存器溢出的可能性。

#### **总结**

交替临时寄存器策略通过优化临时变量的使用和寄存器分配，提升了寄存器利用率，减少了寄存器溢出和移动指令的需求。在 MIPS 和 SPARC 等 RISC 架构的机器代码生成过程中，交替临时寄存器策略能够显著提高指令执行效率和程序性能。

---

## **14.4 一个示例（An Example）**

### **示例概述**

为了更好地理解机器代码生成的过程，本节通过一个具体的示例，展示如何将一个简单的 CPS（Continuation-Passing Style）表达式翻译为目标机器的汇编代码。该示例使用 **Standard ML of New Jersey** 编译器，将一个计算列表中零元素数量的程序进行编译和优化。

### **示例 CPS 表达式**

```sml
FIX([(f, [x, k], APP(VAR g, x))], APP(VAR f, a))
```

**解释**：
- `FIX`：定义一个固定点（固定点函数），用于递归函数的定义。
- `[(f, [x, k], APP(VAR g, x))]`：定义了一个函数 `f`，接收参数 `x` 和续延 `k`，在函数体中调用 `g(x)`。
- `APP(VAR f, a)`：调用函数 `f`，传递实际参数 `a`。

### **翻译步骤**

1. **初始化寄存器分配表**
   - **逃逸函数 `f`** 的形式参数 `x` 和 `k` 分配到寄存器 `R1` 和 `R2`。
   - **函数 `g`** 的寄存器分配将在第一次调用时确定。

2. **生成函数 `f` 的汇编代码**

   ```assembly
   LABEL f:
       MOVE R1, x        ; 将参数 x 移动到寄存器 R1
       CALL g, R1, R2    ; 调用函数 g，传递 R1 作为参数，R2 作为续延
       RET                ; 返回续延
   ```

   **解释**：
   - **`MOVE R1, x`**：将函数 `f` 的参数 `x` 移动到寄存器 `R1`。
   - **`CALL g, R1, R2`**：调用函数 `g`，传递寄存器 `R1` 中的 `x` 作为参数，寄存器 `R2` 中的 `k` 作为续延。
   - **`RET`**：函数 `f` 执行完毕，返回到续延 `k`。

3. **生成启动代码（START）**

   ```assembly
   START:
       MOVE R0, a        ; 将实际参数 a 移动到寄存器 R0
       CALL f, R0, CONT  ; 调用函数 f，传递 R0 作为参数，CONT 作为续延
       HALT               ; 程序结束
   ```

   **解释**：
   - **`MOVE R0, a`**：将实际参数 `a` 移动到寄存器 `R0`。
   - **`CALL f, R0, CONT`**：调用函数 `f`，传递寄存器 `R0` 中的 `a` 作为参数，寄存器 `R3`（假设）中的 `CONT` 作为续延。
   - **`HALT`**：程序执行结束。

4. **生成续延 `CONT` 的汇编代码**

   ```assembly
   LABEL CONT:
       ; 续延 CONT 的指令
   ```

   **解释**：
   - 续延 `CONT` 的具体实现依赖于后续的程序逻辑，此处作为占位符。

### **寄存器分配与优化**

在此示例中，寄存器分配的策略如下：

- **逃逸函数 `f`** 的参数 `x` 和 `k` 分别分配到 `R1` 和 `R2`，确保函数调用时参数传递的高效性。
- **函数 `g`** 的参数 `x` 在 `f` 中已经被分配到 `R1`，因此在调用 `g` 时，`R1` 可以直接用于传递参数，减少了寄存器移动指令。

### **生成指令的优化**

1. **减少寄存器移动**：
   - 通过提前分配寄存器，减少了指令中的寄存器移动操作。例如，`R1` 已经用于存储 `x`，无需额外移动指令来传递给 `g`。

2. **利用延迟槽**：
   - 如果目标机器支持延迟槽（如 MIPS 和 SPARC），编译器可以在延迟槽中插入无关指令，提高指令流水线的执行效率。

3. **指令重排**：
   - 根据指令间的依赖关系，优化指令顺序，减少流水线停顿。例如，在调用 `g` 之前，可以插入一些计算或非相关的指令，以填充延迟槽。

### **寄存器分配与优化策略的实际应用**

在更复杂的程序中，寄存器分配和优化策略会更加复杂。例如：

- **反别名技术**：确保不同变量或指针不会共享同一个寄存器，避免数据冲突。
- **交替临时寄存器**：优化临时变量的使用，减少寄存器溢出和移动指令的需求。
- **指令调度**：重新排列指令顺序，填充延迟槽，减少流水线停顿，提高指令级并行性。

### **总结**

通过这个简单的示例，我们展示了从 CPS 表达式到目标机器汇编代码的翻译过程。关键步骤包括寄存器分配、指令映射和指令优化。通过合理的寄存器分配和优化策略，可以生成高效的机器代码，确保程序的高性能执行。

---

## **结论**

通过对**第十五章 性能评估（Performance Evaluation）**中的**14.3 Translation for the MIPS and SPARC**部分的详细解释，您可以深入理解以下关键要点：

1. **寄存器管理与分配**：
   - **MIPS**：拥有更多的通用寄存器，编译器可以通过保留部分寄存器用于特定用途，优化寄存器的使用，提高代码执行效率。
   - **SPARC**：尽管具有寄存器窗口，但通过将寄存器窗口视为通用寄存器，并保留部分寄存器用于内存管理和异常处理，编译器能够有效利用剩余寄存器。

2. **指令映射与优化**：
   - **简单指令的直接映射**：许多抽象机器的简单指令可以直接映射到 MIPS 和 SPARC 的等效指令，保持语义一致性。
   - **复杂指令的特定处理**：如记录创建指令需要分解为多个具体的 `mov` 指令，并利用机器特性的优化策略（如相邻字段移动）来提升性能。

3. **跨度依赖指令的处理**：
   - 通过迭代收敛法解决跨度依赖指令的大小与标签地址的相互依赖问题，确保生成的机器代码能够正确执行。

4. **浮点数处理**：
   - **MIPS** 和 **SPARC** 通常拥有专用的浮点寄存器，但编译器需要有效管理这些寄存器，以减少浮点运算的性能瓶颈。

5. **堆限制检查与内存管理**：
   - **MIPS** 和 **SPARC** 通过比较指令和条件跳转指令实现堆限制检查，确保内存分配的安全性和效率。

6. **缓存效果评估**：
   - **Cache Effectiveness** 指标反映了程序对缓存的利用效率，较高的缓存效果意味着更高的指令执行速度和更少的缓存未命中。

7. **性能指标的分析**：
   - **Non-GC Time** 与 **GC Time** 的比例反映了程序计算效率与垃圾收集开销的平衡。
   - **Code Size** 和 **Data Size** 影响程序的内存使用和缓存性能。

### **关键要点回顾**

1. **寄存器映射**：
   - 根据不同目标机器的寄存器结构和功能差异，合理分配寄存器资源，确保关键寄存器用于内存管理和异常处理，通用寄存器用于存储 CPS 变量和传递参数。

2. **指令调度**：
   - 通过优化指令执行顺序，充分利用处理器的流水线和并行执行能力，减少指令执行时间，提高程序整体性能。

3. **反别名技术**：
   - 防止不同变量或指针引用同一内存位置，优化寄存器分配和指令调度，提升程序性能。

4. **交替临时寄存器策略**：
   - 优化临时变量的使用，减少寄存器溢出和移动指令的需求，提高寄存器利用率。

5. **整数与浮点数运算优化**：
   - 通过合理的寄存器分配和指令生成策略，实现高效的算术运算和内存管理，确保类型安全和执行效率。

通过掌握这些内容，您可以更好地理解如何将高层次的 CPS 表达式高效地转换为目标机器的机器代码，实现高性能的程序执行和内存管理。如果您对**第十五章 性能评估（Performance Evaluation）**中的其他部分有进一步的问题或需要更深入的解释，请随时提问！

### ---------------------------

好的，我将**详细**解释您提供的《Compiling with Continuations》第十五章**“性能评估（Performance Evaluation）”**中的**15.1 硬件（Hardware）**以及**15.2 各种优化的测量（Measurements of Individual Optimizations）**部分。以下是对这些内容的逐步详解，旨在帮助您深入理解性能评估的方法、使用的基准程序、测量指标及其对编译器优化的影响。

---

## **第十五章 性能评估（Performance Evaluation）**

### **15.1 硬件（Hardware）**

#### **硬件环境**

所有基准测试程序都在一台 **MIPS Magnum 3000 工作站** 上运行，该工作站配备了 **128 兆字节的内存**。然而，为了模拟一个“现实”的运行环境，在实际运行测试程序时使用的内存量要少得多；**图15.3** 展示了每个程序所使用的堆大小。

**具体配置如下：**

- **处理器**：MIPS Magnum 3000 工作站
- **内存**：128 MB（但实际测试中使用较少）
- **指令缓存（I-cache）**：32 KB，直接映射
- **数据缓存（D-cache）**：32 KB，直接映射，采用写直达（write-through）策略，配有 **8 深的写缓冲区**，并具备良好的 DRAM 页面模式智能，以便大部分时间以 1 个字/2 个周期的速度写入。
- **缓存行大小**：8 个字（32 字节）
- **虚拟内存管理**：
  - **TLB（Translation Lookaside Buffer）**：存储 56 个用户页面和 8 个内核页面的虚拟内存翻译。
  
#### **MIPS 架构特性**

- **RISC 架构**：MIPS 是一种精简指令集计算机（RISC），其设计目标是每个指令在一个时钟周期内执行完毕。
- **流水线执行**：理论上可以实现每个周期执行一条指令，减少了指令执行的延迟。
- **寄存器数量**：32 个通用寄存器，寄存器 `$0` 始终为零，寄存器 `$1` 用于“分支与链接”（branch-and-link）指令的目标寄存器，寄存器 `$2` 和 `$3` 由操作系统保留，寄存器 `$29` 作为堆栈指针（Stack Pointer），寄存器 `$28` 作为全局指针（Global Pointer），寄存器 `$26` 和 `$27` 作为汇编器临时寄存器。

#### **性能表现**

尽管 MIPS 通常设计为每周期执行一条指令，但在我们的 25 MHz 工作站上，实际观察到的执行速度仅为 **7000 万至 1000 万条指令每秒**，**图15.3** 展示了这些基准程序的缓存效果和指令执行情况。

**性能波动原因分析**：

在实际测试中，重新编译并重新运行相同程序的执行时间常常会有 **5-20%** 的变化（见 **图15.13**）。可能的原因包括：

1. **指令缓存未命中（I-cache miss）**：
   - 当程序尝试获取不在指令缓存中的指令时，会导致数个周期的延迟。
   
2. **数据缓存未命中（D-cache miss）**：
   - 当程序尝试访问不在数据缓存中的数据时，也会导致数个周期的延迟。
   
3. **写缓冲区填满**：
   - 连续的存储操作可能会填满写缓冲区，导致处理器停顿。
   
4. **TLB 未命中（TLB miss）**：
   - 当访问的虚拟页面不在 TLB 中时，会触发一个 10 条指令的陷阱处理程序来重新加载页面。
   
5. **页面错误（Page fault）**：
   - 当访问的虚拟页面不在物理内存中时，会发生页面错误。
   
6. **长延迟指令的使用**：
   - 整数乘法或除法，或者浮点运算，如果结果被过早使用，可能会导致流水线停顿。

**主要结论**：

由于所有基准测试程序在运行时都有充足的物理内存，因此 **页面错误** 可能性较小。此外，除 **Simple** 程序外，其他程序很少进行乘法、除法或浮点运算，因此主要问题可能在于 **内存子系统**，包括指令缓存、数据缓存、写缓冲区和 TLB。

**直接映射缓存的问题**：

直接映射缓存特别容易受到“干扰”问题的影响，即两个频繁访问的地址映射到同一缓存行，导致彼此相互挤出缓存。这可能解释了重新编译后的程序执行时间变化，因为编译器可能会选择不同的代码地址，相对数据的位置变化导致缓存冲突。

#### **为何选择指令计数而非执行时间**

由于缓存命中率的波动，即使是类似的程序也会有较大的执行时间变化，因此为了更准确地比较不同优化的效果，我们选择使用 **指令计数** 作为主要的性能指标，原因如下：

1. **减少缓存命中率的波动影响**：
   - 使用指令计数避免了因缓存命中率不同导致的性能波动，使得优化效果的比较更加公平和准确。
   
2. **跨机器的一致性**：
   - 不同计算机可能有不同大小的缓存或不同的缓存架构（如组相联缓存），使用指令计数使得结果更具普遍性和可比性。

**指令计数的测量方法**：

我们通过以下方法测量指令计数：

- **寄存器分配**：将一个寄存器专门用于存储指令计数。
- **分支指令的计数**：在每个分支指令的延迟槽中，将寄存器中的计数器按指令数增加，包括所有的 NOP 指令和指令计数增加本身。
- **最小化计数指令的影响**：指令计数增加指令的开销非常小，几乎可以忽略不计，并且不影响内存引用模式。

### **15.2 各种优化的测量（Measurements of Individual Optimizations）**

#### **基准测试程序（Figure 15.1）**

| **Key** | **Name**    | **Description**                                              |
| ------- | ----------- | ------------------------------------------------------------ |
| **l**   | **Life**    | 生命游戏，由 Chris Reade 编写，描述于其书中，运行 50 代的滑翔机发射器（glider gun）。 |
| **x**   | **Lex**     | 词法分析器生成器，由 James S. Mattson 和 David R. Tarditi 实现，用于处理 Standard ML 的词法描述。 |
| **y**   | **Yacc**    | LALR(1) 解析器生成器，由 David R. Tarditi 实现，用于处理 Standard ML 的语法。 |
| **k**   | **Knuth–B** | Knuth–Bendix 完成算法的实现，由 Gerard Huet 实现，用于处理几何学的一些公理。 |
| **s**   | **Simple**  | 一个球面流体动力学程序，作为一个“现实”的 FORTRAN 基准程序开发，随后被翻译成 ID 和 Standard ML。 |
| **v**   | **VLIW**    | 超长指令字指令调度器，由 John Danskin 编写。                 |

#### **基准测试统计数据（Figure 15.2）**

| **Key** | **Program** | **Source Lines** | **Compile Time** | **Code Size** | **Data Size** | **Non-GC Time** | **GC Time** | **System Time** |
| ------- | ----------- | ---------------- | ---------------- | ------------- | ------------- | --------------- | ----------- | --------------- |
| **l**   | **Life**    | 117              | 11.6s            | 16k           | 489k          | 21.1s           | 0.8s        | 0.38s           |
| **x**   | **Lex**     | 1223             | 71.5             | 84k           | 1033k         | 15.6            | 1.74        | 0.21            |
| **y**   | **Yacc**    | 5785             | 593.0            | 269k          | 1276k         | 4.41            | 2.04        | 0.47            |
| **k**   | **Knuth–B** | 439              | 29.1             | 35k           | 1619k         | 11.2            | 1.15        | 0.15            |
| **s**   | **Simple**  | 1002             | 87.1             | 75k           | 5391k         | 35.2            | 3.42        | 0.11            |
| **v**   | **VLIW**    | 3216             | 624.0            | 315k          | 3598k         | 28.2            | 2.19        | 0.28            |

**指标解释：**

1. **Source Lines（源代码行数）**：
   - 非空行和非注释行的数量，反映程序规模和复杂性。
   
2. **Compile Time（编译时间）**：
   - 编译程序所需的实际时间。注意：此处的编译时间较高，详见第198页。
   
3. **Code Size（代码大小）**：
   - 编译后生成的程序代码的字节数。
   
4. **Data Size（数据大小）**：
   - 垃圾收集器观察到的程序运行期间的最大堆内存使用量（以千字节为单位），因此是程序同时存活数据量的下限。
   
5. **Non-GC Time（非垃圾收集时间）**：
   - 执行程序时，除垃圾收集和操作系统时间外所花费的 CPU 时间。
   
6. **GC Time（垃圾收集时间）**：
   - 执行垃圾收集所花费的 CPU 时间。
   
7. **System Time（系统时间）**：
   - 程序执行过程中由操作系统占用的时间，包括文件 I/O、系统调用等。
   

**缓存效果（Figure 15.3）**

| **Key** | **Program**      | **Data size** | **Heap size** | **Effectiveness** |
| ------- | ---------------- | ------------- | ------------- | ----------------- |
| **l**   | **Life**         | 0.48 MB       | 2 MB          | 0.30              |
| **x**   | **Lex**          | 1.01 MB       | 3 MB          | 0.29              |
| **y**   | **Yacc**         | 1.25 MB       | 4 MB          | 0.62              |
| **k**   | **Knuth–Bendix** | 1.58 MB       | 8 MB          | 0.69              |
| **s**   | **Simple**       | 5.26 MB       | 16 MB         | 0.72              |
| **v**   | **VLIW**         | 3.51 MB       | 20 MB         | 0.42              |

**指标解释：**

1. **Data Size（数据大小）**：
   - 程序在运行期间使用的内存数据量（以 MB 为单位）。
   
2. **Heap Size（堆大小）**：
   - 程序运行期间堆内存的最大使用量（以 MB 为单位）。
   
3. **Effectiveness（缓存效果）**：
   - 每秒执行的指令数除以机器的时钟频率。
   - **公式**：$$ \text{Cache Effectiveness} = \frac{\text{Instructions Executed per Second}}{\text{Clock Rate of the Machine}} $$
   - 适用于 MIPS 架构，因为其流水线停顿主要由内存层次结构引起。对于其他机器，可能需要更复杂的定义。
   - **高效**：较高的缓存效果表示程序能够更有效地利用缓存，减少缓存未命中次数，从而提升执行速度。

**缓存效果分析：**

- **Life** 和 **Lex** 的缓存效果较低（0.30 和 0.29），表明它们频繁发生缓存未命中，导致执行效率较低。
- **Yacc**、**Knuth–Bendix** 和 **Simple** 的缓存效果较高（0.62、0.69 和 0.72），表明它们能够更有效地利用缓存，执行效率较高。
- **VLIW** 的缓存效果中等（0.42），存在一定的缓存未命中问题。

### **优化效果分析（Figures 15.4 和 15.5）**

#### **关键优化（Figure 15.4）**

**图15.4** 展示了禁用特定优化后，编译程序的运行时间（指令执行数）的变化。图中使用对数刻度，顶部标签表示性能比率，底部标签表示指令数增加的百分比。不同的字母代表不同的基准程序（见图15.1），点号 **•** 表示各个程序增加指令数的几何平均数，方块 **✷** 表示禁用优化对程序大小的影响。

**关键优化如下：**

1. **betacontract**：
   - **定义**：内联扩展仅被调用一次的函数（详见第6章）。
   
2. **deadvars**：
   - **定义**：消除未使用变量的绑定（详见第6章）。
   
3. **selectopt**：
   - **定义**：对已知记录的 SELECT 操作进行常量折叠优化。
   

**结果分析**：

- 这些优化对运行时间和指令数有显著影响，表明它们在编译器优化中极为重要。
- 这些优化的效果可能与将代码翻译为 mini-ML 和续延风格的方法密切相关。Danvy 和 Filinski 最近的研究表明，通过更仔细地将代码转换为 CPS，可以减少“平凡”的 β-缩约红指数（见文献[35]），这可能进一步提升优化效果。

#### **其他优化（Figure 15.5）**

**图15.5** 展示了禁用各种其他优化后，指令执行数的变化。不同的优化按名称列出，图中使用字母代表不同的基准程序，点号 **•** 表示各个程序的平均值，方块 **✷** 表示禁用优化对代码大小的影响。

**关键优化列表**：

1. **eta**：η 规约（详见第6章）。
2. **etasplit**：逆 η 规约（详见第6章）。
3. **uncurry**：将柯里化函数展开为多参数函数（详见第6章）。
4. **dropargs**：消除未使用的函数参数（详见第6章）。
5. **flattenargs**：将 n 元组参数替换为 n 个单独的参数（详见第6章）。
6. **extraflatten**：即使某些调用点需要额外的 SELECT 操作，也将 n 元组参数替换为 n 个单独的参数（详见第6章）。
7. **switchopt**：对选择器参数为整数常量的 SWITCH 操作进行常量折叠优化（详见第7章）。
8. **handlerfold**：消除 sethdlr 范围内的 gethdlr 操作，并消除冗余的 sethdlrs（详见第7章）。
9. **branchfold**：消除分支路径相同的比较操作（α-转换后）。
10. **comparefold**：对条件分支进行常量折叠优化（详见第7章）。
11. **hoistup**：将函数定义提升到与其他 FIX 合并（详见第9章）。
12. **hoistdown**：将函数定义下推到与其他 FIX 合并，并将函数和其他变量绑定推入条件和选择中（详见第9章）。
13. **rangeopt**：通过范围分析消除整数变量的比较操作，但效果不佳。
14. **arithopt**：对整数算术表达式进行常量折叠优化。
15. **cse**：公共子表达式消除（详见第10章）。
16. **csehoist**：对公共子表达式消除进行额外的提升优化（详见第10章）。
17. **betaexpand**：内联扩展被多次调用的函数（详见第7章）。
18. **callee-save**：保存被调用函数使用的寄存器（详见第10章）。
19. **cross-module**：跨模块优化。通常，编译器会将每个模块放在单独的文件中进行编译，但为了基准测试，我们将所有模块放在一个文件中进行编译。
20. **argrep**：在抽象机器代码生成阶段，第一次调用已知函数时，可以专门化参数表示，避免寄存器-寄存器移动（详见第10章）。
21. **load schedule**：针对 MIPS 的最终目标机器代码生成阶段，禁止立即使用 LOAD 指令的结果，可以通过指令调度将其他有用指令填充到延迟槽中（详见第14章）。
22. **branch schedule**：针对大多数 RISC 机器，分支指令后面的一条指令无论分支是否被采取都会执行，编译器可以通过指令调度将有用的指令放入延迟槽中，减少 NOP 指令（详见第14章）。

**结果分析**：

- **部分优化**（如 `rangeopt` 和 `cse`）的效果不佳，甚至可能对指令计数的影响不大或造成负面影响。
- **关键优化**（如 `betacontract`、`deadvars` 和 `selectopt`）在前述分析中已证明其重要性。
- **交替临时寄存器（Alternating Temporaries）** 和 **指令调度** 在优化指令执行顺序和减少流水线停顿方面发挥了重要作用。

#### **组合优化效果（Figure 15.6）**

**图15.6** 展示了禁用所有优化后的效果。理论上，如果所有优化相互独立，其综合效果应为各个优化单独效果的乘积。然而，实际情况中，优化之间可能存在依赖关系或冗余效果。

**结果分析**：

- 实际效果显示，虽然禁用 19 个优化可能带来 8 倍的速度提升，但实际只提供了 4 倍的速度提升。这表明优化之间存在一定的依赖性或冗余，但整体仍然显著提升了性能。
- 这意味着，即使某些优化的单独效果较小，但综合起来仍然能带来显著的性能提升。

### **总结**

通过对**第十五章 性能评估（Performance Evaluation）**中的**15.1 硬件**和**15.2 各种优化的测量**部分的详细解释，您可以深入理解以下关键要点：

1. **硬件环境对性能的影响**：
   - **缓存结构**（指令缓存、数据缓存、写缓冲区）和 **TLB** 的配置显著影响程序的执行效率。
   - **直接映射缓存** 易受“干扰”问题影响，导致缓存未命中频繁，进而影响指令执行速度。
   
2. **基准测试程序的选择与特性**：
   - 选择多样化的基准测试程序（如生命游戏、词法分析器生成器、解析器生成器、几何学算法、流体动力学程序和指令调度器）以全面评估编译器优化的效果。
   
3. **性能指标的测量与分析**：
   - 使用 **指令计数** 作为主要性能指标，避免缓存命中率波动对测量结果的影响。
   - 通过测量 **编译时间**、**代码大小**、**数据大小**、**非 GC 时间**、**GC 时间** 和 **系统时间**，全面评估编译器优化对程序性能的影响。
   - **缓存效果** 作为衡量程序对缓存利用效率的指标，较高的缓存效果意味着更高的执行效率。
   
4. **优化的重要性与效果**：
   - **betacontract**、**deadvars** 和 **selectopt** 是最为关键的优化，对程序的指令计数和运行速度有显著影响。
   - 其他优化（如 **eta**、**uncurry**、**cse** 等）对性能有不同程度的影响，其中部分优化效果不佳，需要进一步改进。
   - **指令调度** 和 **交替临时寄存器** 策略在优化指令执行顺序和提高寄存器利用率方面起到了关键作用。
   
5. **优化之间的依赖性**：
   - 各种优化之间可能存在依赖关系或冗余效果，导致综合优化效果不如单独优化效果的简单乘积。
   - 尽管存在依赖性，但整体优化仍能显著提升程序性能。

通过理解这些关键要点，您可以更好地掌握编译器优化的实际效果及其在不同硬件环境下的表现。这对于设计高效的编译器和优化策略具有重要指导意义。如果您对**第十五章 性能评估（Performance Evaluation）**中的其他部分有进一步的问题或需要更深入的解释，请随时提问！

### ----------------------------

好的，我将**详细**解释您提供的《Compiling with Continuations》第十五章**“性能评估（Performance Evaluation）”**中的**15.4 更多关于缓存（More about Caches）**部分。以下是对该节内容的逐步详解，旨在帮助您深入理解缓存对编译器优化效果的影响，以及相关测量方法和结果分析。

---

## **15.4 更多关于缓存（More about Caches）**

### **概述**

在前面的讨论中，针对各项优化和参数调整的分析主要集中在**指令计数**上，这是因为如**15.1 硬件（Hardware）**部分所述，指令计数受缓存命中率等因素的影响较大。然而，实际用户更关心的是**执行时间**而非指令计数。因此，本节将探讨指令计数与缓存效果之间的关系，以及优化措施如何影响程序的执行时间。

### **指令计数与执行时间的关系**

- **指令计数**：指的是程序在运行过程中执行的总指令数。虽然指令计数是衡量编译器优化效果的一个重要指标，但它并不能完全反映程序的实际执行时间。

- **执行时间**：程序的实际运行时间不仅取决于指令的总数，还受制于指令执行的效率，这包括缓存命中率、流水线停顿、内存访问延迟等因素。

因此，优化编译器时，仅关注指令计数可能忽略了优化措施对缓存效果和实际执行时间的影响。例如，某些优化可能减少指令数，但由于引入了更多的缓存未命中，最终可能导致执行时间没有显著改善，甚至可能变长。

### **缓存效果（Cache Effectiveness）的影响**

**图15.14**展示了各种优化和参数调整对缓存效果的影响。缓存效果的定义是每秒执行的指令数除以机器的时钟频率（适用于 MIPS 架构）。较高的缓存效果意味着程序能够更有效地利用缓存，减少缓存未命中次数，从而提高执行速度。

**关键发现包括：**

1. **加载调度（Load Scheduling）**：
   - **效果**：降低缓存效果约10%。
   - **原因**：加载调度通过重新安排指令顺序，移除了原本对缓存有利的NOP（无操作）指令，这导致缓存未命中率上升。

2. **β-缩约（β-contraction）**：
   - **效果**：平均降低缓存效果约15%。
   - **特殊情况**：在**Simple**程序中，β-缩约实际上显著提高了缓存效果。
   - **原因**：β-缩约优化可能改变了指令的内存访问模式，导致某些程序在优化后缓存利用更高。

### **指令计数与缓存效果的综合影响**

指令计数的变化与缓存效果的变化可以结合起来评估对**执行时间**的总体影响。具体方法是将缓存效果的变化乘以指令计数的变化，得出对执行时间的影响。

**图15.14**显示了这些优化对缓存效果的影响。然而，该图的一个显著特点是缓存效果的变化具有很大的方差，意味着不同程序或相同程序的不同运行可能会因为缓存冲突等原因产生较大的性能波动。这使得从缓存效果的数据中得出普遍性的结论变得困难。

### **优化之间的相互影响**

**图15.6**展示了同时禁用多项优化时的效果。理论上，如果各个优化之间是独立的，那么它们的综合效果应等于各个优化单独效果的乘积。然而，实际结果显示，优化之间存在一定的依赖性或冗余性，导致综合优化效果不如预期。例如，禁用19项优化后，理论上应提供8倍的速度提升，但实际效果仅为4倍。这表明某些优化措施之间可能存在重叠或相互依赖，但整体优化仍然显著提升了性能。

### **参数调整对缓存效果的影响**

**图15.7 至 图15.16**展示了不同参数调整对缓存效果和其他性能指标的影响。

1. **β-缩约/η-规约循环次数（Rounds of β-contraction before η-reduction）**：
   - **图15.7**显示，在进行n轮β-缩约和η-规约之前，执行这些优化的效果。结果表明，对于这些基准程序，进行2轮优化已经足够，进一步增加轮次数对执行时间的影响不大。

2. **寄存器数量限制（Register Limitation）**：
   - **图15.8**展示了在目标机器上人为限制寄存器数量对性能的影响。结果显示，当寄存器数量大于等于9时，性能下降不明显。然而，某些基准程序（如**Life**）在寄存器数量较少时反而表现更好，可能是因为寄存器分配的特殊情况。

3. **内联扩展轮次数（Rounds of in-line expansion）**：
   - **图15.9**展示了增加内联扩展轮次数对指令计数和执行时间的影响。结果表明，多轮内联扩展可以显著减少执行时间，且在大多数情况下，经过6轮扩展后，进一步增加轮次数的效果不大。

4. **内联扩展的乐观程度（Optimism of the in-line expander）**：
   - **图15.10**展示了内联扩展阶段中参数C（表示每次内联扩展可容忍的最大代码增长量）的变化对性能的影响。较大的C值意味着更积极的内联扩展，导致代码大小增加，但也提升了执行速度。

5. **早期放弃优化（Giving up early）**：
   - **图15.11**展示了在β-扩展阶段中，当达到一定的优化步数后放弃进一步优化对性能的影响。结果表明，对于中等规模的基准程序，适当减少优化步数可以减少编译时间，而对执行时间影响不大。

6. **堆大小对缓存效果的影响（Heap Size Effect on Cache Effectiveness）**：
   - **图15.15**展示了堆大小（堆大小与活跃数据量的比率R）对缓存效果的影响。结果表明，当堆大小过大或过小时，缓存效果都会下降。这可能是因为：
     - **堆大小过大**：内存引用分散，导致缓存命中率下降。
     - **堆大小过小**：垃圾收集频繁，与编译代码争夺缓存资源，导致缓存效果下降。

### **堆分配率与垃圾收集开销**

- **图15.16**展示了基准程序的堆分配率和垃圾收集（GC）开销。
  - **堆分配率**：每条指令分配的堆字（四字节）的比例。结果显示，Standard ML of New Jersey编译的程序在堆上分配的频率远高于C程序（20.7% vs. 12%）。
  - **GC开销**：GC时间占非GC时间的比例，平均为14%。这表明垃圾收集的开销是可以接受的，并且通过优化垃圾收集策略（如多代收集），有可能进一步减少开销。

**关键结论**：

1. **高堆分配率**：
   - Standard ML程序在堆上频繁分配闭包和记录，导致大量的存储指令。这意味着程序设计者不需要过分担心“consing”（频繁分配新对象），因为系统已经高效地管理堆内存。

2. **垃圾收集开销**：
   - 尽管堆分配频繁，垃圾收集的开销仍在合理范围内（平均14%）。通过改进垃圾收集策略，可以进一步降低这一比例。

3. **与C程序的比较**：
   - ML程序与C程序在堆分配率和存储指令比例上存在显著差异。这可能归因于两种语言的编程模型不同，以及编译器在优化存储指令方面的差异。

### **总结**

**15.4 更多关于缓存**部分深入探讨了编译器优化措施对缓存效果的影响，以及这些影响如何进一步影响程序的实际执行时间。以下是该节的关键要点总结：

1. **指令计数与执行时间**：
   - 指令计数虽然是评估编译器优化效果的重要指标，但由于缓存命中率等因素的波动，不能完全反映实际执行时间。

2. **缓存效果的重要性**：
   - 缓存效果直接影响程序的执行速度。优化措施可能通过改变指令和数据的内存访问模式，进而影响缓存命中率。

3. **优化措施的相互影响**：
   - 各种优化措施之间可能存在依赖性或冗余性，导致综合优化效果不如单独优化效果的简单乘积。

4. **参数调整对性能的影响**：
   - 调整编译器和运行时系统的参数（如寄存器数量、内联扩展轮次数、堆大小等）对缓存效果和执行时间有显著影响。

5. **堆分配率与垃圾收集开销**：
   - Standard ML程序在堆上频繁分配对象，导致较高的堆分配率和一定的垃圾收集开销。通过优化垃圾收集策略，可以进一步提高性能。

6. **与其他语言的比较**：
   - 与C程序相比，ML程序在堆分配率和存储指令比例上存在显著差异，反映了两种语言不同的编程模型和编译器优化策略。

通过理解这些关键要点，您可以更好地掌握编译器优化在实际硬件环境下的表现及其对程序性能的影响。如果您对**第十五章 性能评估（Performance Evaluation）**中的其他部分有进一步的问题或需要更深入的解释，请随时提问！

### ---------------------------

好的，我将**详细**解释您提供的《Compiling with Continuations》第十五章**“性能评估（Performance Evaluation）”**中的**15.5 编译时间（Compile Time）**、**15.6 与其他编译器的比较（Comparison with Other Compilers）**以及**15.7 结论（Conclusions）**部分。以下是对这些内容的逐步详解，旨在帮助您深入理解编译时间的影响因素、与其他编译器的性能比较以及整体的性能评估结论。

---

## **15.5 编译时间（Compile Time）**

### **概述**

**Standard ML of New Jersey (SML/NJ)** 的编译速度较慢，主要原因包括优化阶段的效率低下、非生产性阶段的工作量大以及从 λ-语言到续延风格（Continuation-Passing Style, CPS）的转换过程中生成了大量不必要的缩约红指数（redexes）。以下详细分析这些因素及其对编译时间的影响，并探讨改进措施。

### **编译时间长的原因**

1. **优化阶段效率低下**：
   - **原型化实现**：许多优化阶段的实现类似于原型，缺乏对运行速度的关注。
   - **非生产性阶段的工作量大**：如提升（hoisting）、公共子表达式消除（common-subexpression elimination, CSE）等优化阶段花费大量时间，但实际效果有限。

2. **冗余缩约红指数的生成**：
   - **从 λ-语言到 CPS 的转换**：生成了大量不必要的 β-缩约红指数，必须由优化阶段进行缩减。这增加了优化阶段的负担。

### **改进措施及效果**

作者提到了一些可以轻松修复的问题，并进行了相应的调整来减少编译时间：

1. **禁用不必要的优化**：
   - 例如，禁用提升和公共子表达式消除阶段。

2. **调整参数**：
   - 设置 `reducemore` 参数为 400，以减少优化阶段的迭代次数。

调整后的编译时间和各编译阶段的时间分布如**图15.17**所示。

### **编译阶段时间分布（Figure 15.17）**

| **Program** | **Compile Time (s)** | **Parse (%)** | **Semantics (%)** | **Translate (%)** | **Convert (%)** | **Optimize (%)** | **Closure (%)** | **Spill (%)** | **Generate (%)** | **Assemble (%)** |
| ----------- | -------------------- | ------------- | ----------------- | ----------------- | --------------- | ---------------- | --------------- | ------------- | ---------------- | ---------------- |
| **Life**    | 11                   | 5.9%          | 8.1%              | 0.7%              | 1.1%            | 9.4%             | 12.9%           | 0.8%          | 8.4%             | 52.6%            |
| **Lex**     | 88                   | 4.7%          | 7.3%              | 0.5%              | 0.8%            | 24.3%            | 8.1%            | 0.7%          | 5.8%             | 48.0%            |
| **Yacc**    | 499                  | 3.4%          | 4.0%              | 0.3%              | 0.6%            | 24.4%            | 9.8%            | 1.0%          | 4.1%             | 52.4%            |
| **Knu-B**   | 29                   | 5.9%          | 6.4%              | 0.7%              | 1.2%            | 20.9%            | 8.7%            | 0.7%          | 7.5%             | 48.0%            |
| **Simple**  | 120                  | 3.8%          | 7.7%              | 0.4%              | 0.7%            | 29.4%            | 6.0%            | 0.4%          | 3.8%             | 47.9%            |
| **VLIW**    | 328                  | 3.6%          | 4.7%              | 0.4%              | 0.7%            | 15.4%            | 13.1%           | 0.7%          | 4.3%             | 57.1%            |
| **Average** | **~125**             | **4.6%**      | **6.4%**          | **0.5%**          | **0.8%**        | **20.6%**        | **9.8%**        | **0.7%**      | **5.6%**         | **51.0%**        |

**主要观察**：

- **Assemble 阶段**：占用了超过 50% 的编译时间，这是一个显著的瓶颈。该阶段包括跨度依赖跳转的解析、指令调度和实际指令位模式的生成。
- **Optimize 阶段**：占用约 20%的编译时间，包括 η 规约（eta-reduction）、β-缩约（beta-contraction）和 β-扩展（beta-expansion）等优化。
- **Closure 阶段**：占用约 10%的时间，处理闭包相关的优化。
- **Parse、Semantics、Translate、Convert、Spill、Generate** 阶段占用的时间相对较少。

### **编译时间改进的潜力**

作者提出了一些具体的改进措施，估计可以显著减少编译时间：

1. **闭包阶段速度翻倍**：
   - 通过优化闭包处理的算法或数据结构，可以将该阶段的速度提高一倍。
   
2. **汇编阶段速度提高五倍**：
   - 通过优化汇编阶段的算法和数据结构，解决当前算法或数据结构导致的性能瓶颈，可以将汇编阶段的速度提高五倍。
   
3. **优化阶段速度翻倍**：
   - 通过移除无用的优化数据收集（如图15.5中显示的无用优化）和实现更智能的 CPS 转换，可以将优化阶段的速度提高一倍。

**预期效果**：

- 总体编译速度大约可以提高一倍。

### **现有编译速度**

调整后的编译速度仍然较慢，约为 **25 行每秒**，相比之下，一个优秀的 C 编译器在类似机器上可以达到 **400 行每秒** 的编译速度。这表明，尽管优化编译器可以显著提高编译速度，但当前的编译器设计和实现仍存在较大的改进空间。

### **编译时间改进的两点安慰**

1. **无需用 C 编写程序**：
   - 使用 SML/NJ 编译器不需要像 C 那样手动管理内存和指针，可以提高开发效率和代码安全性。
   
2. **计算机性能增长快于程序规模增长**：
   - 随着计算机硬件性能的提升，编译器的编译速度问题有望通过硬件进步得到缓解。

---

## **15.6 与其他编译器的比较（Comparison with Other Compilers）**

### **概述**

本节将 **Standard ML of New Jersey (SML/NJ)** 与其他几种 ML 编译器进行性能比较，包括编译速度和运行速度。这些编译器包括 **Poly/ML**、**Poplog ML**、**Edinburgh ML**、**The Kit Compiler**、**ANU ML**、**MicroML** 以及 **CAML** 的编译器。以下是详细的比较分析。

### **主要 ML 编译器简介**

1. **Poly/ML**：
   - **实现语言**：Poly 语言。
   - **支持平台**：Motorola 68020 和 SPARC 机器。
   - **性能**：编译速度较快，运行速度较慢于 SML/NJ。
   
2. **Poplog ML**：
   - **实现环境**：Poplog 系统。
   - **支持平台**：VAX、MC68020、Intel 386 和 SPARC 机器。
   - **性能**：编译速度较快，运行速度较慢于 Poly/ML。
   
3. **Edinburgh ML**：
   - **实现语言**：C 语言，使用字节码解释器。
   - **特点**：可移植性强，但执行速度较慢。
   
4. **The Kit Compiler**：
   - **作者**：Nick Rothwell。
   - **特点**：直接实现 The Definition of Standard ML，适用于研究用途，编译和执行时间远高于“真正”的编译器。
   
5. **ANU ML**：
   - **开发机构**：澳大利亚国立大学。
   - **支持平台**：MC68020、VAX 和 Pyramid。
   - **特点**：实现了 The Definition 的核心语言和旧版本的模块。
   
6. **MicroML**：
   - **开发机构**：瑞典 Umea 大学。
   - **特点**：为 IBM PC 设计的 ML 子集解释器。
   
7. **CAML 编译器**：
   - **实现语言**：CAML 语言，非标准 ML。
   - **版本**：
     - **CAML**：生成多种机器的本地代码。
     - **CAML Light**：快速的字节码解释器，内存占用显著低于 SML/NJ。

### **性能比较实验**

作者在一台 **SparcStation 2** 上对 **Poly/ML** 和 **SML/NJ** 进行了基准测试，使用了前述的六个基准程序。结果如**图15.18**所示。

#### **图15.18 Poly/ML vs. SML/NJ**

| **Program** | **Poly/ML Compile Time (s)** | **Poly/ML Run Time (s)** | **SML/NJ Compile Time (s)** | **SML/NJ Run Time (s)** |
| ----------- | ---------------------------- | ------------------------ | --------------------------- | ----------------------- |
| **Life**    | 3                            | 30.4                     | 10                          | 23.6                    |
| **Lex**     | 18                           | 24.9                     | 48                          | 18.0                    |
| **Yacc**    | 91                           | 11.0                     | 180                         | 7.9                     |
| **Knuth–B** | 9                            | 34.1                     | 24                          | 20.6                    |
| **Simple**  | 20                           | 260.5                    | 62                          | 54.4                    |
| **VLIW**    | 55                           | 50.3                     | 157                         | 39.3                    |
| **Average** | **~40**                      | **58.7**                 | **70.2**                    | **20.3**                |

**主要观察**：

- **编译时间**：
  - **Poly/ML** 约为 **SML/NJ** 的 **0.73 倍**（1.99 vs. 0.73 比率）。
  - **SML/NJ** 的编译时间明显长于 **Poly/ML**，尤其是在较大程序如 **Yacc** 和 **VLIW** 上。
  
- **运行时间**：
  - **SML/NJ** 运行时间明显快于 **Poly/ML**，平均约为 **Poly/ML** 的 **1.7 倍**。
  
- **堆内存使用**：
  - **SML/NJ** 使用的堆内存约为 **Poly/ML** 的 **1.5 倍**。

### **对比其他编译器**

作者还提到其他编译器，如 **CAML** 和 **CAML Light**，并引用了**图15.19**的结果。**图15.19**展示了在 Knuth–Bendix 基准测试下，不同编译器的运行时间和 GC 时间。

#### **图15.19 不同编译器的比较**

| **Compiler**           | **Execute Time (s)** | **GC Time (s)** |
| ---------------------- | -------------------- | --------------- |
| **CAML V2-6.1**        | 14.5                 | 6.2             |
| **CAML Light**         | 0.2                  | 28.3            |
| **SML/NJ**             | 0.65                 | 9.6             |
| **SML/NJ x-mod**       | 0.73                 | 1.7             |
| **LeLisp**             | 15.23                | 4.1             |
| **SunOS 3.5, cc -O**   | 4.35                 | -               |
| **gcc 1.37.1, gcc -O** | 4.22                 | -               |
| **Ultrix 4.0, cc -O2** | 0.90                 | -               |

**主要观察**：

- **CAML Light** 在 GC 时间上显著高于其他编译器，但执行时间极低（0.2秒），可能是因为其实现为字节码解释器，GC 开销较大。
- **SML/NJ x-mod**（将所有模块放在一个文件中以允许跨模块优化）在执行时间和 GC 时间上表现优异。
- **SML/NJ** 的执行时间和 GC 时间适中，显示出较好的运行性能。

### **总结**

**SML/NJ** 相较于其他 ML 编译器有以下特点：

1. **编译速度慢**：
   - 与 **Poly/ML** 和 **Poplog ML** 相比，**SML/NJ** 的编译速度较慢，尤其在处理大型基准程序时差距更为明显。
   
2. **运行速度快**：
   - **SML/NJ** 生成的代码运行速度快于 **Poly/ML**，在大多数基准测试中，**SML/NJ** 的程序执行时间显著短于 **Poly/ML**。

3. **堆内存使用较高**：
   - **SML/NJ** 在运行时使用的堆内存比 **Poly/ML** 高出约 1.5 倍，但其 GC 开销仍在合理范围内（平均约 14%）。

4. **与其他语言的比较**：
   - 与 **C** 编译器相比，**SML/NJ** 的堆分配率更高，GC 开销也相对较大，但这也反映了两种语言不同的编程模型和内存管理策略。

5. **编译器优化的潜力**：
   - **SML/NJ** 仍有很大的优化空间，特别是在汇编阶段和闭包处理阶段，通过优化这些关键部分，可以显著提高编译速度。

---

## **15.7 结论（Conclusions）**

### **关键发现总结**

通过对第十五章的详细分析，可以得出以下关键结论：

1. **缓存未命中显著影响执行速度**：
   - 缓存未命中占用了程序执行时间的很大一部分，若能有效减少缓存未命中，程序的执行速度可以提升约两倍。
   - 建议硬件或软件方面改进，如增加缓存大小或优化垃圾收集策略，以提高缓存效果。

2. **最重要的优化措施**：
   - **β-缩约（beta-contraction）**、**死变量消除（dead-variable elimination）** 和 **常量折叠（constant folding）** 是最重要的优化措施，对程序的指令计数和运行速度有显著影响。
   - 这些优化在将代码翻译为 mini-ML 和 CPS 的过程中尤为有效，减少了冗余的缩约红指数。

3. **内联扩展、η-规约、元组参数展开和去柯里化**：
   - 这些优化措施虽然在节省时间和空间上表现良好，但相对于前三者的重要性稍低。

4. **消除未使用的过程参数、对常量参数的算术运算求值和跨模块优化**：
   - 这些优化不仅能显著节省时间，还能更大幅度地节省空间。

5. **条件比较的常量折叠**：
   - 此优化对运行时间没有显著提升，但能显著节省代码空间。

6. **寄存器分配策略**：
   - 基于实际参数选择寄存器分配策略（如 **argrep**）是非常有效的，可以减少寄存器-寄存器移动指令的需求。

7. **优化措施的独立性**：
   - 各种优化措施之间存在一定的依赖性或冗余性，导致综合优化效果不如预期的简单乘积。但整体优化仍能显著提升性能。

8. **堆分配率与垃圾收集开销**：
   - **SML/NJ** 程序在堆上频繁分配对象，导致较高的堆分配率和一定的垃圾收集开销（平均约 14%）。通过优化垃圾收集策略（如多代收集），可以进一步减少 GC 开销。

9. **寄存器使用数量**：
   - 目标机器上约 **17 个通用寄存器**（包括 **5-6 个专用寄存器**）已经足够使用，**14 个寄存器**的性能表现几乎与 **17 个寄存器**相当。

10. **内联扩展的轮次数**：
    - 两轮内联扩展足以捕捉大多数有用的 β-缩约，进一步增加轮次数对性能提升有限。

11. **β-扩展器的启发式方法**：
    - 现有的 β-扩展器启发式方法表现出较好的鲁棒性，能够在不同的程序中稳定提供优化效果。

12. **跨模块优化**：
    - 在当前的编译器实现中，跨模块优化对性能的提升有限，但未来有望通过自动跨编译单元的优化进一步提升性能。

### **关键要点回顾**

1. **寄存器映射**：
   - 根据不同目标机器的寄存器结构和功能差异，合理分配寄存器资源，确保关键寄存器用于内存管理和异常处理，通用寄存器用于存储 CPS 变量和传递参数。

2. **指令调度**：
   - 通过优化指令执行顺序，充分利用处理器的流水线和并行执行能力，减少指令执行时间，提高程序整体性能。

3. **反别名技术**：
   - 防止不同变量或指针引用同一内存位置，优化寄存器分配和指令调度，提升程序性能。

4. **交替临时寄存器策略**：
   - 优化临时变量的使用，减少寄存器溢出和移动指令的需求，提高寄存器利用率。

5. **整数与浮点数运算优化**：
   - 通过合理的寄存器分配和指令生成策略，实现高效的算术运算和内存管理，确保类型安全和执行效率。

### **最终结论**

通过对 **第十五章 性能评估** 的详细分析，可以得出以下总体结论：

- **优化的重要性**：某些优化措施（如 β-缩约、死变量消除和常量折叠）对程序性能有显著影响，是编译器优化中不可或缺的部分。

- **编译器的瓶颈**：汇编阶段和闭包处理阶段是当前编译器的主要性能瓶颈，需要重点优化。

- **缓存影响**：缓存未命中率对程序执行时间有显著影响，编译器优化需要考虑内存访问模式，以提高缓存利用率。

- **寄存器管理**：合理的寄存器分配策略和寄存器数量对程序性能至关重要，优化寄存器使用可以显著提升执行效率。

- **与其他编译器的比较**：虽然 **SML/NJ** 的编译速度较慢，但其生成的代码运行速度较快。其他编译器如 **Poly/ML** 和 **Poplog ML** 在编译速度上表现更好，但生成的代码运行速度较慢。

- **编译时间的改进潜力**：通过优化汇编阶段、闭包处理和优化阶段的算法与数据结构，**SML/NJ** 的编译时间有望大幅减少。

- **未来的改进方向**：
  - 优化编译器的各个阶段，提高整体编译速度。
  - 改进垃圾收集策略，以提高缓存效果和减少 GC 开销。
  - 进一步优化寄存器管理和指令调度，以提升程序的执行效率。

通过理解和应用这些结论，可以指导编译器的进一步优化，提升其性能和实用性。

如果您对**第十五章 性能评估（Performance Evaluation）**中的其他部分有进一步的问题或需要更深入的解释，请随时提问！

### ----------------------------



### ---------------------------



### ----------------------------



### ---------------------------



### ----------------------------



### ---------------------------



### ----------------------------



### ---------------------------



### ----------------------------