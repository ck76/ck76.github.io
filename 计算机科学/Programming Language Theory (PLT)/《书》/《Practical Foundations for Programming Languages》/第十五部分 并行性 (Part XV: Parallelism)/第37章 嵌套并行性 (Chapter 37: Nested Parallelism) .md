[toc]



### **Part XV 并行性 (Parallelism)**

**并行性**(parallelism) 是指在程序执行过程中，多个任务可以同时进行的能力。在现代计算机系统中，特别是在多核处理器上，并行性是提升计算效率的重要手段。第 XV 部分介绍了并行计算的概念和机制，讨论了嵌套并行、分叉连接、成本动态分析，以及如何实现高效的并行计算。

---

### **1. 嵌套并行 (Nested Parallelism)**

**嵌套并行**指的是一个并行任务中包含另一个并行任务。这种结构允许程序在多层次上并行化，从而提高并行效率。

- **嵌套并行的典型应用**：例如在矩阵乘法中，外层循环可以并行化，而内层循环也可以进一步并行化。通过这种嵌套结构，计算可以充分利用多核资源。

#### **公式分析**：
如果一个任务 $T$ 在执行过程中调用了两个并行任务 $T_1$ 和 $T_2$，并且这两个任务本身也可以进一步并行化，那么整个任务结构是**递归的并行结构**。这类并行的复杂度可以用递归方程描述，通常通过分治策略求解。

---

### **2. 二叉分叉连接 (Binary Fork-Join)**

**二叉分叉连接**(binary fork-join) 是一种典型的并行计算模式。在这种模式下，一个任务可以分叉为两个并行子任务（fork），当子任务完成时，它们的结果会被合并（join）。

- **分叉 (Fork)**：一个任务被分解为两个子任务，并行执行。
- **连接 (Join)**：当两个子任务完成时，合并它们的结果以继续主任务的执行。

#### **公式分析**：
设 $T_1$ 和 $T_2$ 是两个并行任务，二叉分叉连接的成本可以用公式 $T_f = T_1 + T_2 + T_j$ 来表示，其中 $T_j$ 是连接两个结果的时间。通常，$T_1$ 和 $T_2$ 可以同时执行，因此总执行时间主要由最大值 $\max(T_1, T_2)$ 决定。

---

### **3. 成本动态分析 (Cost Dynamics)**

**成本动态分析**是指对并行计算的**时间复杂度**和**工作量**进行评估。通过分析程序的并行部分和串行部分，计算出程序的总执行时间和并行效率。

- **工作量 (Work)**：是指执行所有任务所需的总时间，即所有任务的累积时间。
- **跨度 (Span)**：是指执行最长的路径所需的时间，代表了并行计算中最慢的部分。

#### **公式分析**：
并行计算的**总时间** $T_p$ 可以用**工作量** $W$ 和**跨度** $S$ 来描述：
$$
T_p = \frac{W}{p} + S
$$
其中 $p$ 是处理器的数量，$W$ 是总工作量，$S$ 是跨度。

---

### **4. 多重分叉连接 (Multiple Fork-Join)**

**多重分叉连接**扩展了二叉分叉连接的概念，允许一个任务分叉为多个子任务，而不仅仅是两个。这种模式更适合高度并行的任务。

#### **公式分析**：
如果一个任务分叉为 $n$ 个子任务，每个子任务的成本为 $T_i$，那么总的执行时间为：
$$
T_f = \max(T_1, T_2, ..., T_n) + T_j
$$
其中 $T_j$ 是合并这些任务结果的时间。由于多个任务可以同时执行，总时间由最长的任务决定。

---

### **5. 可证明的高效实现 (Provably Efficient Implementations)**

在并行计算中，重要的是如何通过正确的算法设计实现高效的并行执行。**可证明的高效实现**意味着我们可以通过数学证明表明某个并行算法在给定的硬件资源下是最优或接近最优的。

#### **公式分析**：
例如，在一个具有 $p$ 个处理器的系统中，我们可以通过分析工作量 $W$ 和跨度 $S$ 来证明并行算法的效率。如果我们能够确保：
$$
T_p = O\left(\frac{W}{p} + S\right)
$$
则表明该并行算法在处理器数量增加时具有良好的扩展性。

---

### **6. 未来 (Futures) 和推测 (Speculations)**

**未来**(futures) 和**推测**(speculations) 是并行计算中的高级机制，允许我们在未来的某个时间点获取计算结果，或者在推测某个条件成立的情况下预先进行计算。

- **未来 (Futures)**：一种并行计算机制，允许程序启动一个任务并在未来的某个时间点获取其结果。
- **推测 (Speculations)**：允许程序在特定条件下并行执行可能用到的任务，即使这些任务的必要性尚未确定。

#### **公式分析**：
假设我们启动了一个未来任务 $f$，其结果在时间 $t_1$ 完成，那么我们可以在未来的某个时间 $t_2$ 通过调用 `f.get()` 来获取其结果。推测机制则允许在多个可能条件下启动多个并行任务，并根据实际情况保留正确的计算结果。

---

### **7. 应用与实际 (Applications of Futures)**

**未来** 和 **推测** 机制在实际应用中非常有用，尤其是在处理并发任务时，例如 Web 服务器的请求处理、数据库的查询优化等。

#### **公式分析**：
如果有多个独立的任务需要执行，未来机制可以并行启动这些任务，并在需要结果时获取它们。通过分析任务的依赖关系，可以优化执行顺序，确保并行性和计算效率。

---

### **总结**

第 XV 部分详细介绍了并行计算的基本概念和机制，包括嵌套并行、二叉分叉连接、多重分叉连接、成本分析和高效实现。同时，**未来** 和 **推测** 提供了灵活的并行计算机制，使得程序可以高效地管理和执行并行任务。这些技术为现代多核系统和分布式计算中的高性能并行程序设计提供了理论和实践的基础。

### ---------------------------------

### 第 39 章 嵌套并行性 (Nested Parallelism)

**并行计算**(parallel computation) 的主要目的是通过同时执行多个计算来减少程序的运行时间。例如，当我们需要相加两个通过复杂计算得出的数时，可以考虑同时并行地计算这两个加数，然后再求它们的和。然而，能够利用并行性的前提是程序的各个部分之间的依赖关系。如果一个计算依赖于另一个计算的结果，那么我们必须依次执行这些计算，因为第一个计算的结果需要传递给第二个计算。换句话说，程序中子计算之间的依赖关系越少，并行化的机会就越大。

这种对依赖关系的减少，特别强调了**函数式编程模型**(functional models of computation)，因为在命令式代码中，由于可能存在可变状态（例如可共享的可赋值变量），这类可变性会强制程序进行顺序执行，限制了并行的可能性。而函数式编程没有可变状态，所以在大多数情况下能更好地利用并行性。

在本章中，我们将讨论**嵌套并行性**(nested parallelism)，即在并行计算中嵌套其他并行计算，形成层次化结构。嵌套并行性有时也称为**分叉连接并行性**(fork-join parallelism)，因为它涉及**分叉**(fork) 出两个或多个并行计算，并在完成它们的计算后通过**连接**(join) 来合并它们的结果，然后继续执行下一个步骤。

我们将探讨两种不同的嵌套并行性动态：

1. **结构动态**(structural dynamics)：在复合表达式上进行单次转换时，可能涉及多个组成表达式的并行转换。这种动态是以并行结构为中心，强调程序结构中的并行性。

2. **成本动态**(cost dynamics)：专注于并行程序的**顺序复杂度**和**并行复杂度**（即**工作量**和**深度**）。成本动态通过将每个计算关联到一个**串行-并行图**(series-parallel graph)，对程序的执行时间进行建模。串行-并行图是一种图形结构，能够展示并行任务之间的依赖关系，并且有助于分析程序的执行性能。

---

### **1. 二叉分叉连接 (Binary Fork-Join)**

**二叉分叉连接**(binary fork-join) 是嵌套并行性最简单的形式，它允许一个任务分叉为两个并行的子任务，然后在这些子任务完成后，将结果合并到主任务中。例如，假设有两个任务 $T_1$ 和 $T_2$ 可以并行执行，在分叉后，这两个任务会同时计算，并在计算结束后通过连接操作将它们的结果汇合到主任务。

#### **公式解释**：

假设有两个并行任务 $T_1$ 和 $T_2$，它们分别耗时 $W_1$ 和 $W_2$，那么总的执行时间 $T_{\text{binary}}$ 可以表示为：
$$
T_{\text{binary}} = \max(W_1, W_2) + T_{\text{join}}
$$
其中 $T_{\text{join}}$ 是将两个任务结果合并的时间。在并行计算中，总时间主要由两个任务中耗时最长的那个决定。

---

### **2. 成本动态 (Cost Dynamics)**

**成本动态**分析了并行程序的时间复杂度。并行程序的效率取决于两个因素：

- **工作量**(work)：程序中所有任务的总工作量，即所有任务的累积时间。这表示了整个程序的理论最短执行时间，即使没有并行性。
- **深度**(depth)：程序执行的最长路径。这表示了在最佳并行化条件下，程序中最慢的部分，它决定了并行程序的最终瓶颈。

通过这两个因素，可以评估并行程序在不同处理器数量下的性能表现。

#### **公式解释**：

并行程序的总执行时间 $T_p$ 可以通过工作量 $W$ 和深度 $D$ 来表示：
$$
T_p = \frac{W}{p} + D
$$
其中 $p$ 是可用的处理器数量，$W$ 是总的工作量，$D$ 是并行程序的深度。工作量除以处理器数量表示的是每个处理器平均承担的工作，深度 $D$ 是执行过程中不可避免的顺序计算部分。

---

### **3. 多重分叉连接 (Multiple Fork-Join)**

**多重分叉连接**(multiple fork-join) 是二叉分叉连接的扩展，它允许一个任务分叉为多个并行任务，而不仅仅是两个。这种模式更适合处理高度并行的任务，特别是那些可以分解为大量独立子任务的计算，例如矩阵乘法或大规模数据处理。

#### **公式解释**：

如果一个任务分叉为 $n$ 个并行任务，每个子任务的工作量为 $W_i$，总的执行时间为：
$$
T_{\text{multi}} = \max(W_1, W_2, ..., W_n) + T_{\text{join}}
$$
由于多个任务可以同时执行，总的执行时间由最长的任务决定。

---

### **4. 可证明的高效实现 (Provably Efficient Implementations)**

**可证明的高效实现**(provably efficient implementations) 意味着我们可以通过理论分析或数学证明表明某个并行算法在给定的硬件资源下是高效的。这类实现通常通过减少串行瓶颈和优化并行化来达到较高的效率。

#### **公式解释**：

假设我们在具有 $p$ 个处理器的系统中执行某个并行算法，如果我们能证明该算法的执行时间 $T_p$ 满足：
$$
T_p = O\left(\frac{W}{p} + D\right)
$$
则表明该算法具有良好的可扩展性，并且随着处理器数量的增加，程序的执行时间会显著减少。这是并行程序设计中重要的性能衡量标准。

---

### **5. 备注 (Notes)**

在本章中，**并行性**的核心概念是通过减少子任务之间的依赖，增加并行化的可能性。通过嵌套并行和分叉连接技术，程序可以显著减少执行时间。同时，成本动态的分析帮助我们量化并行计算的效率。

### ---------------------------------

### 39.1 二叉分叉连接 (Binary Fork-Join)

在这里，我们讨论一种并行语言，它的唯一并行性来源于两个变量绑定的同时计算。这种并行性由如下形式的构造表示：
$$
\text{par } x_1 = e_1 \text{ and } x_2 = e_2 \text{ in } e,
$$
其中两个变量 $x_1$ 和 $x_2$ 分别绑定到两个表达式 $e_1$ 和 $e_2$，用于单个表达式 $e$ 中。这种构造代表了一个简单的**分叉-连接**(fork-join) 原语，其中 $e_1$ 和 $e_2$ 可以独立计算，然后通过表达式 $e$ 合并它们的结果。

### **并行绑定构造**

并行绑定构造的抽象语法可以通过以下方式表示：
$$
\text{par}(e_1; e_2; x_1.x_2.e),
$$
这清楚地表明，变量 $x_1$ 和 $x_2$ 仅在 $e$ 中绑定，而不在它们各自的绑定中。这确保了 $e_1$ 和 $e_2$ 之间的相互独立性，也就是说 $e_1$ 的求值与 $e_2$ 的求值无关，反之亦然。

例如，并行的**配对**可以定义为如下形式的表达式：
$$
\text{par } x_1 = e_1 \text{ and } x_2 = e_2 \text{ in } \langle x_1, x_2 \rangle,
$$
该表达式表示分别并行计算 $e_1$ 和 $e_2$ 的值，然后构造这两个值的配对。

### **类型规则**

并行绑定构造的类型规则如下所示：
$$
\frac{\Gamma \vdash e_1 : \tau_1 \quad \Gamma \vdash e_2 : \tau_2 \quad \Gamma, x_1 : \tau_1, x_2 : \tau_2 \vdash e : \tau}
{\Gamma \vdash \text{par}(e_1; e_2; x_1.x_2.e) : \tau}
\tag{39.1}
$$

#### **公式详解**：

- **$\Gamma \vdash e_1 : \tau_1$**：表示在上下文 $\Gamma$ 中，表达式 $e_1$ 的类型为 $\tau_1$。
- **$\Gamma \vdash e_2 : \tau_2$**：表示在上下文 $\Gamma$ 中，表达式 $e_2$ 的类型为 $\tau_2$。
- **$\Gamma, x_1 : \tau_1, x_2 : \tau_2 \vdash e : \tau$**：表示在上下文 $\Gamma$ 中，带有变量 $x_1$ 和 $x_2$ 的表达式 $e$ 的类型为 $\tau$。
- **$\text{par}(e_1; e_2; x_1.x_2.e)$**：表示并行计算 $e_1$ 和 $e_2$，并将它们的结果绑定到 $x_1$ 和 $x_2$ 中，然后计算表达式 $e$。

这种类型规则确保了并行构造中的每个部分都类型一致，并且整个并行表达式也能够正确地类型化。

---

### **顺序动态规则 (Sequential Dynamics)**

我们接下来定义并行构造的**顺序动态规则**，用转移判断形式 $e \rightarrow_{\text{seq}} e'$ 来表示，即表达式 $e$ 顺序转换为表达式 $e'$。

#### **规则 39.2a**：当 $e_1$ 可以进行求值时，计算 $e_1$ 的下一步
$$
e_1 \rightarrow e_1' \quad \Rightarrow \quad \text{par}(e_1; e_2; x_1.x_2.e) \rightarrow_{\text{seq}} \text{par}(e_1'; e_2; x_1.x_2.e)
$$

**解释**：如果表达式 $e_1$ 可以转换为 $e_1'$，那么整个并行表达式可以通过将 $e_1$ 转换为 $e_1'$ 而继续。

#### **公式详解**：
- **$e_1 \rightarrow e_1'$**：表示 $e_1$ 进行一次转换，得到 $e_1'$。
- **$\text{par}(e_1; e_2; x_1.x_2.e)$**：表示并行绑定构造，其中 $e_1$ 和 $e_2$ 可以并行求值。
- **$\text{par}(e_1'; e_2; x_1.x_2.e)$**：表示当 $e_1$ 进行转换后，并行表达式的下一步状态。

---

#### **规则 39.2b**：当 $e_1$ 已经计算完毕，继续计算 $e_2$
$$
e_1 \ \text{val} \quad e_2 \rightarrow e_2' \quad \Rightarrow \quad \text{par}(e_1; e_2; x_1.x_2.e) \rightarrow_{\text{seq}} \text{par}(e_1; e_2'; x_1.x_2.e)
$$

**解释**：当 $e_1$ 已经是一个值时，继续求值 $e_2$，直到它也可以计算为值。

#### **公式详解**：
- **$e_1 \ \text{val}$**：表示 $e_1$ 已经计算为值。
- **$e_2 \rightarrow e_2'$**：表示 $e_2$ 进行一次转换，得到 $e_2'$。
- **$\text{par}(e_1; e_2'; x_1.x_2.e)$**：表示并行表达式中的 $e_2$ 进行了转换。

---

#### **规则 39.2c**：当 $e_1$ 和 $e_2$ 都已经是值时，计算表达式 $e$
$$
e_1 \ \text{val} \quad e_2 \ \text{val} \quad \Rightarrow \quad \text{par}(e_1; e_2; x_1.x_2.e) \rightarrow_{\text{seq}} [e_1, e_2 / x_1, x_2]e
$$

**解释**：当 $e_1$ 和 $e_2$ 都已经是值时，将它们的值分别绑定到 $x_1$ 和 $x_2$ 中，然后计算表达式 $e$。

#### **公式详解**：
- **$[e_1, e_2 / x_1, x_2]e$**：表示将 $e_1$ 和 $e_2$ 的值替换到表达式 $e$ 中的 $x_1$ 和 $x_2$。

---

### **总结**

二叉分叉连接 (Binary Fork-Join) 是并行计算中的基本构造，它允许两个独立的计算同时进行，并在计算完成后合并它们的结果。通过抽象语法和类型规则，我们确保了程序中的并行构造能够类型安全地执行。顺序动态规则描述了如何逐步执行并行任务，并在必要时合并结果。

### ---------------------------------

### 39.1 并行动态 (Parallel Dynamics)

在并行计算中，程序可以通过并行执行多个任务来加速完成。并行动态通过转移判断的形式 $e \rightarrow_{\text{par}} e'$ 来定义，其中表达式 $e$ 经过并行转换为 $e'$。以下是并行动态的规则。

---

#### **规则 39.3a**：两个表达式同时进行并行计算
$$
e_1 \rightarrow_{\text{par}} e_1' \quad e_2 \rightarrow_{\text{par}} e_2' \quad \Rightarrow \quad \text{par}(e_1; e_2; x_1.x_2.e) \rightarrow_{\text{par}} \text{par}(e_1'; e_2'; x_1.x_2.e)
$$

**解释**：如果两个表达式 $e_1$ 和 $e_2$ 都可以并行求值，则它们分别同时进行一步转换，并且并行构造也相应地更新。

#### **公式详解**：
- **$e_1 \rightarrow_{\text{par}} e_1'$**：表示 $e_1$ 进行了一次并行计算转换，变为 $e_1'$。
- **$e_2 \rightarrow_{\text{par}} e_2'$**：表示 $e_2$ 同时进行了并行计算转换，变为 $e_2'$。
- **$\text{par}(e_1'; e_2'; x_1.x_2.e)$**：表示更新后的并行构造，表示 $e_1$ 和 $e_2$ 都完成了相应的并行转换。

---

#### **规则 39.3b**：当 $e_1$ 继续并行计算，而 $e_2$ 已经是值
$$
e_1 \rightarrow_{\text{par}} e_1' \quad e_2 \ \text{val} \quad \Rightarrow \quad \text{par}(e_1; e_2; x_1.x_2.e) \rightarrow_{\text{par}} \text{par}(e_1'; e_2; x_1.x_2.e)
$$

**解释**：如果 $e_1$ 仍然可以并行计算，而 $e_2$ 已经是一个值，则 $e_1$ 继续进行转换，而 $e_2$ 保持不变。

#### **公式详解**：
- **$e_1 \rightarrow_{\text{par}} e_1'$**：表示 $e_1$ 继续并行计算，进行了一次转换。
- **$e_2 \ \text{val}$**：表示 $e_2$ 已经计算完成，成为一个值。
- **$\text{par}(e_1'; e_2; x_1.x_2.e)$**：表示 $e_1$ 更新后的并行构造，$e_2$ 保持不变。

---

#### **规则 39.3c**：当 $e_1$ 已经是值，而 $e_2$ 继续并行计算
$$
e_1 \ \text{val} \quad e_2 \rightarrow_{\text{par}} e_2' \quad \Rightarrow \quad \text{par}(e_1; e_2; x_1.x_2.e) \rightarrow_{\text{par}} \text{par}(e_1; e_2'; x_1.x_2.e)
$$

**解释**：当 $e_1$ 已经成为一个值，$e_2$ 仍然可以并行计算时，$e_2$ 继续计算，而 $e_1$ 保持不变。

#### **公式详解**：
- **$e_1 \ \text{val}$**：表示 $e_1$ 已经计算完成，成为一个值。
- **$e_2 \rightarrow_{\text{par}} e_2'$**：表示 $e_2$ 继续并行计算，进行了一次转换。
- **$\text{par}(e_1; e_2'; x_1.x_2.e)$**：表示更新后的并行构造，$e_1$ 保持不变。

---

#### **规则 39.3d**：当 $e_1$ 和 $e_2$ 都是值时，计算表达式 $e$
$$
e_1 \ \text{val} \quad e_2 \ \text{val} \quad \Rightarrow \quad \text{par}(e_1; e_2; x_1.x_2.e) \rightarrow_{\text{par}} [e_1, e_2 / x_1, x_2]e
$$

**解释**：当 $e_1$ 和 $e_2$ 都已经是值时，将它们分别绑定到 $x_1$ 和 $x_2$ 中，然后计算表达式 $e$。

#### **公式详解**：
- **$[e_1, e_2 / x_1, x_2]e$**：表示将 $e_1$ 和 $e_2$ 的值替换为表达式 $e$ 中的 $x_1$ 和 $x_2$，并继续计算 $e$。

---

### **并行动态的抽象性**

并行动态是理想化的，它抽象掉了现实中计算资源的限制。在实际应用中，计算资源（如处理器数量）可能会限制并行计算的能力，但理论上的并行动态假设资源是无限的。这种理想化有助于我们专注于并行程序的效率，而不必考虑实际的计算资源分配。

### **隐式并行性定理 (Implicit Parallelism Theorem)**

**隐式并行性定理**的核心思想是：**顺序动态**和**并行动态**在计算结果上是一致的。也就是说，无论是顺序执行还是并行执行，程序的语义保持不变，唯一的区别在于执行的效率。这一特性意味着我们可以在顺序平台上开发程序，即使它是为了并行平台设计的，因为程序的行为不会受到是否使用并行动态的影响。

由于顺序动态是**确定性**的（即每个表达式最多有一个值），隐式并行性定理也暗示了并行动态是确定性的。这种确定性并行性与非确定性并发（下一章会讨论）形成鲜明对比。

---

### **定理的证明**

隐式并行性定理的证明可以通过定义一种**求值动态** $e \Downarrow v$（参考第 7 章）来进行，并且证明如下等价性：
$$
e \rightarrow^*_{\text{par}} v \iff e \Downarrow v \iff e \rightarrow^*_{\text{seq}} v
$$
其中 $v$ 是一个值闭合的表达式。这一证明的核心规则是并行 let 构造的求值规则：
$$
e_1 \Downarrow v_1 \quad e_2 \Downarrow v_2 \quad [v_1, v_2 / x_1, x_2]e \Downarrow v \quad \Rightarrow \quad \text{par}(e_1; e_2; x_1.x_2.e) \Downarrow v
\tag{39.4}
$$

---

### **总结**

- **并行动态**通过多个规则展示了如何同时计算表达式并最终将结果组合起来。
- **隐式并行性定理**确保了顺序动态和并行动态的语义一致性，使得程序的执行结果不受并行与否的影响。
- 通过 **确定性并行性**，我们可以在顺序平台上开发程序，而不需要担心其在并行平台上的行为是否会有所不同。

### ---------------------------------

### 引理 39.1：**顺序动态和求值动态的等价性**
$$
e \rightarrow^*_{\text{seq}} v \iff e \Downarrow v
$$

**证明思路**：证明该引理的关键是展示顺序动态 ($\rightarrow_{\text{seq}}$) 和求值动态 ($\Downarrow$) 的一致性。我们需要证明两点：
1. 如果 $e \rightarrow_{\text{seq}} e'$ 且 $e' \Downarrow v$，那么 $e \Downarrow v$。
2. 如果 $e_1 \rightarrow^*_{\text{seq}} v_1$ 且 $e_2 \rightarrow^*_{\text{seq}} v_2$，且 $[v_1, v_2 / x_1, x_2]e \rightarrow^*_{\text{seq}} v$，那么并行表达式 $ \text{par } x_1 = e_1 \text{ and } x_2 = e_2 \text{ in } e \rightarrow^*_{\text{seq}} v$。

---

#### **第一点**：证明 $e \rightarrow_{\text{seq}} e' \land e' \Downarrow v \Rightarrow e \Downarrow v$

首先，我们通过归纳展示，对于顺序动态 $e \rightarrow_{\text{seq}} e'$，如果 $e'$ 可以求值到 $v$，那么 $e$ 也可以求值到 $v$。

- **基本情况**：假设 $e'$ 已经是一个值 $v$，则根据求值动态的定义，$e \Downarrow v$，因为 $v$ 是最终的结果。
- **归纳步骤**：对于每个顺序转移 $e \rightarrow_{\text{seq}} e'$，假设 $e' \Downarrow v$，我们希望证明 $e \Downarrow v$。由于顺序动态规则是一致的，它允许 $e$ 通过一系列步骤最终转换为 $v$。

因此，如果 $e \rightarrow_{\text{seq}} e'$ 且 $e' \Downarrow v$，那么 $e \Downarrow v$。

---

#### **第二点**：证明 $e_1 \rightarrow^*_{\text{seq}} v_1 \land e_2 \rightarrow^*_{\text{seq}} v_2 \land [v_1, v_2 / x_1, x_2]e \rightarrow^*_{\text{seq}} v \Rightarrow \text{par } x_1 = e_1 \text{ and } x_2 = e_2 \text{ in } e \rightarrow^*_{\text{seq}} v$

在并行表达式的情况下，我们需要证明：
- 如果 $e_1$ 和 $e_2$ 分别可以求值为 $v_1$ 和 $v_2$，并且 $[v_1, v_2 / x_1, x_2]e$ 可以进一步求值为 $v$，那么整个并行表达式 $\text{par } x_1 = e_1 \text{ and } x_2 = e_2 \text{ in } e$ 也可以求值为 $v$。

根据规则 39.2c，当 $e_1$ 和 $e_2$ 都是值时，整个并行表达式可以将 $v_1$ 和 $v_2$ 分别绑定到 $x_1$ 和 $x_2$，然后继续求值 $e$，最终得到结果 $v$。因此，该情况成立。

---

### 引理 39.2：**并行动态和求值动态的等价性**
$$
e \rightarrow^*_{\text{par}} v \iff e \Downarrow v
$$

**证明思路**：该引理的证明与引理 39.1 类似，重点在于展示并行动态 ($\rightarrow_{\text{par}}$) 和求值动态 ($\Downarrow$) 的一致性。

---

#### **第一点**：证明 $e \rightarrow_{\text{par}} e' \land e' \Downarrow v \Rightarrow e \Downarrow v$

我们通过归纳证明，对于并行动态 $e \rightarrow_{\text{par}} e'$，如果 $e'$ 可以求值到 $v$，那么 $e$ 也可以求值到 $v$。

- **基本情况**：如果 $e'$ 已经是值 $v$，则根据求值动态的定义，$e \Downarrow v$。
- **归纳步骤**：对于并行动态中的每一个转换 $e \rightarrow_{\text{par}} e'$，我们假设 $e' \Downarrow v$，需要证明 $e \Downarrow v$。并行动态规则允许多个表达式同时转换，但最终它们仍然必须遵循求值动态的规则，因此 $e$ 也可以求值为 $v$。

---

#### **第二点**：证明 $e_1 \rightarrow^*_{\text{par}} v_1 \land e_2 \rightarrow^*_{\text{par}} v_2 \land [v_1, v_2 / x_1, x_2]e \rightarrow^*_{\text{par}} v \Rightarrow \text{par } x_1 = e_1 \text{ and } x_2 = e_2 \text{ in } e \rightarrow^*_{\text{par}} v$

这个证明类似于顺序动态中的并行情况。根据规则 39.3d，当 $e_1$ 和 $e_2$ 都是值时，整个并行表达式将 $v_1$ 和 $v_2$ 分别绑定到 $x_1$ 和 $x_2$ 中，并继续求值表达式 $e$，最终得到结果 $v$。如果 $e_1$ 或 $e_2$ 尚未完成求值，规则 39.3a、39.3b 和 39.3c 分别处理继续计算的情况。

- 如果 $e_1 = v_1$ 且 $e_2 = v_2$，则根据规则 39.3d，整个并行表达式求值为 $v$。
- 如果 $e_2 = v_2$ 但 $e_1$ 继续求值，归纳假设适用于 $e_1$ 的求值过程，通过规则 39.3b 得到整个并行表达式的求值结果。
- 如果 $e_1$ 已经是值，而 $e_2$ 继续求值，归纳假设适用于 $e_2$，通过规则 39.3c 处理。
- 当 $e_1$ 和 $e_2$ 同时求值时，规则 39.3a 确保整个过程的一致性。

---

### 定理 39.3：**隐式并行性定理 (Implicit Parallelism Theorem)**
$$
\forall v \ \text{val}, \ e \rightarrow^*_{\text{seq}} v \iff e \rightarrow^*_{\text{par}} v
$$

**证明**：该定理的证明依赖于前面两个引理，即引理 39.1 和 39.2。隐式并行性定理表明，顺序动态和并行动态在计算结果上是一致的，也就是说，无论程序是顺序执行还是并行执行，最终的求值结果不会改变，唯一的区别在于执行效率。

因此，程序的**语义**不会受到并行性与否的影响，我们只需关注程序的**复杂性**，而不必担心程序的**正确性**。这个定理确保了并行计算不会引入不确定性或影响结果的准确性。

---

### **总结**

- **引理 39.1 和 39.2**：证明了顺序动态、并行动态和求值动态之间的等价性，表明它们在求值结果上是相同的。
- **隐式并行性定理 (Theorem 39.3)**：说明程序的语义与并行性无关，只影响执行效率。并行执行不会影响程序的正确性，程序可以在顺序平台上开发，并在并行平台上运行，而不会出现语义上的差异。

### ---------------------------------

### 39.2 成本动态 (Cost Dynamics)

**成本动态**(Cost Dynamics) 是并行计算中的重要概念，用于量化程序的计算代价。通过为表达式的求值分配一个**成本图**(cost graph)，可以分析程序的**工作量**(work) 和 **深度**(depth)，从而评估其并行性能。

#### **成本图的语法**
成本图的定义如下：
- **$0$**：零成本，表示没有任何计算。
- **$1$**：单位成本，表示一个基本的计算步骤。
- **$c_1 \otimes c_2$**：并行组合，表示 $c_1$ 和 $c_2$ 是可以并行执行的计算。
- **$c_1 \oplus c_2$**：顺序组合，表示 $c_1$ 和 $c_2$ 是必须顺序执行的计算。

成本图可以用来表示**串行-并行有向无环图**(series-parallel directed acyclic graph)，其中每个图有一个源节点和一个汇节点，代表整个计算的开始和结束。

---

### **成本图的构建**

成本图的直观理解是将图中的**节点**视为子计算，**边**则表示这些计算之间的依赖关系。节点之间的边限制了计算的执行顺序，某些计算必须在其依赖的子计算完成后才能开始。

#### **图的构建规则**：
- **$0$**：一个只有一个节点的图，表示没有计算，没有边，源节点和汇节点都是该节点本身。
- **$1$**：一个简单的图，包含两个节点和一条边，表示从源节点到汇节点的一个计算步骤。
- **$c_1 \otimes c_2$**：并行组合。如果 $g_1$ 和 $g_2$ 分别是 $c_1$ 和 $c_2$ 的图，新的图有两个额外的节点：一个源节点有两条边连接到 $g_1$ 和 $g_2$ 的源节点，汇节点则有从 $g_1$ 和 $g_2$ 的汇节点连接过来的两条边，表示并行执行的计算。
- **$c_1 \oplus c_2$**：顺序组合。$g_1$ 和 $g_2$ 分别为 $c_1$ 和 $c_2$ 的图，新的图将 $g_1$ 的汇节点连接到 $g_2$ 的源节点，表示 $c_1$ 的计算必须先于 $c_2$。

---

### **工作量 (Work) 和深度 (Depth)**

成本图中定义了两个度量指标来评估程序的计算复杂度：**工作量**(work) 和 **深度**(depth)。

#### **工作量 (Work)**
工作量是整个计算中所需的**计算步骤总数**，对应于程序的顺序复杂度。工作量的递归定义如下：
$$
\text{wk}(c) =
\begin{cases}
0, & \text{if } c = 0 \\
1, & \text{if } c = 1 \\
\text{wk}(c_1) + \text{wk}(c_2), & \text{if } c = c_1 \otimes c_2 \\
\text{wk}(c_1) + \text{wk}(c_2), & \text{if } c = c_1 \oplus c_2 \\
\end{cases}
\tag{39.5}
$$

#### **深度 (Depth)**
深度是计算的**关键路径长度**(critical path length)，即最长的依赖链长度，对应于程序的并行复杂度。深度的递归定义如下：
$$
\text{dp}(c) =
\begin{cases}
0, & \text{if } c = 0 \\
1, & \text{if } c = 1 \\
\max(\text{dp}(c_1), \text{dp}(c_2)), & \text{if } c = c_1 \otimes c_2 \\
\text{dp}(c_1) + \text{dp}(c_2), & \text{if } c = c_1 \oplus c_2 \\
\end{cases}
\tag{39.6}
$$

#### **公式解释**：

- **工作量 $\text{wk}(c)$**：表示整个计算中的总工作步骤数。对于并行组合 $c_1 \otimes c_2$，工作量等于两个子计算的工作量之和；对于顺序组合 $c_1 \oplus c_2$，也是两个子计算的工作量之和。
  
- **深度 $\text{dp}(c)$**：表示关键路径的长度。对于并行组合 $c_1 \otimes c_2$，深度取 $c_1$ 和 $c_2$ 的最大深度；对于顺序组合 $c_1 \oplus c_2$，深度是 $c_1$ 和 $c_2$ 的深度之和。

---

### **工作量与深度的直观理解**

- **工作量**：工作量是计算的总体成本，表示所有计算步骤的总和。它衡量了在**顺序执行**情况下，程序需要多少时间完成所有的计算。因此，工作量是程序的**顺序复杂度**。
  
- **深度**：深度表示程序中最长的依赖链，它衡量了在**并行执行**时的最低时间限度。即使我们有无限的并行资源，深度决定了程序的最短完成时间。因此，深度是程序的**并行复杂度**。

---

### **成本图的实际应用**

**成本图**可以帮助程序员评估程序的并行效率：
- **工作量 (work)**：表示程序的总工作量，无论有多少处理器，计算这些任务都需要完成。高工作量意味着程序总体上复杂度较高。
- **深度 (depth)**：表示程序的最小完成时间，即使有无限多的处理器，也无法将时间缩短到比深度更低。较低的深度意味着程序并行化的潜力较大。

通过分析工作量和深度，可以估计程序在并行计算中的表现。例如，一个工作量很高但深度很低的程序可以利用并行性大幅提升速度，而一个深度很高的程序则会受到并行性的限制，因为某些计算必须顺序进行。

---

### **总结**

在并行计算中，成本动态通过**工作量**和**深度**两个指标来评估程序的计算复杂度：
- **工作量**衡量了程序的总计算步骤数，对应顺序复杂度。
- **深度**衡量了程序的关键路径长度，对应并行复杂度。

通过这些指标，程序员可以设计出更高效的并行算法，充分利用现代多处理器系统的计算能力。

### ---------------------------------

### 39.2 成本动态中的时间复杂度 (Cost Dynamics for Time Complexity)

在第 7 章中，我们引入了**成本动态**(cost dynamics) 作为评估计算时间复杂度的手段。定理 7.7 的证明表明，如果 $e \Downarrow_k v$，即 $e$ 经过 $k$ 步求值得到结果 $v$，则这等价于 $e \rightarrow_k v$，也就是说，$e$ 到 $v$ 的评估复杂度等于从 $e$ 到 $v$ 的转移步骤数。在本节中，我们通过**成本图**(cost graphs) 来衡量复杂度，并将这些成本图与第 39.1 节中的结构动态联系起来。

### **成本动态的判断**
**成本动态**的判断形式为：
$$
e \Downarrow_c v,
$$
其中 $e$ 是闭合表达式，$v$ 是闭合值，$c$ 是成本图，表示在给定的成本下，$e$ 求值为 $v$。

#### **零成本的判断**
如果 $e$ 是一个值 $v$，那么成本为零，即：
$$
e \Downarrow_0 v \quad \text{if} \ e \ \text{val}.
$$

### **并行 let 构造的成本分配**

在并行 `let` 构造中，我们需要同时求值两个表达式 $e_1$ 和 $e_2$，然后将它们的值绑定到变量 $x_1$ 和 $x_2$ 中，继续计算表达式 $e$。成本分配规则如下：
$$
e_1 \Downarrow_{c_1} v_1 \quad e_2 \Downarrow_{c_2} v_2 \quad [v_1, v_2 / x_1, x_2]e \Downarrow_c v \quad \Rightarrow \quad \text{par}(e_1; e_2; x_1.x_2.e) \Downarrow_{(c_1 \otimes c_2) \oplus 1 \oplus c} v
\tag{39.7}
$$

### **公式解析**

#### **并行组合 $\otimes$**
- **$c_1 \otimes c_2$**：表示 $e_1$ 和 $e_2$ 是可以并行计算的，整个计算的总成本为两个子计算的**并行组合**。并行组合意味着 $e_1$ 和 $e_2$ 可以同时开始，并且没有相互依赖关系。
  
#### **顺序组合 $\oplus$**
- **$(c_1 \otimes c_2) \oplus 1 \oplus c$**：整个并行计算的总成本不仅包括并行执行的 $e_1$ 和 $e_2$ 的成本，还需要考虑将它们的结果合并并继续计算表达式 $e$ 的成本。这里的 $\oplus 1$ 代表将 $e_1$ 和 $e_2$ 的值替换到 $e$ 中的成本（常数时间替换），$c$ 表示继续求值 $e$ 的成本。

#### **解释**：
1. **$e_1 \Downarrow_{c_1} v_1$ 和 $e_2 \Downarrow_{c_2} v_2$**：表示 $e_1$ 和 $e_2$ 分别求值为 $v_1$ 和 $v_2$，其对应的成本为 $c_1$ 和 $c_2$。
2. **$[v_1, v_2 / x_1, x_2]e \Downarrow_c v$**：表示在将 $v_1$ 和 $v_2$ 分别替换到 $e$ 中的 $x_1$ 和 $x_2$ 后，继续求值表达式 $e$，最终得到结果 $v$，成本为 $c$。
3. **并行成本 $(c_1 \otimes c_2) \oplus 1 \oplus c$**：总成本包括 $e_1$ 和 $e_2$ 的并行求值成本，常数时间替换的成本 1，以及后续表达式 $e$ 的求值成本 $c$。

---

### **成本分配的特点**

#### **隐式的分叉和连接成本**
并行计算的分叉和连接（即 fork 和 join）的成本在成本图中是隐含的。分叉表示开始两个独立计算，连接表示在两个并行计算完成后合并结果。这里我们假设分叉和连接的成本为常数（即 $\oplus 1$），因为在实际实现中，分叉和连接通常是常数时间的操作。

#### **替换的单位成本**
在求值完成后，将结果 $v_1$ 和 $v_2$ 绑定到变量 $x_1$ 和 $x_2$ 的替换操作被分配了单位成本 ($1$)。这种替换操作通常通过一种常数时间的机制来实现，例如更新环境或内存中的变量。

---

### **语言其他构造的成本动态**

对于语言中的其他构造，其成本动态的定义类似于并行 `let` 构造，但只使用**顺序组合**($\oplus$) 来确保源自 `let` 构造的并行性可以被孤立出来。这意味着，除了并行 `let` 外，所有其他构造都是顺序执行的。

---

### **两个简单事实**

在讨论成本动态时，重要的有两个简单事实：

1. **成本分配不影响结果**：
   成本动态中分配的成本图只用于衡量计算的复杂度，不会改变程序的求值结果。程序的语义保持不变，唯一不同的是我们可以通过成本图来分析计算的时间复杂度。

2. **工作量和深度的影响**：
   成本图中的**工作量**和**深度**直接决定了程序的顺序和并行复杂度。工作量代表了程序中所有计算步骤的总和，而深度代表了程序中最长的依赖链。

---

### **总结**

成本动态为程序的并行执行提供了一种形式化的分析手段，通过构建**成本图**，我们可以清楚地量化程序的**工作量**(work) 和 **深度**(depth)。并行 `let` 构造的成本分配规则展示了如何同时执行多个子表达式，并将其结果合并到主表达式中。总之，成本动态不改变程序的求值结果，只是为并行程序的时间复杂度分析提供了工具。

### ---------------------------------

### 引理 39.4：$e \Downarrow v \iff e \Downarrow_c v$ 对某个 $c$ 成立

**证明思路**：这个引理的核心是证明带有成本图 ($c$) 的求值和没有成本的求值之间是等价的。

#### **从右到左**：
假设 $e \Downarrow_c v$，即表达式 $e$ 可以在某个成本图 $c$ 下求值为 $v$。我们可以通过**去掉成本图的标记**，得到没有成本的求值派生过程。因此，$e \Downarrow v$。

#### **从左到右**：
假设 $e \Downarrow v$，即 $e$ 在没有成本的情况下求值为 $v$。我们可以通过根据成本动态的规则，为求值派生过程**添加成本图的标记**，从而得到 $e \Downarrow_c v$。成本图的分配是由成本动态规则决定的。

因此，$e \Downarrow v \iff e \Downarrow_c v$ 成立。

---

### 引理 39.5：**唯一性**——如果 $e \Downarrow_c v$ 且 $e \Downarrow_{c'} v$，那么 $c = c'$

**证明思路**：这表明对于给定的表达式 $e$ 和结果 $v$，其求值的成本图是唯一的。为了证明这一点，我们使用**归纳法**(induction) 对 $e \Downarrow_c v$ 的推导进行分析。

#### **基本情况**：
- 当 $e$ 是一个值时，成本为零，即 $e \Downarrow_0 v$。在这种情况下，唯一的成本图是 $c = 0$，显然 $c = c'$。

#### **归纳步骤**：
- 对于复杂的表达式，例如并行 `let` 构造，根据成本动态规则，$e_1$ 和 $e_2$ 分别有其独立的成本图 $c_1$ 和 $c_2$。通过归纳假设，我们知道这些子表达式的成本图是唯一的，因此整个表达式的成本图也是唯一的。
- 在每一步计算中，成本的分配是根据固定规则进行的，因此不存在两种不同的成本图能同时对应相同的求值过程。

因此，如果 $e \Downarrow_c v$ 且 $e \Downarrow_{c'} v$，那么必定有 $c = c'$。

---

### 定理：**工作量和深度成本的关系**

这个定理建立了**成本动态**和**结构动态**之间的联系，表明：

1. **工作量**(work cost) 对应于程序的**顺序复杂度**，即在顺序执行时计算所需的总时间。
2. **深度成本**(depth cost) 对应于程序的**并行复杂度**，即在并行执行时，最短的关键路径长度。

换句话说，**工作量**表示在顺序执行时程序所需的计算步骤总数，而**深度**表示即使有无限并行资源时，程序必须顺序执行的部分。这一结论帮助我们理解并行计算中的性能瓶颈。

#### **公式说明**：
- 工作量 $W$ 和深度 $D$ 是通过成本图的构建规则（并行组合 $\otimes$ 和顺序组合 $\oplus$）计算得出的。
- 在一个理想的并行系统中，程序的最短完成时间由**深度**决定，而如果我们只能顺序执行，所需时间则由**工作量**决定。

### 总结：
- **引理 39.4** 证明了带成本图的求值和不带成本图的求值是等价的。
- **引理 39.5** 证明了成本图是唯一的。
- 最后，定理阐述了工作量和深度与程序的顺序和并行复杂度的对应关系，明确了在并行计算中，如何通过成本图评估程序的性能。

### ---------------------------------

### 定理 39.6：工作量和深度的关系

**定理内容**：
- 如果 $e \Downarrow_c v$，那么 $e \rightarrow_w^{\text{seq}} v$ 且 $e \rightarrow_d^{\text{par}} v$，其中 $w = \text{wk}(c)$ 和 $d = \text{dp}(c)$。  
- 反之，如果 $e \rightarrow_w^{\text{seq}} v$，那么存在 $c$ 使得 $e \Downarrow_c v$ 且 $\text{wk}(c) = w$；如果 $e \rightarrow_d^{\text{par}} v'$，那么存在 $c'$ 使得 $e \Downarrow_{c'} v'$ 且 $\text{dp}(c') = d$。

#### **公式解释**：
- $e \Downarrow_c v$：表示表达式 $e$ 以成本图 $c$ 求值为结果 $v$。
- $e \rightarrow_w^{\text{seq}} v$：表示表达式 $e$ 在顺序执行时以 $w$ 步求值为结果 $v$，其中 $w$ 是工作量。
- $e \rightarrow_d^{\text{par}} v$：表示表达式 $e$ 在并行执行时以 $d$ 步求值为结果 $v$，其中 $d$ 是深度。

#### **工作量**($\text{wk}(c)$)：指的是整个计算所需的总步骤数，代表**顺序复杂度**。

#### **深度**($\text{dp}(c)$)：表示计算中的**关键路径**的长度，即在并行计算中，必须顺序执行的部分的长度，代表**并行复杂度**。

### **证明思路**

#### **第一部分：从 $e \Downarrow_c v$ 推导出 $e \rightarrow_w^{\text{seq}} v$ 和 $e \rightarrow_d^{\text{par}} v$**

我们使用归纳法对 $e \Downarrow_c v$ 的推导进行归纳，其中有趣的情况是并行构造的成本分配（规则 39.7）：

- **顺序复杂度**：  
  通过归纳假设，$e_1 \rightarrow_{w_1}^{\text{seq}} v_1$，$e_2 \rightarrow_{w_2}^{\text{seq}} v_2$，并且 $[v_1, v_2 / x_1, x_2]e \rightarrow_w^{\text{seq}} v$，其中 $w_1 = \text{wk}(c_1)$，$w_2 = \text{wk}(c_2)$，$w = \text{wk}(c)$。通过将这些推导组合在一起，我们得到：
  $$
  \text{par}(e_1; e_2; x_1.x_2.e) \rightarrow_{w_1}^{\text{seq}} \text{par}(v_1; e_2; x_1.x_2.e) \rightarrow_{w_2}^{\text{seq}} \text{par}(v_1; v_2; x_1.x_2.e) \rightarrow^{\text{seq}} [v_1, v_2 / x_1, x_2]e \rightarrow_w^{\text{seq}} v
  $$

  注意到 $\text{wk}((c_1 \otimes c_2) \oplus 1 \oplus c) = w_1 + w_2 + 1 + w$，这完成了证明。

- **并行复杂度**：  
  通过归纳假设，$e_1 \rightarrow_{d_1}^{\text{par}} v_1$，$e_2 \rightarrow_{d_2}^{\text{par}} v_2$，并且 $e \rightarrow_d^{\text{par}} v$，其中 $d_1 = \text{dp}(c_1)$，$d_2 = \text{dp}(c_2)$，$d = \text{dp}(c)$。假设 $d_1 \leq d_2$（否则可以对 $d_1$ 和 $d_2$ 进行交换），我们可以将推导组合如下：
  $$
  \text{par}(e_1; e_2; x_1.x_2.e) \rightarrow_{d_1}^{\text{par}} \text{par}(v_1; e_2'; x_1.x_2.e) \rightarrow_{d_2 - d_1}^{\text{par}} \text{par}(v_1; v_2; x_1.x_2.e) \rightarrow^{\text{par}} [v_1, v_2 / x_1, x_2]e \rightarrow_d^{\text{par}} v
  $$

  计算 $\text{dp}((c_1 \otimes c_2) \oplus 1 \oplus c) = \max(d_1, d_2) + 1 + d$，这完成了证明。

#### **第二部分：从 $e \rightarrow_w^{\text{seq}} v$ 和 $e \rightarrow_d^{\text{par}} v$ 推导出 $e \Downarrow_c v$**

- **顺序复杂度的推导**：  
  我们需要证明，如果 $e \rightarrow_{\text{seq}} e_0$，并且 $e_0 \Downarrow_{c_0} v$，那么 $e \Downarrow_c v$，其中 $\text{wk}(c) = \text{wk}(c_0) + 1$。假设 $e = \text{par}(e_1; e_2; x_1.x_2.e_0)$，其中 $e_1$ 和 $e_2$ 是值。那么 $e \rightarrow_{\text{seq}} e_0$，并且存在 $c_0$ 使得 $e_0 \Downarrow_{c_0} v$。因此，$e \Downarrow_c v$，其中 $c = (0 \otimes 0) \oplus 1 \oplus c_0$，并且 $\text{wk}(c) = \text{wk}(c_0) + 1$。

- **并行复杂度的推导**：  
  类似的，如果 $e \rightarrow_{\text{par}} e_0$，我们可以推导出 $e \Downarrow_c v$，其中 $\text{dp}(c) = \text{dp}(c_0) + 1$。

### 归纳步骤：

- 对于 $e_1$ 和 $e_2$，我们可以通过分别对 $e_1 \rightarrow_{\text{seq}} e_1'$ 和 $e_2 \rightarrow_{\text{par}} e_2'$ 进行处理，得到相应的工作量和深度。
- 通过组合这两个子计算的推导，我们可以递归地构建整个表达式 $e$ 的工作量和深度。

### **结论：**

定理 39.6 证明了**工作量**和**深度**如何通过成本图反映程序的顺序复杂度和并行复杂度。通过分析成本图的工作量 ($\text{wk}(c)$) 和深度 ($\text{dp}(c)$)，我们可以推导出程序在顺序执行和并行执行时的复杂度。这为并行程序设计提供了理论依据，帮助我们在设计和优化并行程序时，评估其执行效率。

### ---------------------------------

### 定理 39.6 详解：工作量和深度的关系

**定理内容**：

- 如果 $e \Downarrow_c v$，则 $e \rightarrow_w^{\text{seq}} v$ 并且 $e \rightarrow_d^{\text{par}} v$，其中 $w = \text{wk}(c)$，$d = \text{dp}(c)$。
- 反过来，如果 $e \rightarrow_w^{\text{seq}} v$，则存在 $c$ 使得 $e \Downarrow_c v$ 并且 $\text{wk}(c) = w$；如果 $e \rightarrow_d^{\text{par}} v'$，则存在 $c'$ 使得 $e \Downarrow_{c'} v'$ 并且 $\text{dp}(c') = d$。

#### **公式符号详解**：
- **$e \Downarrow_c v$**：表示表达式 $e$ 通过成本图 $c$ 求值为 $v$。
- **$e \rightarrow_w^{\text{seq}} v$**：表示表达式 $e$ 在顺序执行时以 $w$ 步求值为结果 $v$，$w$ 代表**工作量**。
- **$e \rightarrow_d^{\text{par}} v$**：表示表达式 $e$ 在并行执行时以 $d$ 步求值为结果 $v$，$d$ 代表**深度**。

#### **工作量**($\text{wk}(c)$)：表示整个计算过程中的总步骤数，对应于程序的**顺序复杂度**。

#### **深度**($\text{dp}(c)$)：表示计算中的最长依赖链长度，也就是需要顺序执行的部分，决定了程序的**并行复杂度**。

### 证明详解

#### **第一部分：从 $e \Downarrow_c v$ 推导出 $e \rightarrow_w^{\text{seq}} v$ 和 $e \rightarrow_d^{\text{par}} v$**

我们通过**归纳法**对 $e \Downarrow_c v$ 的推导进行归纳，其中比较复杂的情况是并行构造的成本分配规则 (39.7)。

##### 1. **顺序复杂度** (Sequential Complexity)

通过归纳假设，我们得到：
- $e_1 \rightarrow_{w_1}^{\text{seq}} v_1$
- $e_2 \rightarrow_{w_2}^{\text{seq}} v_2$
- $[v_1, v_2 / x_1, x_2] e \rightarrow_w^{\text{seq}} v$

其中 $w_1 = \text{wk}(c_1)$，$w_2 = \text{wk}(c_2)$，$w = \text{wk}(c)$。通过组合这些推导，我们得到完整的求值过程：
$$
\text{par}(e_1; e_2; x_1.x_2.e) \rightarrow_{w_1}^{\text{seq}} \text{par}(v_1; e_2; x_1.x_2.e) \rightarrow_{w_2}^{\text{seq}} \text{par}(v_1; v_2; x_1.x_2.e) \rightarrow^{\text{seq}} [v_1, v_2 / x_1, x_2]e \rightarrow_w^{\text{seq}} v
$$

注意：我们需要验证 $\text{wk}((c_1 \otimes c_2) \oplus 1 \oplus c) = w_1 + w_2 + 1 + w$。

##### 2. **并行复杂度** (Parallel Complexity)

通过归纳假设，我们得到：
- $e_1 \rightarrow_{d_1}^{\text{par}} v_1$
- $e_2 \rightarrow_{d_2}^{\text{par}} v_2$
- $e \rightarrow_d^{\text{par}} v$

其中 $d_1 = \text{dp}(c_1)$，$d_2 = \text{dp}(c_2)$，$d = \text{dp}(c)$。假设 $d_1 \leq d_2$，则我们可以组合推导过程如下：
$$
\text{par}(e_1; e_2; x_1.x_2.e) \rightarrow_{d_1}^{\text{par}} \text{par}(v_1; e_2'; x_1.x_2.e) \rightarrow_{d_2 - d_1}^{\text{par}} \text{par}(v_1; v_2; x_1.x_2.e) \rightarrow^{\text{par}} [v_1, v_2 / x_1, x_2]e \rightarrow_d^{\text{par}} v
$$

计算 $\text{dp}((c_1 \otimes c_2) \oplus 1 \oplus c)$：
$$
\text{dp}((c_1 \otimes c_2) \oplus 1 \oplus c) = \max(d_1, d_2) + 1 + d
$$

#### **第二部分：从 $e \rightarrow_w^{\text{seq}} v$ 和 $e \rightarrow_d^{\text{par}} v$ 推导出 $e \Downarrow_c v$**

##### 1. **顺序求值的推导** (Sequential Evaluation)

我们需要证明：
- 如果 $e \rightarrow_{\text{seq}} e_0$ 且 $e_0 \Downarrow_{c_0} v$，那么 $e \Downarrow_c v$ 并且 $\text{wk}(c) = \text{wk}(c_0) + 1$。

假设 $e = \text{par}(e_1; e_2; x_1.x_2.e_0)$ 且 $e_1$ 和 $e_2$ 是值。则 $e \rightarrow_{\text{seq}} e_0$，并且存在 $c_0$ 使得 $e_0 \Downarrow_{c_0} v$。因此 $e \Downarrow_c v$，其中 $c = (0 \otimes 0) \oplus 1 \oplus c_0$，并且 $\text{wk}(c) = \text{wk}(c_0) + 1$。

##### 2. **并行求值的推导** (Parallel Evaluation)

类似地，如果 $e \rightarrow_{\text{par}} e_0$，我们可以推导出 $e \Downarrow_c v$，其中 $\text{dp}(c) = \text{dp}(c_0) + 1$。

---

### 推导过程详解

##### **工作量推导**：

假设 $e = \text{par}(e_1; e_2; x_1.x_2.e_0)$ 且 $e_1 \rightarrow_{\text{seq}} e_1'$。通过对 $e_1$ 的推导，我们有：
- $e_1 \Downarrow_{c_1} v_1$
- $e_2 \Downarrow_{c_2} v_2$
- $[v_1, v_2 / x_1, x_2] e_0 \Downarrow_{c_0} v$

因此，整个表达式 $e$ 的成本图为 $c = (c_1 \otimes c_2) \oplus 1 \oplus c_0$，并且 $\text{wk}(c) = \text{wk}(c_1) + \text{wk}(c_2) + 1 + \text{wk}(c_0)$。

##### **深度推导**：

对于并行动态，假设 $e = \text{par}(e_1; e_2; x_1.x_2.e_0)$ 且 $e_1 \rightarrow_{\text{par}} e_1'$，则：
- $e_1 \Downarrow_{c_1} v_1$ 且 $\text{dp}(c_1) = 1 + \text{dp}(c_0)$
- $e_2 \Downarrow_{c_2} v_2$ 且 $\text{dp}(c_2) = 1 + \text{dp}(c_0)$

通过计算，我们得到整个表达式的深度：
$$
\text{dp}(c) = \max(\text{dp}(c_1), \text{dp}(c_2)) + 1 + \text{dp}(c_0)
$$

---

### 推论 39.7 详解

**推论 39.7**：如果 $e \rightarrow_w^{\text{seq}} v$ 且 $e \rightarrow_d^{\text{par}} v'$，那么 $v = v'$，并且 $e \Downarrow_c v$，其中 $\text{wk}(c) = w$ 且 $\text{dp}(c) = d$。

#### **总结**：

- 定理

 39.6 和推论 39.7 证明了通过成本图，可以统一分析程序的**顺序复杂度**和**并行复杂度**。成本图中的**工作量**反映了顺序执行的总步骤，而**深度**反映了并行执行时的关键路径长度。

### ---------------------------------

### 39.3 多分支并行（Multiple Fork-Join）

到目前为止，我们讨论的并行模型主要基于**二元的分支/合并**（binary fork/join），也就是通过二元的并行 `let` 构造实现的并行计算。这种模式虽然在很多情况下足够，但并不总是最自然的编程模型。更自然的模型允许同时生成**任意数量的并行任务**，而不是通过二元的级联分支和对应的合并来实现。这种模型通常被称为**数据并行**（data parallelism），其并行性来源于数据结构本身，尤其是具有不定大小的数据结构。

#### **数据并行的基本思想**：
数据并行性允许对具有**无限大小**的数据结构进行并行操作。一个典型的例子是**序列**（sequence），即指定类型的一组值。我们可以通过并行地对序列中的每个元素同时应用某个函数来实现数据并行。

#### **主要的操作**：
为说明这些概念，我们讨论一个简单的序列操作语言。其语法和主要操作如下：

#### **类型定义**：
$$
\text{Typ} \ \tau ::= \text{seq}(\tau) \quad \text{sequence of type } \tau
$$

- **$\text{seq}(\tau)$**：定义序列类型，表示由 $\tau$ 类型的元素组成的序列。

#### **表达式定义**：
$$
\text{Exp} \ e ::= \text{seq}(e_0, \dots, e_{n-1}) \quad \text{sequence of expressions} \ e_0, \dots, e_{n-1}
$$

##### **序列操作**：
1. **长度操作**：
   - **$\text{len}(e)$**：计算并返回序列 $e$ 的长度。
     - 例如，$\text{len}(\text{seq}(1, 2, 3))$ 返回 $3$。

2. **子元素提取**：
   - **$\text{sub}(e_1; e_2)$**：从序列 $e_1$ 中提取索引为 $e_2$ 的元素。
     - 例如，$\text{sub}(\text{seq}(1, 2, 3); 1)$ 返回 $2$，即提取索引为 $1$ 的元素。

3. **构造表操作（tabulate）**：
   - **$\text{tab}(x.e_1; e_2)$**：生成一个长度为 $e_2$ 的序列，其中第 $i$ 个元素通过将 $i$ 替换到 $x$ 中得到 $[i/x]e_1$。
     - 例如，$\text{tab}(x.x^2; 4)$ 生成序列 $\text{seq}(0, 1, 4, 9)$。

4. **映射操作（map）**：
   - **$\text{map}(x.e_1; e_2)$**：对序列 $e_2$ 的每个元素并行应用表达式 $e_1$，生成一个新序列，其中第 $i$ 个元素通过将 $e_2$ 中第 $i$ 个元素替换到 $x$ 中得到 $[e_i/x]e_1$。
     - 例如，$\text{map}(x.2x; \text{seq}(1, 2, 3))$ 返回 $\text{seq}(2, 4, 6)$。

5. **串联操作（concatenate）**：
   - **$\text{cat}(e_1; e_2)$**：将两个相同类型的序列 $e_1$ 和 $e_2$ 串联起来，生成一个新序列。
     - 例如，$\text{cat}(\text{seq}(1, 2); \text{seq}(3, 4))$ 返回 $\text{seq}(1, 2, 3, 4)$。

---

### **数据并行的动态**

通过这些操作，我们可以看到数据并行性的源头是对序列元素的操作。特别是**map** 和 **tabulate** 操作，它们允许我们并行地处理序列中的每个元素，而这些操作之间没有顺序依赖关系。因此，这种结构提供了**任意数量的并行任务**，而不仅仅是通过二元的并行分支和合并实现。

#### **并行 map 的优势**：
- **map** 操作是数据并行的核心，它允许我们对序列的每个元素同时进行操作，这是一种天然的并行形式。通过并行 map 操作，我们可以高效地对大规模数据集进行处理。

#### **多分支并行和二元并行的区别**：
- 在二元并行中，我们需要通过层层分支将并行任务分解成二元的任务链，而多分支并行则允许我们一次性生成任意数量的并行任务。这种模型在处理大规模数据结构时更加自然和高效，特别是在需要对所有数据元素进行操作的场景中。

---

### **总结**

在多分支并行模型中，计算的并行性来源于数据结构的大小，尤其是序列。我们通过**map** 和 **tabulate** 等操作，能够实现对序列元素的并行操作，生成任意数量的并行任务，而无需通过层层的二元分支来构造并行性。这种模型非常适合大规模数据处理的场景，比如矩阵运算、图像处理等。

### ---------------------------------

### 39.3 多分支并行中的静态规则 (Statics of Multiple Fork-Join)

在并行计算中，静态规则用于验证程序的类型正确性，确保在计算过程中，每个操作的输入和输出类型匹配。这里，我们为每个序列操作给出了相应的**类型规则**，并通过这些规则确保程序的静态正确性。

#### **静态规则的解释**

#### 1. **序列构造** (Sequence Construction)
$$
\Gamma \vdash e_0 : \tau \dots \Gamma \vdash e_{n-1} : \tau \quad \Rightarrow \quad \Gamma \vdash \text{seq}(e_0, \dots, e_{n-1}) : \text{seq}(\tau) \tag{39.8a}
$$

- **解释**：如果每个元素 $e_0, e_1, \dots, e_{n-1}$ 的类型都是 $\tau$，则它们组成的序列 $\text{seq}(e_0, \dots, e_{n-1})$ 的类型为 $\text{seq}(\tau)$，表示由类型 $\tau$ 的元素构成的序列。

#### 2. **长度操作** (Length Operation)
$$
\Gamma \vdash e : \text{seq}(\tau) \quad \Rightarrow \quad \Gamma \vdash \text{len}(e) : \text{nat} \tag{39.8b}
$$

- **解释**：如果 $e$ 是一个类型为 $\text{seq}(\tau)$ 的序列，则 $\text{len}(e)$ 返回该序列的长度，类型为 $\text{nat}$（自然数）。

#### 3. **元素提取** (Element Extraction)
$$
\Gamma \vdash e_1 : \text{seq}(\tau) \quad \Gamma \vdash e_2 : \text{nat} \quad \Rightarrow \quad \Gamma \vdash \text{sub}(e_1; e_2) : \tau \tag{39.8c}
$$

- **解释**：如果 $e_1$ 是类型为 $\text{seq}(\tau)$ 的序列，$e_2$ 是索引，类型为 $\text{nat}$，则 $\text{sub}(e_1; e_2)$ 提取索引为 $e_2$ 的元素，其类型为 $\tau$。

#### 4. **表操作** (Tabulate Operation)
$$
\Gamma, x : \text{nat} \vdash e_1 : \tau \quad \Gamma \vdash e_2 : \text{nat} \quad \Rightarrow \quad \Gamma \vdash \text{tab}(x.e_1; e_2) : \text{seq}(\tau) \tag{39.8d}
$$

- **解释**：如果在上下文 $\Gamma$ 中，变量 $x$ 的类型为 $\text{nat}$，$e_1$ 的类型为 $\tau$，$e_2$ 的类型为 $\text{nat}$，则 $\text{tab}(x.e_1; e_2)$ 返回一个长度为 $e_2$ 的序列，其中每个元素通过替换索引 $x$ 到 $e_1$ 中得到，类型为 $\text{seq}(\tau)$。

#### 5. **映射操作** (Map Operation)
$$
\Gamma \vdash e_2 : \text{seq}(\tau) \quad \Gamma, x : \tau \vdash e_1 : \tau' \quad \Rightarrow \quad \Gamma \vdash \text{map}(x.e_1; e_2) : \text{seq}(\tau') \tag{39.8e}
$$

- **解释**：如果 $e_2$ 是类型为 $\text{seq}(\tau)$ 的序列，且在上下文 $\Gamma$ 中，$x$ 的类型为 $\tau$，$e_1$ 的类型为 $\tau'$，则 $\text{map}(x.e_1; e_2)$ 返回一个序列，其中每个元素通过将 $e_2$ 中的元素替换到 $e_1$ 中求值，其结果为 $\text{seq}(\tau')$。

#### 6. **串联操作** (Concatenation)
$$
\Gamma \vdash e_1 : \text{seq}(\tau) \quad \Gamma \vdash e_2 : \text{seq}(\tau) \quad \Rightarrow \quad \Gamma \vdash \text{cat}(e_1; e_2) : \text{seq}(\tau) \tag{39.8f}
$$

- **解释**：如果 $e_1$ 和 $e_2$ 均为类型 $\text{seq}(\tau)$ 的序列，则 $\text{cat}(e_1; e_2)$ 返回将这两个序列连接起来的新序列，类型为 $\text{seq}(\tau)$。

---

### **公式符号详解**

- **$\Gamma$**：表示类型上下文，包含变量及其对应的类型信息。
- **$e_1, e_2, \dots, e_n$**：表示表达式。
- **$\tau$**：表示类型，如 $\text{nat}$ 表示自然数类型，$\text{seq}(\tau)$ 表示由类型为 $\tau$ 的元素组成的序列。
- **$x$**：是变量，用于表达式中的占位符。
- **$\vdash$**：表示类型推导的符号，左边是输入表达式及其类型，右边是输出的推导结果。

---

### **总结**

这些静态规则确保每个序列操作在执行时是类型安全的。通过这些规则，我们可以推导出表达式的类型，并保证程序不会因为类型不匹配而导致运行时错误。这些操作展示了如何在并行计算中使用数据并行模型进行序列操作，并通过静态类型系统确保其正确性。

### ---------------------------------

### 39.3 成本动态规则详解 (Cost Dynamics of Sequence Constructs)

这些成本动态规则定义了序列操作的求值成本，明确了每个操作的计算步骤及其对应的工作量和深度。我们将详细解释每个操作的成本动态，并解析公式中的符号和操作。

---

#### **规则 39.9a：序列构造的成本动态**
$$
e_0 \Downarrow_{c_0} v_0, \dots, e_{n-1} \Downarrow_{c_{n-1}} v_{n-1} \quad \Rightarrow \quad \text{seq}(e_0, \dots, e_{n-1}) \Downarrow_{\bigoplus_{i=0}^{n-1} c_i} \text{seq}(v_0, \dots, v_{n-1})
\tag{39.9a}
$$

- **解释**：每个表达式 $e_0, e_1, \dots, e_{n-1}$ 分别以成本 $c_0, c_1, \dots, c_{n-1}$ 求值为 $v_0, v_1, \dots, v_{n-1}$。整个序列的求值成本是各个子表达式的成本总和，即 $\bigoplus_{i=0}^{n-1} c_i$。
  - **成本计算**：将所有子表达式的成本累加，构造的序列成本是这些子表达式成本的和。

---

#### **规则 39.9b：长度操作的成本动态**
$$
e \Downarrow_c \text{seq}(v_0, \dots, v_{n-1}) \quad \Rightarrow \quad \text{len}(e) \Downarrow_{c \oplus 1} \text{num}[n]
\tag{39.9b}
$$

- **解释**：对序列 $e$ 求长度时，首先对 $e$ 进行求值，其成本为 $c$。计算长度的操作是常数时间操作，因此成本为 $1$，总成本为 $c \oplus 1$。
  - **长度的成本**：计算长度本身只需要一步操作，因此在原始求值成本 $c$ 上加 $1$。

---

#### **规则 39.9c：元素提取的成本动态**
$$
e_1 \Downarrow_{c_1} \text{seq}(v_0, \dots, v_{n-1}), \ e_2 \Downarrow_{c_2} \text{num}[i] \ (0 \leq i < n) \quad \Rightarrow \quad \text{sub}(e_1; e_2) \Downarrow_{c_1 \oplus c_2 \oplus 1} v_i
\tag{39.9c}
$$

- **解释**：从序列 $e_1$ 中提取索引为 $e_2$ 的元素。首先 $e_1$ 和 $e_2$ 的求值成本分别为 $c_1$ 和 $c_2$。提取元素的操作是常数时间操作，成本为 $1$，总成本为 $c_1 \oplus c_2 \oplus 1$。
  - **提取成本**：首先需要对序列和索引求值，然后执行常数时间的提取操作。

---

#### **规则 39.9d：表操作的成本动态**
$$
e_2 \Downarrow_{c} \text{num}[n], \quad [\text{num}[0]/x]e_1 \Downarrow_{c_0} v_0, \dots, [\text{num}[n-1]/x]e_1 \Downarrow_{c_{n-1}} v_{n-1} \quad \Rightarrow \quad \text{tab}(x.e_1; e_2) \Downarrow_{c \oplus \bigoplus_{i=0}^{n-1} c_i} \text{seq}(v_0, \dots, v_{n-1})
\tag{39.9d}
$$

- **解释**：表操作根据索引生成序列。首先对长度 $e_2$ 求值，成本为 $c$。接下来，对于每个索引 $0, 1, \dots, n-1$，分别求值 $[\text{num}[i]/x]e_1$，其成本为 $c_i$。总成本为 $c \oplus \bigoplus_{i=0}^{n-1} c_i$。
  - **表操作的成本**：首先求值序列的长度，然后逐个求值每个元素的表达式。

---

#### **规则 39.9e：映射操作的成本动态**
$$
e_2 \Downarrow_c \text{seq}(v_0, \dots, v_{n-1}), \quad [v_0/x]e_1 \Downarrow_{c_0} v'_0, \dots, [v_{n-1}/x]e_1 \Downarrow_{c_{n-1}} v'_{n-1} \quad \Rightarrow \quad \text{map}(x.e_1; e_2) \Downarrow_{c \oplus \bigoplus_{i=0}^{n-1} c_i} \text{seq}(v'_0, \dots, v'_{n-1})
\tag{39.9e}
$$

- **解释**：映射操作对序列的每个元素应用函数 $e_1$。首先对 $e_2$ 求值为序列，其成本为 $c$。接下来对每个元素 $v_0, \dots, v_{n-1}$，分别求值 $[v_i / x]e_1$，其成本为 $c_i$。总成本为 $c \oplus \bigoplus_{i=0}^{n-1} c_i$。
  - **映射的成本**：对序列求值后，对每个元素应用函数并求值。

---

#### **规则 39.9f：串联操作的成本动态**
$$
e_1 \Downarrow_{c_1} \text{seq}(v_0, \dots, v_{m-1}), \quad e_2 \Downarrow_{c_2} \text{seq}(v'_0, \dots, v'_{n-1}) \quad \Rightarrow \quad \text{cat}(e_1; e_2) \Downarrow_{c_1 \oplus c_2 \oplus \bigoplus_{i=0}^{m+n-1} 1} \text{seq}(v_0, \dots, v_{m-1}, v'_0, \dots, v'_{n-1})
\tag{39.9f}
$$

- **解释**：串联操作将两个序列连接在一起。首先分别对 $e_1$ 和 $e_2$ 求值，成本为 $c_1$ 和 $c_2$。然后将它们连接起来，每个元素的连接成本为常数 $1$，因此连接的成本为 $\bigoplus_{i=0}^{m+n-1} 1$。总成本为 $c_1 \oplus c_2 \oplus \bigoplus_{i=0}^{m+n-1} 1$。
  - **串联的成本**：先对两个序列求值，再逐个连接每个元素。

---

### **成本动态的总结**

这些规则定义了序列操作的成本动态，并通过累加每个子操作的成本来计算整个表达式的总成本。通过这些公式，我们可以精确评估每个操作的工作量和深度，进而推导程序的**顺序复杂度**和**并行复杂度**。

### ---------------------------------

### 39.4 可证明高效的实现 (Provably Efficient Implementations)

在本节中，我们探讨如何实现并行计算，使其在实际硬件上具有**可证明的高效性**。**定理 39.6** 已经证明了成本动态可以准确地模拟并行 `let` 构造的动态，无论是顺序执行还是并行执行。因此，这为并行程序的**渐近复杂度**提供了理论上的保障，使我们能够推断程序的执行时间和性能，而无需过多考虑具体实现的细节。然而，在实际的并行计算平台上，存在一定的限制，例如处理器数量的限制和同步开销。这些实际因素必须考虑在内，以便我们能够推导出对实际执行时间的精确预测。

#### **关键挑战**：
构建一个**可证明高效的实现**涉及两个主要任务：
1. **实现语言的原语操作**：证明语言中的每个原语操作都可以在抽象的机器模型上高效地实现。
2. **工作负载调度**：证明如何在多个处理器之间调度工作负载，以**最小化执行时间**并**最大化并行性**。

### **并行平台的抽象机器模型**

为了构建一个高效的并行实现，我们首先需要一个抽象的机器模型。一个常见的模型是**SMP（共享内存多处理器）**，该模型包含 $p > 0$ 个处理器，通过互联网络实现对共享内存的常数时间访问。每个处理器都可以在常数时间内通过互联网络读取或写入共享内存。

#### **SMP模型的特点**：
- **共享内存**：所有处理器可以在常数时间内访问共享的内存单元。
- **同步原语**：模型假设提供了一种常数时间的同步原语，用于控制处理器对内存单元的同时访问。这些原语允许每个处理器执行原子操作（例如并行的取值和加法），并保证处理器对同一内存单元的并行访问被序列化。

### **可证明高效实现的步骤**

#### 1. **语言原语的实现**
我们首先需要证明语言中的每个原语操作都可以在该抽象机器模型上高效地实现。这包括使用低级机器指令来实现诸如并行 `let`、序列操作等语言构造。在这里，特别要注意的是：
- **同步原语的使用**：必须确保在多个处理器同时访问同一内存单元时，使用同步机制来避免数据竞争。
- **并行 fetch-and-add**：这是一个关键的同步操作，允许处理器并行获取内存单元的当前值，并在一个原子操作中更新该值。

#### 2. **工作负载的调度**
接下来，我们必须证明如何在多个处理器之间有效地分配工作负载，以最大化并行性。调度的目标是**最小化总的执行时间**，这意味着要尽可能地分配任务给所有可用的处理器，以避免处理器空闲。

调度策略需要考虑以下几个方面：
- **任务分解**：将程序中的任务分解成可以并行执行的子任务。
- **任务分配**：将这些子任务合理分配给处理器，尽量确保所有处理器同时工作，从而最小化处理器的空闲时间。

### **Brent定理 (Brent’s Theorem)**

最终，我们可以通过分析并行程序的执行时间和工作量，推导出程序的渐近复杂度。这里的关键结果是**Brent定理**，该定理给出了并行程序在多处理器上的执行时间与工作量之间的关系。

#### **Brent定理的核心思想**：
- **工作量 (Work)**：程序在顺序执行时所需的总工作量（即执行的总步数）。
- **深度 (Depth)**：程序的并行执行中，最长的依赖链的长度（即程序中的最短关键路径）。
- **处理器数量 $p$**：程序在并行执行时使用的处理器数量。

Brent 定理表明，一个程序的执行时间 $T_p$ 在 $p$ 个处理器上的上界为：
$$
T_p \leq \frac{W}{p} + D
$$
其中：
- $W$ 是程序的总工作量。
- $D$ 是程序的并行深度。
- $\frac{W}{p}$ 代表理想情况下处理器分摊的工作量。
- $D$ 代表即使在无限并行的情况下，由于依赖关系必须顺序执行的部分的时间。

#### **解释**：
- **$W/p$**：当 $p$ 个处理器完全并行工作时，工作量被均匀分摊，每个处理器执行 $W/p$ 个单位的工作。
- **$D$**：程序中的关键路径，即必须顺序执行的部分，即使有无限个处理器也不能并行化。

### **总结**

通过 Brent 定理，我们可以为并行程序提供一个清晰的渐近复杂度分析框架。此定理证明了在多处理器系统上，程序的实际执行时间不仅取决于处理器数量 $p$，还取决于程序的工作量 $W$ 和并行深度 $D$。因此，尽管我们可以通过增加处理器数量来加快程序执行速度，但程序中的依赖关系（即深度 $D$）决定了其最小执行时间。

### ---------------------------------

### 定理 39.8：并行处理的时间复杂度 (Theorem 39.8: Time Complexity on SMP Processors)

**定理内容**：如果 $e \Downarrow_c v$ 且 $\text{wk}(c) = w$ 和 $\text{dp}(c) = d$，那么 $e$ 可以在 $p$ 个处理器的 SMP (共享内存多处理器) 上以时间 $O(\max(w/p, d))$ 进行计算。

#### **解释**：
- **$w$**：表示程序的**工作量** (work)，即顺序执行时总的计算步骤数。
- **$d$**：表示程序的**深度** (depth)，即计算中的最长依赖链，也就是并行化时的最短执行时间。
- **$p$**：处理器数量。
  

这个定理揭示了一个重要的事实：程序的执行时间永远不能少于其深度 $d$，并且在最理想的情况下，工作量 $w$ 可以均匀分配给 $p$ 个处理器，每个处理器执行 $w/p$ 轮操作。因此，程序的并行执行时间的上限为 $O(\max(w/p, d))$，即受工作量与处理器数目比率和深度之间的最大值控制。

#### **推导解释**：
1. **顺序执行**：
   - 如果处理器数量 $p = 1$，则定理给出的时间复杂度为 $O(w)$，这与程序的顺序复杂度一致。顺序执行时，所有任务只能逐个完成，总工作量就是总的执行时间。
   
2. **并行执行**：
   - 在理想的情况下，如果有 $p$ 个处理器且工作量 $w$ 可以完美分配，则 $p$ 个处理器可以同时执行工作，从而每个处理器承担 $w/p$ 的工作量。
   - 然而，执行时间也受深度 $d$ 限制，深度是并行计算中需要顺序完成的部分，即使有无限个处理器，也无法减少这部分时间。因此，总时间由 $O(\max(w/p, d))$ 决定。

#### **并行性评估**：并行化比率 (Parallelizability Ratio)

为评估一个程序的并行性，定义了**并行化比率**（parallelizability ratio），即工作量与深度的比值 $w/d$。并行化比率决定了程序能否从并行计算中获得显著的性能提升：
- 如果 $w/d \gg p$，即工作量远大于深度，则程序是**可并行化的**，因为此时 $w/p \gg d$，意味着通过增加处理器可以显著减少运行时间。
- 如果 $w/d$ 为常数，则程序的深度 $d$ 会主导运行时间，意味着增加处理器的数量无法显著降低程序的执行时间，此时程序的并行性有限。

### **问题的并行性**

定理指出，并不是所有问题都可以有效并行化。目前，已知一些问题可以设计高效并行的算法，而对另一些问题，还没有已知的高效并行算法。这在复杂性理论中是一个尚未解决的开放性问题，即如何系统地分类哪些问题是可并行的，哪些问题不可并行。

### **Brent定理的核心思想**

为证明 Brent 定理，我们可以构建一个模型，该模型调度 $p$ 个并行处理器上工作负载的执行。假设每个处理器实现了类似 L{nat *} 的动态，这里 L{nat *} 是一种描述自然数和函数操作的语言。

#### **并行动态的状态模型**：
状态 $\nu Σ { µ }$ 表示并行计算状态，形式如下：
$$
\nu a_1 \sim \tau_1, \dots, a_n \sim \tau_n \{ a_1 \mapsto e_1 \otimes \dots \otimes a_n \mapsto e_n \}
$$
其中 $n \geq 1$，该状态表示计算已经分解为 $n$ 个并行任务。每个任务都有一个名字，任务内部可能依赖于其他任务的名字。任务被称为**阻塞**（blocked）时，它依赖的任务尚未完成；如果任务没有依赖，则称为**就绪**（ready）。

#### **并行调度的执行模型**：
在并行处理器上调度任务时，必须考虑任务之间的依赖关系。那些没有依赖关系的任务可以在不同处理器上并行执行，而那些依赖其他任务的任务则必须等待其依赖完成后才能开始执行。因此，程序的执行时间由以下两个因素决定：
1. **任务调度的工作量**：处理器的并行工作量，受限于工作量 $w$ 和处理器数量 $p$。
2. **任务的深度**：任务的依赖链长度，决定了必须顺序完成的部分，也就是程序的关键路径长度 $d$。

### **总结**

定理 39.8 的结论为并行计算提供了理论上的指导，表明在多处理器系统上，程序的执行时间的上界由工作量 $w$ 和深度 $d$ 控制。通过 Brent 定理，我们可以分析程序的并行性，并评估是否能够通过增加处理器数量显著减少程序的运行时间。如果工作量 $w$ 远大于深度 $d$，那么该程序具有较高的并行化潜力，否则程序的并行性有限。

### ---------------------------------

### 本地和全局转换 (Local and Global Transitions)

在并行计算模型中，有两种类型的状态转换：**本地转换**和**全局转换**。这两种转换分别表示不同粒度下的计算步骤：

1. **本地转换 (Local Transitions)**：表示每个处理器单独执行的计算步骤。
2. **全局转换 (Global Transitions)**：表示多达 $p$ 个处理器在固定时间内同时执行的多个本地转换。

### **本地转换的定义**

本地转换的形式为：
$$
\nu \Sigma \ a \sim \tau \ \{ \mu \otimes a \mapsto e \} \ \rightarrow_{\text{loc}} \ \nu \Sigma' \ a \sim \tau \ \{ \mu' \otimes a \mapsto e' \}
$$

- **$e$ 是就绪的表达式**，它表示当前任务可以被执行。
- **三种可能的状态**：
  - **(a)**：$\Sigma$ 和 $\Sigma'$ 都是空的，$\mu$ 和 $\mu'$ 也是空的。这对应于任务的普通计算步骤 (即没有新的任务生成或合并)。
  - **(b)**：$\Sigma$ 和 $\mu$ 是空的，而 $\Sigma'$ 和 $\mu'$ 声明了两个新的不同任务的类型和绑定。这表示任务**生成了两个并行任务**，并等待它们的完成。
  - **(c)**：$\Sigma'$ 和 $\mu'$ 都是空的，而 $\Sigma$ 和 $\mu$ 声明了两个已完成的不同任务的类型和绑定。这表示任务**合并了两个并行任务**的结果，并继续其执行。

### **本地转换的规则**

#### 规则 39.10a：普通函数应用的本地转换
$$
\nu \ a \sim \tau \ \{ a \mapsto (\lambda (x: \tau_2) e)(e_2) \} \ \rightarrow_{\text{loc}} \ \nu \ a \sim \tau \ \{ a \mapsto [e_2 / x] e \}
\tag{39.10a}
$$

- **解释**：这是标准的函数应用操作。表达式 $(\lambda (x: \tau_2) e)(e_2)$ 应用 $e_2$ 到函数 $\lambda (x: \tau_2) e$ 中，通过替换 $x$ 为 $e_2$ 来继续计算。

#### 规则 39.10b：并行任务创建的本地转换
$$
\nu \ a \sim \tau \ \{ a \mapsto \text{par}(e_1; e_2; x_1 . x_2 . e) \} \ \rightarrow_{\text{loc}} \ \nu \ a_1 \sim \tau_1 \ a_2 \sim \tau_2 \ a \sim \tau \ \{ a_1 \mapsto e_1 \otimes a_2 \mapsto e_2 \otimes a \mapsto \text{par}(a_1; a_2; x_1 . x_2 . e) \}
\tag{39.10b}
$$

- **解释**：这个规则表示创建两个并行任务 $a_1$ 和 $a_2$，分别计算表达式 $e_1$ 和 $e_2$。表达式 $\text{par}(a_1; a_2; x_1 . x_2 . e)$ 被阻塞，直到 $a_1$ 和 $a_2$ 的计算完成。

#### 规则 39.10c：并行任务合并的本地转换
$$
e_1 \ \text{val}, \ e_2 \ \text{val}
$$
$$
\nu \ a_1 \sim \tau_1 \ a_2 \sim \tau_2 \ a \sim \tau \ \{ a_1 \mapsto e_1 \otimes a_2 \mapsto e_2 \otimes a \mapsto \text{par}(a_1; a_2; x_1 . x_2 . e) \}
\ \rightarrow_{\text{loc}} \ \nu \ a \sim \tau \ \{ a \mapsto [e_1, e_2 / x_1, x_2] e \}
\tag{39.10c}
$$

- **解释**：这个规则表示当两个并行任务 $a_1$ 和 $a_2$ 都完成时，它们的结果 $e_1$ 和 $e_2$ 被合并到表达式 $e$ 中，并替换 $x_1$ 和 $x_2$。计算任务继续执行 $[e_1, e_2 / x_1, x_2] e$，并且并行任务 $a_1$ 和 $a_2$ 被清除，因为它们已经完成。

---

### **全局转换 (Global Transitions)**

全局转换描述了多达 $p$ 个处理器同时执行多个本地转换。全局转换表示所有处理器同时执行的本地计算步骤。在实际应用中，全局转换的成本会受到并行化的限制，例如处理器数量、任务的同步以及任务之间的依赖。

- **并行任务的同步**：在规则 39.10b 中，任务被阻塞，直到所有并行任务都完成。
- **全局调度**：全局转换控制了多处理器系统的并行任务调度，确保在资源允许的情况下，多个本地任务可以同时执行。

---

### **总结**

- **本地转换**：每个处理器执行的单步操作，处理任务的函数应用、任务的并行创建和并行任务的合并。不同任务可以有依赖关系，阻塞状态直到依赖任务完成。
- **全局转换**：多个处理器同时执行多个本地转换，处理多处理器系统中的并行调度问题。

这种并行计算模型明确了如何在并行环境中创建和合并任务，并通过任务的依赖关系和同步控制任务的执行顺序。

### ---------------------------------

### 全局转换 (Global Transitions)

全局转换描述了并行系统中多个处理器的同时执行步骤。在每一步全局转换中，最多可以有 $p \geq 1$ 个处理器并行执行多个任务。具体的形式如下：
$$
\nu \Sigma_1 a_1 \sim \tau_1 \{ \mu_1 \otimes a_1 \mapsto e_1 \} \rightarrow_{\text{loc}} \nu \Sigma'_1 a_1 \sim \tau_1 \{ \mu'_1 \otimes a_1 \mapsto e'_1 \}
$$
$$
\vdots
$$
$$
\nu \Sigma_n a_n \sim \tau_n \{ \mu_n \otimes a_n \mapsto e_n \} \rightarrow_{\text{loc}} \nu \Sigma'_n a_n \sim \tau_n \{ \mu'_n \otimes a_n \mapsto e'_n \}
$$
$$
\Rightarrow_{\text{glo}}
$$
$$
\nu \Sigma_0 \Sigma_1 a_1 \sim \tau_1 \dots \Sigma_n a_n \sim \tau_n \{ \mu_0 \otimes \mu_1 \otimes a_1 \mapsto e_1 \otimes \dots \otimes \mu_n \otimes a_n \mapsto e_n \}
$$
$$
\rightarrow_{\text{glo}} \nu \Sigma_0 \Sigma'_1 a_1 \sim \tau_1 \dots \Sigma'_n a_n \sim \tau_n \{ \mu_0 \otimes \mu'_1 \otimes a_1 \mapsto e'_1 \otimes \dots \otimes \mu'_n \otimes a_n \mapsto e'_n \}
\tag{39.11}
$$

#### **解释**：
- **全局转换的含义**：在全局转换中，多个任务在同一时间被多个处理器执行。每个处理器执行的步骤是**本地转换**的结果。每次全局转换中，最多有 $p$ 个任务被调度执行。
- **全局状态**：状态由 $n$ 个任务组成，每个任务都有其局部状态 $\mu$ 和表达式 $e$。所有的任务可以并行执行，并在全局转换中同时更新。

### **任务调度和依赖关系**

在每一步全局转换中，任务的调度受限于任务之间的依赖关系。如果任务之间没有依赖关系，则这些任务可以并行执行。具体来说，满足以下条件时，任务可以被调度：
- **并行任务调度**：在全局调度时，最多可以有 $n \leq p$ 个任务是**就绪**状态。每个任务在执行时可能依赖其他任务的完成情况。
- **任务的分解**：如果任务依赖于其他任务，那么这些任务将被分组，并根据依赖关系进行调度。
- **任务的合并**：本地任务执行完成后，如果它依赖的其他任务已经完成，则这些任务将被合并，进入下一步计算。

### **并行任务的生成与合并**

- **任务生成 (Fork)**：在并行系统中，本地转换可能会生成新的并行任务。例如，在规则 (39.10b) 中，任务 $a$ 可以生成两个新的并行任务 $a_1$ 和 $a_2$。在这种情况下，全局状态中会添加两个新任务，并等待它们的执行。
- **任务合并 (Join)**：当两个并行任务 $a_1$ 和 $a_2$ 完成时，它们的结果将被合并到一个新的任务中。合并完成后，旧任务被删除，继续执行新的任务。

### **唯一任务名称与同步**

在实现并行系统时，需要确保生成的任务名称是全局唯一的。尽管任务是局部创建的，但必须保证不同处理器创建的任务不会有重名情况。为此，处理器之间需要进行同步，确保任务名称在全局范围内的唯一性。

### **Brent 定理的证明要点**

**Brent 定理**揭示了如何利用多个处理器来加速程序的执行。其要点包括：

1. **工作量 (Work)**：定义为程序的总计算步骤数，表示程序在单个处理器上执行时的复杂度。设 $w$ 表示工作量。
2. **深度 (Depth)**：定义为程序中的最长依赖链，也就是并行执行时无法避免的顺序步骤。设 $d$ 表示深度。
3. **处理器数目 (Processors)**：设 $p$ 表示并行处理器的数量。

Brent 定理证明，如果在每个阶段最多可以调度 $p$ 个就绪任务，那么程序将在 $w/p$ 个步骤内完成计算，其中 $w$ 是程序的工作量。

- **依赖关系的影响**：在某些阶段，可能无法充分利用所有处理器。这是因为任务之间的依赖关系限制了并行性。在这种情况下，程序的执行时间受深度 $d$ 的限制，无法少于 $d$ 步。

- **最优调度**：如果没有任务依赖限制，则程序的执行时间可以接近 $w/p$。这意味着，处理器的数量越多，程序的执行时间就越短，直到受到深度 $d$ 的限制。

### **结论**

Brent 定理的关键结论是：
- 程序的**最短执行时间**为 $d$（深度），这是任何并行计算都无法避免的顺序执行时间。
- 如果处理器数量足够大，程序的执行时间可以接近 $w/p$，其中 $w$ 是程序的总工作量，$p$ 是处理器数。
- 当 $d$ 远小于 $w/p$ 时，程序的运行时间由 $w/p$ 决定，表明系统可以充分利用并行性。

因此，**全局转换**模型为多处理器并行计算的执行时间提供了理论依据，表明通过合理的调度和资源利用，可以显著减少程序的执行时间。

### ---------------------------------

### 全局转换 (Global Transitions)

全局转换表示多个处理器在多任务环境下同时执行的步骤。在并行处理器系统中，全局转换模型化了最多 $p \geq 1$ 个处理器在一个时间步中执行的计算步骤。每个处理器执行一个局部任务，该任务可能依赖其他任务的执行结果或是可以并行执行。

公式 **(39.11)** 定义了全局转换的规则：

$$
\nu \Sigma_1 a_1 \sim \tau_1 \{ \mu_1 \otimes a_1 \mapsto e_1 \} \rightarrow_{\text{loc}} \nu \Sigma'_1 a_1 \sim \tau_1 \{ \mu'_1 \otimes a_1 \mapsto e'_1 \}
$$
$$
\vdots
$$
$$
\nu \Sigma_n a_n \sim \tau_n \{ \mu_n \otimes a_n \mapsto e_n \} \rightarrow_{\text{loc}} \nu \Sigma'_n a_n \sim \tau_n \{ \mu'_n \otimes a_n \mapsto e'_n \}
$$
$$
\Rightarrow_{\text{glo}} \nu \Sigma_0 \Sigma_1 a_1 \sim \tau_1 \dots \Sigma_n a_n \sim \tau_n \{ \mu_0 \otimes \mu_1 \otimes a_1 \mapsto e_1 \otimes \dots \otimes \mu_n \otimes a_n \mapsto e_n \}
$$
$$
\rightarrow_{\text{glo}} \nu \Sigma_0 \Sigma'_1 a_1 \sim \tau_1 \dots \Sigma'_n a_n \sim \tau_n \{ \mu_0 \otimes \mu'_1 \otimes a_1 \mapsto e'_1 \otimes \dots \otimes \mu'_n \otimes a_n \mapsto e'_n \}
$$

### **公式解释**：

- **符号 $\nu \Sigma a \sim \tau$**：这表示一个全局状态，其中 $\Sigma$ 是类型环境，$a$ 是任务名称，$\tau$ 是任务的类型。$\mu$ 代表当前任务的局部状态，$e$ 是该任务正在执行的表达式。 
- **$ \rightarrow_{\text{loc}}$**：表示局部转换的步骤。每个任务在其所属处理器上独立执行该转换，这个局部转换是在一个本地的时间步中发生的。
- **$ \otimes $**：表示多个任务在同一时刻可以并行执行。每个任务独立地执行，但多个任务之间可能存在依赖关系。

#### **全局转换规则的解释**：

1. **局部转换 (Local Transitions)**：
   - 首先，每个任务都会执行一个局部转换 $ \rightarrow_{\text{loc}}$。这些局部转换可以是简单的表达式求值（如函数应用），或者是涉及并行任务的生成或合并。
   - 例如，局部转换 $\nu \Sigma_1 a_1 \sim \tau_1 \{ \mu_1 \otimes a_1 \mapsto e_1 \} \rightarrow_{\text{loc}} \nu \Sigma'_1 a_1 \sim \tau_1 \{ \mu'_1 \otimes a_1 \mapsto e'_1 \}$ 表示任务 $a_1$ 在局部处理器上执行一次转换，将任务状态从 $e_1$ 转变为 $e'_1$。

2. **全局转换 (Global Transition)**：
   - 全局转换 $ \Rightarrow_{\text{glo}}$ 表示多个处理器同时执行多个任务的局部转换。具体地，$p$ 个处理器可以在一个全局时间步中执行 $n$ 个任务的局部转换，其中 $1 \leq n \leq p$。
   - 全局转换将多个局部转换组合在一起，形成整个系统状态的更新。例如，若 $a_1, a_2, \dots, a_n$ 是 $n$ 个任务，则全局转换表示这些任务同时更新其状态。

### **任务调度与依赖**：

1. **任务的并行与依赖**：
   - 在并行计算中，任务可以并行执行的前提是它们之间没有依赖关系。如果某些任务依赖其他任务的结果，则必须等这些任务先完成。例如，任务 $a_1$ 和 $a_2$ 可以并行执行，但任务 $a_3$ 可能依赖于 $a_1$ 和 $a_2$ 的结果，则 $a_3$ 不能立即开始。
   - 这种依赖关系体现在转换规则中，例如公式 **(39.10c)**，其中当 $e_1$ 和 $e_2$ 都求值完成后，才能继续后续任务的合并。

2. **全局任务调度**：
   - 在每一步全局转换中，调度器会选择 $n \leq p$ 个就绪任务进行并行执行。就绪任务是那些没有依赖其他任务结果的任务。
   - 任务的调度是基于依赖关系的，因此在某些全局步骤中，可能并不是所有处理器都能充分利用。

### **任务的生成与合并**：

1. **任务生成 (Forking)**：
   - 在并行计算中，某个任务可能会生成两个新的任务来并行执行。生成的新任务独立于原任务，它们被加入到全局状态中等待执行。例如，规则 **(39.10b)** 表示一个任务生成两个新的并行任务 $a_1$ 和 $a_2$。
   - 这种生成操作在并行计算中十分常见，它允许将大任务分解为更小的并行任务，以提高效率。

2. **任务合并 (Joining)**：
   - 当两个并行任务完成时，系统会将它们的结果合并回主任务中，继续执行。例如，规则 **(39.10c)** 表示两个任务 $a_1$ 和 $a_2$ 完成后，合并其结果 $e_1$ 和 $e_2$，并继续执行合并后的任务。

### **任务名称的全局唯一性**：

- 由于多个处理器可能同时生成任务，因此需要确保每个任务的名称在全局范围内是唯一的。虽然任务是局部创建的，但需要同步机制来确保多个处理器不会为不同任务分配相同的名称。
- 这种同步机制在并行处理系统中非常重要，它可以防止任务名称冲突，从而确保任务的正确执行。

### **Brent 定理的证明**

**Brent 定理**证明了并行计算的时间复杂度。其关键点是：
1. **工作量 (Work, w)**：程序在单处理器上执行时的总步骤数，表示为 $w$。这是顺序执行程序的复杂度。
2. **深度 (Depth, d)**：程序的最长依赖链，也就是需要顺序执行的部分。这是并行执行时无法并行化的最短执行时间。
3. **处理器数目 (Processors, p)**：表示可以同时执行的处理器数量。

定理证明，当存在 $p$ 个处理器时，程序的总执行时间可以分为两个部分：
- **工作量 $w/p$**：理想情况下，处理器可以将总工作量 $w$ 平均分配给 $p$ 个处理器，这时每个处理器只需要执行 $w/p$ 轮操作。
- **深度 $d$**：由于任务的依赖关系，即使有无限多个处理器，程序也无法比其深度 $d$ 更快完成。

### **定理 39.8 的含义**：

**定理 39.8** 给出的结果表明：
- **程序的执行时间的下界是深度 $d$**：这是因为深度是程序中的关键路径，无论有多少个处理器，这部分必须顺序完成。
- **理想情况下的执行时间是 $w/p$**：如果没有任务依赖关系，处理器可以完全并行化工作，总时间为 $w/p$，即每个处理器承担 $w/p$ 的工作量。

### **并行化的可行性**：

程序的并行性取决于工作量 $w$ 和深度 $d$ 之间的比值，称为**并行化比率 (Parallelizability Ratio)**，即 $w/d$。如果 $w/d \gg p$，那么程序具有较好的并行性，因为这意味着工作量远远大于依赖关系，可以通过增加处理器显著减少运行时间。

### **总结**：

- 全局转换模型通过将多个处理器的局部转换组合在一起，描述了多处理器并行计算的执行过程。
- 处理器的任务调度取决于任务之间的依赖关系，这决定了在某些阶段，可能无法充分利用所有处理器。
- 通过 **Brent 定理**

，我们可以分析并行程序的时间复杂度，并评估其并行化潜力。

### ---------------------------------

### 39.5 备注 (Notes)

这一节讨论了**并行性**（Parallelism）和**并发性**（Concurrency）之间的关键区别，并引入了这些概念的历史来源及理论背景。

#### **并行性与并发性**的区别：

1. **并行性 (Parallelism)**：
   - 并行性主要关注的是**效率**（Efficiency），而不是语义。并行性中的程序**语义**在并行执行和非并行执行时应该保持一致，也就是说，无论程序是否并行执行，其语义和结果都不会发生改变。
   - 通过并行化程序执行，可以提升计算效率，缩短执行时间。并行执行的核心思想是将多个独立的任务同时进行，以更好地利用处理器资源。

2. **并发性 (Concurrency)**：
   - 并发性主要关注的是**组合性**（Composition），即如何将多个程序或进程组合在一起进行交互，而不仅仅是执行效率。并发程序的语义是相对弱化的，目的是允许多个程序之间进行组合和协调，而不影响各个程序的独立语义。
   - 在并发性中，程序的执行顺序可能不是固定的，不同进程之间的通信和协作是关键点，通常通过机制如进程同步、锁、消息传递等来实现。

#### **并行性与并发性的区分**：

- **并行性**强调计算的**时间效率**，例如如何减少程序的运行时间。程序的语义在执行中不会因为并行性而变化。
- **并发性**关注的是**程序的组合与交互**，而不是如何通过同时执行任务来提高效率。并发性允许程序之间以松散的方式组合，使它们能够在不确定的时间点进行通信或合作。

### **历史背景**：

- **Blelloch (1990)** 是最早区分并行性和并发性的人之一，他提出了这一重要区分，并且阐述了如何通过不同的方式处理并行和并发。
  
- **Blelloch 和 Greiner (1995, 1996a)** 开创了**成本语义**（Cost Semantics）和**可证明的高效实现**（Provably Efficient Implementations）等概念。这些理论帮助我们通过数学和形式化方法，分析并行程序的复杂度和效率，并设计能够在硬件上高效运行的并行算法。

#### **成本语义 (Cost Semantics)**：
成本语义为程序的执行赋予了时间复杂度的度量，帮助我们分析程序在不同执行模式下的效率，例如顺序执行和并行执行的区别。通过成本语义，能够推导出程序在不同处理器数量下的理论运行时间。

#### **可证明的高效实现 (Provably Efficient Implementations)**：
这一概念通过理论证明来确保并行程序的实现是最优的，即在给定的硬件条件下，程序的执行时间能够达到其最低的上限。例如，使用共享内存多处理器 (SMP) 时，可以通过合理的调度算法和同步机制，证明程序在多处理器上的执行是高效的。

### **总结**：
- **并行性**和**并发性**是不同的概念，前者关注效率，后者关注组合。
- 并行性提升程序效率的关键在于合理分配任务，尽量避免依赖关系的阻碍。并发性则更关注如何在保持程序独立性的前提下，实现程序之间的交互。
- **成本语义**和**可证明的高效实现**理论为并行计算的分析和优化提供了强有力的工具，这些理论帮助我们理解并行程序的复杂性并设计更高效的实现方案。


### ---------------------------------


### ---------------------------------