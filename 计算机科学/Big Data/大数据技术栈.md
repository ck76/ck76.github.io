

提起大数据，不得不提由IBM提出的关于大数据的5V特点：Volume（大量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实性），而对于大数据领域的从业人员的日常工作也与这5V密切相关。大数据技术在过去的几十年中取得非常迅速的发展，尤以Hadoop和Spark最为突出，已构建起庞大的技术生态体系圈。

首先通过一张图来了解一下目前大数据领域常用的一些技术，当然大数据发展至今所涉及技术远不止这些。

BigData Stack：

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gqdo8pv5lsj310u0u0dit.jpg" alt="img" style="zoom:50%;" />

下面分不同层介绍各个技术，当然各个层并不是字面意义上的严格划分，如Hive既提供数据处理功能也提供数据存储功能，但此处将其划为数据分析层中
**1. 数据采集和传输层**

- **Flume**
  Flume一个分布式、可靠的、高可用的用于数据采集、聚合和传输的系统。常用于日志采集系统中，支持定制各类数据发送方用于收集数据、通过自定义拦截器对数据进行简单的预处理并传输到各种数据接收方如HDFS、HBase、Kafka中。之前由Cloudera开发，后纳入Apache
- **Logstash**
  ELK工作栈的一员，也常用于数据采集，是开源的服务器端数据处理管道
- **Sqoop**
  Sqoop主要通过一组命令进行数据导入导出的工具，底层引擎依赖于MapReduce，主要用于Hadoop（如HDFS、Hive、HBase）和RDBMS（如mysql、oracle）之间的数据导入导出
- **Kafka**
  分布式消息系统。生产者（producer）——消费者（consumer）模型。提供了类似于JMS的特性，但设计上完全不同，不遵循JMS规范。如kafka允许多个消费者主动拉取数据，而JMS中只有点对点模式消费者才会主动拉取数据。主要应用在数据缓冲、异步通信、汇集数据、系统接偶等方面
- **Pulsar**
  pub-sub模式的分布式消息平台，拥有灵活的消息模型和直观的客户端API。类似于Kafka，但Pulsar支持多租户，有着资产和命名空间的概念，资产代表系统里的租户。假设有一个Pulsar集群用于支持多个应用程序，集群里的每个资产可以代表一个组织的团队、一个核心的功能或一个产品线。一个资产可以包含多个命名空间，一个命名空间可以包含任意个主题

**2. 数据存储层**

- **HBase**
  基于Google Bigtable的开源实现，是一个具有高可靠性、高性能、面向列、可伸缩性、典型的key/value分布式存储的nosql数据库系统，主要用于海量结构化和半结构化数据存储。它介于nosql和RDBMS之间，仅能通过行键（row key）和行键的range来检索数据，行数据存储是原子性的，仅支持单行事务（可通过hive支持来实现多表join等复杂操作）。HBase查询数据功能很简单，不支持join等复杂操作，不支持跨行和跨表事务
- **Kudu**
  介于HDFS和HBase之间的基于列式存储的分布式数据库。兼具了HBase的实时性、HDFS的高吞吐，以及传统数据库的sql支持
- **HDFS**
  分布式文件存储系统，具有高容错（high fault-tolerant）、高吞吐（high throughput）、高可用（high available）的特性。HDFS非常适合大规模数据集上的应用，提供高吞吐量的数据访问，可部署在廉价的机器上。它放宽了POSIX的要求，这样可以实现流的形式访问（文件系统中的数据。主要为各类分布式计算框架如Spark、MapReduce等提供海量数据存储服务，同时HDFS和HBase底层数据存储也依赖于HDFS

**3. 数据分析层**

- **Spark**
  Spark是一个快速、通用、可扩展、可容错的、内存迭代式计算的大数据分析引擎。目前生态体系主要包括用于批数据处理的SparkRDD、SparkSQL，用于流数据处理的SparkStreaming、Structured-Streaming，用于机器学习的Spark MLLib，用于图计算的Graphx以及用于统计分析的SparkR，支持Java、Scala、Python、R多种数据语言
- **Flink**
  分布式的大数据处理引擎，可以对有限数据流和无线数据流进行有状态的计算。Flink在设计之初就是以流为基础发展的，然后再进入批处理领域，相对于spark而言，它是一个真正意义上的实时计算引擎
- **Storm**
  由Twitter开源后归于Apache管理的分布式实时计算系统。Storm是一个没有批处理能力的数据流处理计算引擎，storm提供了偏底层的API，用户需要自己实现很多复杂的逻辑
- **MapReduce**
  分布式运算程序的编程框架，适用于离线数据处理场景，内部处理流程主要划分map和reduce两个阶段
- **Hive**
  Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供HQL语句（类SQL语言）查询功能，存储依赖于HDFS。支持多种计算引擎，如Spark、MapReduce（默认）、Tez；支持多种存储格式，如TextFile、SequenceFile、RCFile、ORC、Parquet（常用）；支持多种压缩格式，如gzip、lzo、snappy（常用）、bzip2
- **Tez**
  支持DAG作业的开源计算框架。相对于MapReduce性能更好，主要原因在于其将作业描述为DAG（有向无环图），这一点与Spark类似
- **Pig**
  基于Hadoop的大规模数据分析平台，它包含了一种名为Pig Latin的脚本语言来描述数据流，并行地执行数据流处理的引擎，为复杂的海量数据并行计算提供了一个简单的操作和编程接口。Pig Latin本身提供了许多传统的数据操作，同时允许用户自己开发一些自定义函数用来读取、处理和写数据，该语言的编译器会把类SQL的数据分析请求转换为一系列经过优化处理的MapReduce运算
- **Mahout**
  提供一些可扩展的机器学习领域经典算法的实现，Mahout包含许多实现，包括聚类、分类、推荐过滤、频繁子项挖掘。通过使用Apache Hadoop 库，可以将Mahout扩展到云中
- **Phoenix**
  构建在HBase之上的一个SQL层，能让我们通过标准的JDBC API操作HBase中的数据。Phoenix完全使用Java编写，作为HBase内嵌的JDBC驱动。Phoenix查询引擎会将SQL查询转换为一个或多个HBase scan，并编排执行以生成标准JDBC结果集

**4. OLAP引擎**

- **Druid**
  开源的、基于列存储的、分布式的，适用于实时数据分析的存储系统，能够快速聚合、灵活过滤、毫秒级查询和低延迟数据导入。通过使用Bitmap indexing加速列存储的查询速度，并使用CONCISE算法来对bitmap indexing进行压缩，使得生成的segments比原始文本文件小很多，并且它的各个组成部分之间耦合性低，如果不需要实时数据完全可以忽略实时节点
- **Kylin**
  最初由eBayInc.开发并贡献至开源社区的分布式分析引擎。提供Hadoop/Spark之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据，它能在亚秒内查询巨大的Hive表。需要使用者对数仓模型有深度了解，并需构建cube。能够与多种可视化工具，如Tableau，PowerBI等，令用户可以使用BI工具对Hadoop数据进行分析
- **Impala**提供对HDFS、HBase等数据的高性能、低延迟的交互式SQL查询功能的大数据查询分析引擎，由Cloudera开源。它基于Hive，使用Hive的元数据在内存中计算，具有实时、批处理、高并发等优点
- **Presto**
  开源的分布式大数据SQL查询引擎，适用于交互式分析查询。可以将多个数据源的数据进行合并，并且可以直接从HDFS读取数据，在使用前不需要大量的ETL操作

**5. 资源管理层**

- **Yarn**
  Yarn是一个资源调度平台，负责为运算程序分配资源和调度，不参与用户程序内部工作。核心组件包括：ResourceManager（全局资源管理器，负责整个系统的资源管理和分配）、NodeManager（每个节点上的资源和任务管理器）
- **Kubernetes**
  又称K8s，为容器化的应用提供资源调度、部署运行、均衡容灾、服务注册、扩容缩容等功能的自动化容器操作的开源平台。具体体现在：自动化容器的部署和复制、随时扩展或收缩容器规模、将容器组织成组，并且提供容器间的负载均衡等。Kubernetes支持docker和Rocket，可以将Docker看成Kubernetes内部使用的低级别组件
- **Mesos**
  类似于Yarn，也是一个分布式资源管理平台，为MPI、Spark作业在统一资源管理环境下运行。它对Hadoop2.0支持很好，但国内用的不多

**6. 工作流调度器**

- **Oozie**
  基于工作流引擎的任务调度框架，能够提供能够提供对MapReduce和Pig 任务的调度与协调
- **Azkaban**
  由LinkedIn开源，相对Oozie更轻量级。用于在一个工作流内以一个特定顺序运行一组任务，通过一种kv文件格式来建立任务之间的依赖关系并为用户提供了易于使用的web界面来维护和跟踪允许任务的工作流

**7. 其他**

- **Ambari**
  基于web的安装部署工具，支持对大多数的Hadoop组件，如HDFS、MapReduce、Hive、Pig、HBase等的管理和监控
- **Zookeeper**
  分布式协调服务即为用户的分布式应用程序提供协调服务，如主从协调、服务器节点动态上下线、统一配置管理、分布式共享锁等，它本身也是一个分布式程序（部署奇数台，只要由半数以上zookeeper节点存活，zookeeper集群就能正常提供服务），它是Google Chubby一个开源实现



---



![img](https://p.ipic.vip/svjvz6.jpg)

## 采集层 && 传输层

- Sqoop: 在hadoop和关系型数据库之间转换数据。
- Flume: 一个分布式的高可用的数据收集、聚集和移动的工具。通常用于从其他系统搜集数据，如web服务器产生的日志，通过Flume将日志写入到Hadoop的HDFS中。
- Canal: 阿里mysql数据库binlog的增量订阅&消费组件。
- Logstash: 开源的日志收集管理工具。
- Kafka: 消息队列，一个分布式流平台。类似的还有RabbitMQ、ZeroMQ、ActiveMQ
- RocketMQ: 阿里开源的消息队列。

## 存储层

- HBase: Hadoop数据库。
- Alluxio: 以内存为中心分布式存储系统。
- Redis: 开源的内存键值数据库，相比于Memcache，支持丰富的数据结构。
- Ignit: 以内存为中心的分布式数据库，缓存和处理平台，用于事务，分析和流式工作负载，在PB级别的数据上提供接近内存速度访问数据。
- TiDB: 分布式 NewSQL数据库。类似的还有GreenPlum与OceanBase。
- HDFS: Hadoop的分布式文件系统。
- Ceph: 开源分布式存储系统，提供了块储存RDB、分布式文件储存Ceph FS、以及分布式对象存储Radosgw三大储存功能，是目前为数不多的集各种存储能力于一身的开源存储中间件。
- Kudu: cloudera开源的运行在hadoop平台上的列式存储系统.
- CouchDB: 开源的面向文档的数据库管理系统，与MongoDB类似。

## 计算层

- Hive: 构建在Hadoop上的数据仓库框架，基于SQL对存放在Hadoop上的大规数据执行查询。同类的产品还有:

- - kylin: 开源的分布式分析引擎，提供Hadoop/Spark之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据。
  - Druid: 为监控而生的数据库连接池。
  - SparkSQL: Spark的结构化数据处理模块。
  - Impala: Apache Hadoop开源的本地分析数据库。

- Spark: Spark是一个分布式计算框架。

- Storm: 一个分布式的、高容错的实时计算系统。Storm适用的场景：

- - 流数据处理：Storm可以用来用来处理源源不断的消息，并将处理之后的结果保存到持久化介质中。
  - 分布式RPC：由于Storm的处理组件都是分布式的，而且处理延迟都极低，所以可以Storm可以做为一个通用的分布式RPC框架来使用。

- Flink: 一个针对流数据和批数据的分布式处理引擎。

- YARN: hadoop的集群资源管理系统。

- Mesos: Mesos 可以将整个数据中心的资源（包括 CPU、内存、存储、网络等）进行抽象和调度，使得多个应用同时运行在集群中分享资源，并无需关心资源的物理分布情况。

- Kubernetes: 开源容器集群管理系统，基于Docker构建一个容器调度服务，为容器化的应用提供资源调度、部署运行、均衡容灾、服务注册、扩容缩容等功能。

- Presto: 数据仓库和数据分析产品：数据分析、大规模数据聚集和生成报表。通过使用分布式查询，可以快速高效的完成海量数据的查询。如果你需要处理TB或者PB级别的数据，那么你可能更希望借助于Hadoop和HDFS来完成这些数据的处理。作为Hive和Pig（Hive和Pig都是通过MapReduce的管道流来完成HDFS数据的查询）的替代者，Presto不仅可以访问HDFS，也可以操作不同的数据源，包括：RDBMS和其他的数据源（例如：Cassandra）。

- ZooKeeper: 一个分布式的，开放源码的分布式应用程序协调服务。

- Lucene: 一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎，与ElasticSearch类似。

- 其他(区块链框架): Etherenum(以太坊)，HyperLedger(超级账本)

## 工具层 && 服务层

- Zeppelin: 一个基于web的交互式数据分析和数据可视化的框架。
- Kylin: 开源的分布式分析引擎，提供Hadoop/Spark之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据。



**总结**

> 集群管理：Ambari、Cloudera Manager
> 发行版：Apache、CDH(Cloudera)、HDP(Hortonworks)
> 数据总线：Kafka、RocketMQ、TT、ActiveMQ
> 日志收容：Scribe、Logstash、Flume、chukwa
> 数据检索：Lucene、Elasticsearch、[Crate.io](https://link.zhihu.com/?target=http%3A//Crate.io)、Solr
> OLAP：Druid、mondrian、pinot、Elasticsearch、Presto、kylin、Lylin、Impala、Dremel、ApacheDrill、Presto、Deepgreen DB
> 列式存储数据库：Vertica、Actian、HBase、HiStore
> 分布式计算框架：Storm、hadoop、spark、Flink、工作流调度(azkaban、ozzle)、DAG计算框架(Tez)
> 时序数据库：mysql、postgresql、kairosDB、influxdb等
> 分布式文件系统：hadoop(hdfs)、GFS
> 分布式缓存框架：leveldb、memcache、redis
> 数据存储格式：Avro、ProtocolBuffer、parequet、Thrift
> 可视化：Grafana、Kibana、Pivot、Superset等
> 分布式数据存储：Cassandra、HBase、kudu、Alluxio
> 分布式调度框架：Zookeeper(Paxos)
> 分布式资源管理框架：yarn、mesos
> 微服务管理：dubbo、spring cloud、服务框架(RestAPI、RPC、AKKA)
> 机器学习：mahout、DeepLearning4j、H2O、SparkNet
> 架构：Lambda(离线计算、实时计算、不可变性、读写分离、复杂性分离)



---

![img](https://tva1.sinaimg.cn/large/008i3skNly1gqdoaodypzj30hs0cqdgm.jpg)



大数据平台技术栈



下面自底向上介绍各个层的主要项目。

1 采集层和传输层





![img](https://tva1.sinaimg.cn/large/008i3skNly1gqdoanb8ufj30rs03ct8v.jpg)



采集层



- Sqoop

在hadoop和关系型数据库之间转换数据。

- Flume

Flume是一个分布式的高可用的数据收集、聚集和移动的工具。通常用于从其他系统搜集数据，如web服务器产生的日志，通过Flume将日志写入到Hadoop的HDFS中。





![img](https://tva1.sinaimg.cn/large/008i3skNly1gqdoalmubrj31400grdgx.jpg)



Flume



- Canal

数据抽取是 ETL 流程的第一步。我们会将数据从 RDBMS 或日志服务器等外部系统抽取至数据仓库，进行清洗、转换、聚合等操作。在现代网站技术栈中，MySQL 是最常见的数据库管理系统，我们会从多个不同的 MySQL 实例中抽取数据，存入一个中心节点，或直接进入 Hive。市面上已有多种成熟的、基于 SQL 查询的抽取软件，如著名的开源项目 Apache Sqoop，然而这些工具并不支持实时的数据抽取。MySQL Binlog 则是一种实时的数据流，用于主从节点之间的数据复制，我们可以利用它来进行数据抽取。借助阿里巴巴开源的 Canal 项目，我们能够非常便捷地将 MySQL 中的数据抽取到任意目标存储中。





![img](https://tva1.sinaimg.cn/large/008i3skNly1gqdoahph76j30hs07imxb.jpg)



Canal



- Logstash

Logstash 是开源的服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的 “存储库” 中。

- Kafka

消息队列，一个分布式流平台。

- RocketMQ

阿里巴巴开源的消息队列。

2 存储层





![img](https://tva1.sinaimg.cn/large/008i3skNly1gqdoafzf5uj30rs053jrk.jpg)



存储层



- HBase

HBase is the Hadoop database, a distributed, scalable, big data store.

- Alluxio/Redis/Ignite

Alluxio以内存为中心分布式存储系统，从下图可以看出， Alluxio主要有两大功能，第一提供一个文件系统层的抽象，统一文件系统接口，桥接储存系统和计算框架；第二通过内存实现对远程数据的加速访问。详情参考Alluxio document。





![img](https://tva1.sinaimg.cn/large/008i3skNly1gqdoaen5b8j30hs07r74p.jpg)



Alluxio



Redis是一个开源的内存键值数据库，相比于Memcache，支持丰富的数据结构。

Ignit是一个以内存为中心的分布式数据库，缓存和处理平台，用于事务，分析和流式工作负载，在PB级别的数据上提供接近内存速度访问数据。

从上述分析可知，Alluxio/Redis/Ignite主要都是通过内存来实现加速。

- TiDB

TiDB是有PingCap开源的分布式NewSQL关系型数据库。NewSQL数据库有两个流派，分别是以Google为代表的Spanner/F1和以Amazon 为代表的Aurora(极光)，目前国内做NewSQL数据库主要是参考Google的Spanner架构，Google Spanner也是未来NewSQL的发展趋势。具体请查阅相关资料，或者访问Youtube，观看黄旭东的分享。

- HDFS

Hadoop的分布式文件系统。

- Ceph

Linux中备受关注的开源分布式存储系统，除了GlusterFS，当属Ceph。目前Ceph已经成为RedHat旗下重要的分布式存储产品，并继续开源。Ceph提供了块储存RDB、分布式文件储存Ceph FS、以及分布式对象存储Radosgw三大储存功能，是目前为数不多的集各种存储能力于一身的开源存储中间件。

- Kudu

Kudu是cloudera开源的运行在hadoop平台上的列式存储系统,拥有Hadoop生态系统应用的常见技术特性，运行在一般的商用硬件上，支持水平扩展,高可用，目前是Apache Hadoop生态圈的新成员之一（incubating）。

Kudu的设计与众不同,它定位于应对快速变化数据的快速分析型数据仓库，希望靠系统自身能力，支撑起同时需要高吞吐率的顺序和随机读写的应用场景，提供一个介于HDFS和HBase的性能特点之间的一个系统，在随机读写和批量扫描之间找到一个平衡点，并保障稳定可预测的响应延迟。可与MapReduce, Spark和其它hadoop生态系统集成。

3 计算层



- Hive

Facebook 开源。Hive是一个构建在Hadoop上的数据仓库框架。Hive的设计目标是让精通SQL技能但Java编程技能相对较弱的分析师能对存放在Hadoop上的大规数据执行查询。

Hive的查询语言HiveQL是基于SQL的。任何熟悉SQL的人都可以轻松使用HiveSQL写查询。和RDBMS相同，Hive要求所有数据必须存储在表中，而表必须有模式（Schema），且模式由Hive进行管理。

类似Hive的同类产品：kylin druid SparkSQL Impala。

KylinApache Kylin™是一个开源的分布式分析引擎，提供Hadoop/Spark之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由eBay Inc. 开发并贡献至开源社区。它能在亚秒内查询巨大的Hive表。

Druid 为监控而生的数据库连接池。

SparkSQL,Spark SQL is Apache Spark's module for working with structured data.

Impala,Impala是Apache Hadoop的开源，本地分析数据库。 它由Cloudera，MapR，Oracle和Amazon等供应商提供。

- Spark
- Spark是一个分布式计算框架。
- Storm
- Storm是一个分布式的、高容错的实时计算系统。Storm对于实时计算的的意义相当于Hadoop对于批处理的意义。Hadoop为我们提供了Map和Reduce原语，使我们对数据进行批处理变的非常的简单和优美。同样，Storm也对数据的实时计算提供了简单Spout和Bolt原语。
- Storm适用的场景：①、流数据处理：Storm可以用来用来处理源源不断的消息，并将处理之后的结果保存到持久化介质中。②、分布式RPC：由于Storm的处理组件都是分布式的，而且处理延迟都极低，所以可以Storm可以做为一个通用的分布式RPC框架来使用。
- Flink

Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. Flink has been designed to run in all common cluster environments, perform computations at in-memory speed and at any scale.

- TensorFlow

TensorFlow™ is an open source software library for high performance numerical computation. Its flexible architecture allows easy deployment of computation across a variety of platforms (CPUs, GPUs, TPUs), and from desktops to clusters of servers to mobile and edge devices. Originally developed by researchers and engineers from the Google Brain team within Google’s AI organization, it comes with strong support for machine learning and deep learning and the flexible numerical computation core is used across many other scientific domains.

- 分布式资源调度
- YARN, Apache YARN(Yet Another Resource Negotiator)是hadoop的集群资源管理系统。YARN在Hadoop2时被引入，最初是为了改善MapReduce的实现，但它具有足够的通用性，也支持其他的分布式计算模式。
- Mesos
- Mesos 最初由 UC Berkeley 的 AMP 实验室于 2009 年发起，遵循 Apache 协议，目前已经成立了 Mesosphere 公司进行运营。Mesos 可以将整个数据中心的资源（包括 CPU、内存、存储、网络等）进行抽象和调度，使得多个应用同时运行在集群中分享资源，并无需关心资源的物理分布情况。
- 如果把数据中心中的集群资源看做一台服务器，那么 Mesos 要做的事情，其实就是今天操作系统内核的职责：抽象资源 + 调度任务。Mesos 项目是 Mesosphere 公司 Datacenter Operating System (DCOS) 产品的核心部件。
- Kubernetes
- Kubernetes是Google 2014年推出的开源容器集群管理系统，基于Docker构建一个容器调度服务，为容器化的应用提供资源调度、部署运行、均衡容灾、服务注册、扩容缩容等功能。
- Presto
- Presto是FaceBook开源的一个开源项目。Presto被设计为数据仓库和数据分析产品：数据分析、大规模数据聚集和生成报表。这些工作经常通常被认为是线上分析处理操作。
- Presto通过使用分布式查询，可以快速高效的完成海量数据的查询。如果你需要处理TB或者PB级别的数据，那么你可能更希望借助于Hadoop和HDFS来完成这些数据的处理。作为Hive和Pig（Hive和Pig都是通过MapReduce的管道流来完成HDFS数据的查询）的替代者，Presto不仅可以访问HDFS，也可以操作不同的数据源，包括：RDBMS和其他的数据源（例如：Cassandra）。
- 其他（区块链框架）
- Etherenum， 以太坊
- HyperLedger，超级账本

4 工具层和服务层





![img](https://tva1.sinaimg.cn/large/008i3skNly1gqdoacchb0j314007ngmd.jpg)



工具层和服务层





- Zeppelin
- Web-based notebook that enables data-driven,
- interactive data analytics and collaborative documents with SQL, Scala and more.
- Kylin
- Apache Kylin™是一个开源的分布式分析引擎，提供Hadoop/Spark之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由eBay Inc. 开发并贡献至开源社区。它能在亚秒内查询巨大的Hive表。



![img](https://tva1.sinaimg.cn/large/008i3skNly1gqdoaak9emj30hs08tt8z.jpg)





- [zhihu](https://zhuanlan.zhihu.com/p/51973232)

- [zhihu2](https://zhuanlan.zhihu.com/p/95926504)

- [zhihu3](https://zhuanlan.zhihu.com/p/53307087)