

http协议从http1.0，http1.1，http2.0到http3.0，每个版本的特点，改进了上个版本哪些问题，详解http协议的进化路线，拥抱QUIC。

---

**1 HTTP1.0**

1.0的HTTP版本，是一种**无状态，无连接**的应用层协议。 HTTP1.0规定浏览器和服务器保持短暂的链接。

浏览器每次请求都需要与服务器建立一个TCP连接，服务器处理完成以后立即断开TCP连接（无连接），服务器不跟踪也每个客户单，也不记录过去的请求（无状态）。

这种无状态性可以借助**cookie/session**机制来做身份认证和状态记录。

**1.1 HTTP1.0存在的问题1：无法复用连接**

每次发送请求，都需要进行一次TCP连接，而TCP的连接释放过程又是比较费事的。这种无连接的特性会使得网络的利用率变低。

**1.2 HTTP1.0存在的问题2：队头阻塞（head of line blocking）**

由于HTTP1.0规定下一个请求必须在前一个请求响应到达之前才能发送，假设前一个请求响应一直不到达，那么下一个请求就不发送，后面的请求就阻塞了。

---

**2 HTTP1.1**

HTTP1.1继承了HTTP1.0的简单，克服了HTTP1.0性能上的问题。

**2.1 长连接**

HTTP1.1增加Connection字段，通过设置**Keep-Alive**保持HTTP连接不断卡。避免每次客户端与服务器请求都要重复建立释放建立TCP连接。提高了网络的利用率。

如果客户端想关闭HTTP连接，可以在请求头中携带Connection:false来告知服务器关闭请求。

**2.2 管道化（pipelining）——尴尬的假并行传输**

HTTP1.1支持请求管道化（pipelining）。

基于HTTP1.1的长连接，使得请求管线化成为可能。 管线化使得请求能够**“并行”传输**。

例如：

假如响应的主体是一个html页面，页面中包含了很多img，这个时候keep-alive就了很大作用。能够“并行”发送多个请求。（注意，**这里的“并行”并不是真正意义上的并行传输**）

需要注意的是：服务器**必须按照客户端请求的先后顺序**依次回送相应的结果，以保证客户端能够区分出每次请求的响应内容。

也就是说，HTTP管道化可以让我们把先进先出队列从客户端（请求队列）迁移到服务端（响应队列）

如果所示，客户端同时发了两个请求分别获取html和css，假如说服务器的css资源先准备就绪，服务器也会先发送html，再发送css。

换句话来说，只有等到html响应的资源完全传输完毕后，css响应的资源才开始传输，不允许同时存在两个并行的响应。

可见，HTTP1.1还是无法解决队头阻塞（head of line blocking）的问题。同时“管道化”技术存在各种各样的问题，所以很多浏览器要么根本不支持它，要么直接默认关闭，并且开启的条件很苛刻……而且好像实际也没有什么用处。

**2.3 HTTP1.1下的真并行传输——浏览器优化策略**

HTTP1.1支持管道化，但是服务器也必须进行逐个响应的送回，这个是很大的一个缺陷。实际上，现阶段的浏览器厂商采取了另外一种做法，它允许我们**打开多个TCP**的会话，也就是说，上图我们看到的并行，其实是不同的TCP连接上的HTTP请求和相应。这才是真正的并行！

很多人以为的连接数情况：



各浏览器在HTTP1.0和HTTP1.1协议下支持的同一域名并行链接数量表格

![各浏览器在HTTP1.0和HTTP1.1协议下支持的同一域名并行链接数量表格](https://cdn.mantoufan.com/202003050848588838_c_w_600.jpg)



**2.4 缓存处理——强缓存、协商缓存，启发式缓存（新增）**

此外，HTTP1.1还加入了缓存处理（强缓存和协商缓存），新的字段如cache-control，支持**断点传输**，以及增加了Host字段（使得一个服务器能够用来创建多个Web站点）

---

**3 HTTP2.0**

HTTP2.0新特性如下：

**3.1 二进制分帧**

HTTP2.0通过在应用层和传输层之间增加一个二进制分层帧，突破了HTTP1.1的性能限制，改进传输性能。

在二进制分帧层上，HTTP 2.0 会将所有传输的信息分割为更小的消息和帧,并对它们采用二进制格式的编码 ，其中HTTP1.x的首部信息会被封装到Headers帧，而我们的request body则封装到Data帧里面。

![img](https://tva1.sinaimg.cn/large/0081Kckwly1glqp2uf7d2j30hd090q3r.jpg)

然后，HTTP 2.0 通信都在一个连接上完成，这个连接可以承载任意数量的双向数据流。相应地，每个数据流以消息的形式发送，而消息由一或多个帧组成，这些帧可以乱序发送，然后再根据每个帧首部的流标识符重新组装。



**3.2 多路复用（链接共享）——真并行传输**

   **流（stream）**：已建立连接上的双向字节流。

   **消息**：与逻辑消息对应的完整的**一系列数据帧**。

   **帧（frame）**：HTTP2.0通信的最小单位，每个帧包含头部，至少也会标识出当前所属的流（stream_id）



所有HTTP2.0通信都在一个TCP链接上完成，这个链接可以撑在任意流量的双向数据流。

**每个数据流以消息的形式发送，而消息由一或多个帧组成。这些帧可以乱序发送，然后再根据每个帧头部的流标识符（Stream_id）重新封装。**

多路复用（连接共享）可能会导致关键字被阻塞，HTTP2.0里每个数据流都可以设置优先级和依赖，优先级高的数据流会被服务器优先处理和返回客户端，数据流还可以依赖其他的子数据流。

**可见，HTTP2.0实现了真正的并行传输，它能够在一个TCP上进行任意数量的HTTP请求。而这个强大的功能基于“二级制分帧”的特性。**

**3.3 头部压缩**

在HTTP1.X中，头部元数据都是以纯文本的形式发送的，通常会给每个请求增加500-8000字节的负荷。

比如cookie，默认情况下，浏览器会在每次请求的时候，把cookie附在header上面发给服务器。

HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header_files表，既避免重复header的传输，又减少了需要传输的大小。

高效的压缩算法可以很大的压缩header，减少发送包的数量从而降低延迟。

**3.4 服务器推送**

服务器除了最初请求的响应外，服务器还可以额外向客户端推送资源，而无需客户端明确的需求。

HTTP 2.0 新增的一个强大的新功能，就是服务器可以对一个客户端请求发送多个响应。换句话说，除了对最初请求的响应外，服务器还可以额外向客户端推送资源，而无需客户端明确地请求。

有了HTTP2.0的服务器推送，HTTP1.x时代的内嵌资源的优化手段也变得没有意义了。而且使用服务器推送的资源的方式更加高效，因为客户端还可以缓存起来，甚至可以由不同的页面共享（依旧遵循同源策略）。



#### **HTTP2.0的请求优先级**

每个HTTP2.0流里面有个优先值，这个优先值确定着客户端和服务器处理不同的流采取不同的优先级策略，高优先级的流都应该优先发送，但又不会绝对的。绝对地准守，可能又会引入首队阻塞的问题：高优先级的请求慢导致阻塞其他资源交付。分配处理资源和客户端与服务器间的带宽，不同优先级的混合也是必须的。



**引申问题：HTTP1.1的合并请求（如CSSsprites）是否适用于HTTP2.0**

没有必要。

在头部压缩技术总，客户端和服务器均会维护两份相同的**静态字典**和**动态字典**。

在静态字典中，包含了常见的头部名称与值的组合。静态字典在首次请求时可以使用。那么现在头部的字段就可以被简写成静态字典中相应字段的index。

而动态字典跟连接的上下文相关，每个HTTP/2连接维护的动态字典不尽相同。动态字典可以在连接不停地进行更新。

也就是说，原本完整的HTTP报文头部的键值或字段，由于字典的存在，现在可以转换成索引index，在相应的端再进行查找还原，也就起到了压缩的作用。

所以，**同一个链接上产生的请求和响应越多，动态字典累积得越全，头部压缩的效果也就越好**，所以**针对HTTP/2网站，最佳实践是不要合并资源**。

另外，HTTP2.0多路复用，使得请求可以并行传输，而HTTP1.1合并请求的一个原因也是为了防止过多的HTTP请求带来的阻塞问题。而现在HTTP2.0已经能够并行传输了，所以合并请求也就没有必要了。

----

**4 HTTP3.0**

**为什么要有HTTP3.0：HTTP/2底层TCP的局限带来的问题**

由于HTTP/2使用了多路复用，一般来说，同一个域名下只需要使用一个TCP链接，但当这个连接中出现了丢包的情况，就会导致HTTP/2的表现情况反倒不如HTTP/2了。

原因是：

**在出现丢包的额情况下，整个TCP都要开始等待重传，导致后面的所有数据都被阻塞。**

但是对于HTTP/1.1来说，可以开启多个TCP连接，出现这种情况只会影响其中一个连接，剩余的TCP链接还可以正常传输数据。

由于修改TCP协议是不可能完成的任务。

Google搞了一个基于UDP协议的QUIC协议，并且使用在了HTTP/3上， HTTP/3之前的名称为HTTP-over-QUIC。

早期Quic协议，存在IETF和Google两个版本，直到它被证实命名为HTTP3.0：



＞IETF的QUIC工作小组创造了QUIC传输协议。QUIC是一个使用UDP来替代TCP的协议。最初的时候，Google开始助力QUIC，其后QUIC更多地被叫做“HTTP/2-encrypted-over-UDP “。 ＞社区中的人们已经使用非正式名称如iQUIC和gQUIC来指代这些不同版本的协议，以将QUIC协议与IETF和Google分开（因为它们在细节上差异很大）。通过“iQUIC”发送HTTP的协议被称为“HQ”（HTTP-over-QUIC）很长一段时间。 ＞2018年11月7日，Litespeed的Dmitri宣布他们和Facebook已经成功地完成了两个HTTP/3实现之间的第一次互操作。Mike Bihop在该主题的HTTPBIS会话中的后续介绍可以在这里看到。会议结束时达成共识称新名称是HTTP/3！



**4.1 0-RTT——QUIC协议相比HTTP2.0的最大优势**

缓存当前会话的上下文，下次恢复会话的时候，只需要将之前的缓存传递给服务器，验证通过，就可以进行传输了。

0-RTT建连可以说是QUIC相比HTTP2最大的性能优势。

什么是0-RTT建连？



＞传输层0-RTT就能建立连接 ＞加密层0-RTT就能建立加密连接



**4.2 多路复用**

QUIC基于UDP，一个连接上的多个stream之间没有依赖，即使丢包，只需要重发丢失的包即可，不需要重传整个连接。

**4.3 更好的移动端表现**

QUIC在移动端的表现比TCP好，因为TCP是基于IP识别连接，而QUIC是通过ID识别链接。

无论网络环境如何变化，只要ID不便，就能迅速重新连上。

**4.4 加密认证的根文——武装到牙齿**

TCP协议头没有经过任何加密和认证，在传输过程中很容易被中间网络设备篡改、注入和窃听。

QUIC的packet可以说武装到了牙齿，除了个别报文，比如PUBLIC_RESET和CHLO，所有报文头部都是经过认证的，报文Body都是经过加密的。

所以只要对 QUIC 做任何更改，接收端都能及时发现，有效地降低了安全风险。

**4.5 向前纠错机制**

QUIC协议有一个非常独特的特性，成为向前纠错（Foward Error Connec，FEC），每个数据包除了它本身的内容之外还包括了其他数据包的数据，因此少量的丢包可以通过其他包的冗余数据直接组装而无需重传。

向前纠错牺牲了每个数据包可以发送数据的上限，但是带来的提升大于丢包导致的数据重传，因为数据重传将会消耗更多的时间（包括确认数据包丢失，请求重传，等待新数据包等步骤的时间消耗）。

例如：

我总共发送三个包，协议会算出这个三个包的异或值并单独发出一个校验包，也就是总共发出了四个包。

当其中出现了非校验包丢失的情况，可以通过另外三个包计算出丢失的数据包的内容。

当然这种技术只能使用在丢失一个包的情况下，如果出现丢失多个包，就不能使用纠错机制了，只能使用重传的方式了。



---

#### 5 总结

**HTTP1.0**

无状态，无连接

**HTTP1.1**

持久连接

请求管道化

增加缓存处理（新的字段如cache-control）

增加Host字段，支持断点传输等

**HTTP2.0**

二进制分帧

多路复用（或连接共享）

头部压缩

服务器推送（Sever push）

**HTTP3.0**

基于UDP实现

0RTT建连

基于UDP的多路复用

加密认证的报文

向前纠错机制

---



# [HTTP/1.1-HTTP/2.0-HTTP/3.0-HTTPS](https://www.cnblogs.com/qbits/p/11192401.html)

## HTTP/1.1

网上关于HTTP/1.1的讨论多是基于RFC2616文档，而IETF已更新了HTTP/1.1并将其分为六个部分，使协议变得更简单易懂，对老版本RFC2616中模糊不清的部分做了解释

- RFC7230-消息语法与路由
- RFC7231-语义与路由
- RFC7232-条件请求
- RFC7233-范围请求
- RFC7234-缓存
- RFC7235-认证

### RFC7230-消息语法与路由

#### 客户端/服务器 消息发送

HTTP是一种在传输层或会话层上交换消息的无状态的请求/响应协议，HTTP使用URI来定位资源和资源间的关系，通常请求会包含请求行，请求首部和请求体，下面的例子是在"http://www.example.com/hello.txt"上进行的GET请求

客户端请求:

```
GET /hello.txt HTTP/1.1   
User-Agent: curl/7.16.3 libcurl/7.16.3 OpenSSL/0.9.7l zlib/1.2.3   
Host: www.example.com Accept-Language: en, mi  
```

服务器响应：

```
HTTP/1.1 200 OK 
Date: Mon, 27 Jul 2009 12:28:53 GMT 
Server: Apache 
Last-Modified: Wed, 22 Jul 2009 19:15:56 GMT 
ETag: "34aa387-d-1568eb00" 
Accept-Ranges: bytes 
Content-Length: 51 
Vary: Accept-Encoding 
Content-Type: text/plain 

Hello World! My payload includes a trailing CRLF.
```

### RFC7231-语义与路由

#### 安全方法

如果请求方法语义上是只读的，那么它被认为是安全的，根据之前定义，GET，HEAD，OPTIONS，TRACE是安全的

#### 幂等方法

如果多个相同的请求方法对服务器的效果与单个请求对服务器的效果相同，则该请求方法是幂等的，根据定义PUT，DELETE与安全方法是幂等的

#### 可缓存方法

当请求方法的响应允许被缓存以供未来复用时，该请求方法是可缓存的。通常，不依赖当前或权威响应的安全方法被认为是可缓存的，本规范定义GET，HEAD，POST为可缓存的，虽然大多数缓存实现只支持GET和HEAD

#### GET

GET是主要的信息取回机制，客户端可以将GET语义改变为"范围请求"，请求被选定representation的一部分

#### HEAD

HEAD与GET方法几乎一样，但其响应中没有消息体，通常被用于测试连接性，可访问性和最近修改情况

#### POST

POST通常被用于提交表单，发布消息以及创建资源，添加数据到资源已存在的representation上，当有多个资源在源服务器上被创建时，源服务器**应该**发送201响应
POST请求的响应只有包含explicit freshness information（4.2.1 of [RFC7234]）的时候才被定义为可缓存的，然而POST缓存并没有被广泛实现，当源服务器希望客户端能够缓存POST的结果以供之后的GET使用时，源服务器**可能**发送包含Content-Location且其值为POST的有效请求URI相同的200响应

## HTTPS

RFC2818：HTTP Over TSL

### HTTP与HTTPS不同

- HTTPS需要CA（Certificate Authority，数字证书认证机构） 申请证书，免费的很少
- HTTP默认80端口；HTTPS默认443端口
- HTTP使用http标识符；HTTPS使用https标识符
- HTTP是明文传输；HTTPS是加密传输
- HTTP响应比HTTPS快，因为HTTPS还需要TSL握手，所以HTTPS更耗费服务器资源

## HTTP/1.1与HTTP/2.0

HTTP/1.1默认开启Connection： keep-alive，支持长连接（持久连接）和请求Pipelining，可以在一个TCP连接上发送多个HTTP请求与响应。

- HTTP/1.x是基于文本解析的，HTTP/2.0是基于二进制解析的
- HTTP/2.0采用多路复用，很好的解决了浏览器限制同一个域名下的请求数量的问题
- HTTP/2.0采用Header压缩，HTTP/1.x的header携带大量信息且重复，HTTP/2.0的通信双方各执一份header fields缓存，减少了传输大小与重复header的传输
- HTTP/2.0服务端推送减少了请求次数，减少请求次数

## 附录

### 面试问答

#### GET和POST有什么区别

答：

- GET参数通过URL传递，POST放在Request body中
- GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息
- GET是安全的且是幂等的，POST则不是
- GET产生的URL地址可以被Bookmark，而POST不可以
- GET请求会被浏览器主动cache，而POST不会，除非手动设置
- GET请求只能进行url编码，而POST支持多种编码方式

#### HTTP/1.x与HTTP/2.0区别

答：

- HTTP/2.0基于二进制解析，而HTTP/1.x仅支持文本解析
- HTTP/2.0支持多路复用
- HTTP/2.0支持服务端推送
- HTTP/2.0支持Header压缩

### 参考链接

- [RFC](https://tools.ietf.org/)
- [HTTP/1.1 rfc(7230-7237) 中文翻译](https://github.com/pearzl/HTTP11_chinese)
- [都 2019 年了，还问 GET 和 POST 的区别](https://blog.fundebug.com/2019/02/22/compare-http-method-get-and-post/)
- [HTTP 与 HTTPS 的区别](https://www.runoob.com/w3cnote/http-vs-https.html)
- [HTTP1.0、HTTP1.1 和 HTTP2.0 的区别](https://juejin.im/entry/5981c5df518825359a2b9476)
- [一文读懂 HTTP/2 及 HTTP/3 特性](https://blog.fundebug.com/2019/03/07/understand-http2-and-http3/)



---



### HTTP1.0、HTTP2.0、HTTP 3.0及HTTPS简要介绍

HTTP 建立之初，是为了将超文本标记语言(HTML)文档从Web服务器传送到客户端的浏览器。但随着CSS,Javascript的出现，以及移动互联时代的到来，我们不得不对HTTP进行不断地优化。

**HTTP优化：**
影响一个 HTTP 网络请求的因素主要有两个方面：带宽和延迟。
随着网络基础建设的完善，带宽因素已经不需要再考虑，仅需要考虑的就是**延迟**。延迟主要受三个方面影响：浏览器阻塞（HOL blocking）, DNS查询（DNS Lookup）,建立连接（Initial connection）.

#### 1 HTTP1.0及HTTPS

##### （1）HTTP1.0

- 请求与响应支持 HTTP 头，响应含状态行，增加了状态码，
- 支持 HEAD，POST 方法
- 支持传输 HTML 文件以外其他类型的内容

HTTP1.0 使用的是非持久连接，主要缺点是**客户端必须为每一个待请求的对象建立并维护一个新的连接**，即每请求一个文档就要有两倍RTT 的开销。因为同一个页面可能存在多个对象，所以非持久连接可能使一个页面的下载变得十分缓慢，而且这种 短连接增加了网络传输的负担。

**注：**
RTT(Round Trip Time)：一个连接的往返时间，即数据发送时刻到接收到确认的时刻的差值；

##### （2）HTTP1.1

- 支持长连接。
- 在HTTP1.0的基础上引入了更多的缓存控制策略。
- 引入了请求范围设置，优化了带宽。
- 在错误通知管理中新增了错误状态响应码。
- 增加了Host头处理，可以传递主机名（hostname）。

**缺点：**
传输内容是明文，不够安全

##### （3）HTTPS

- HTTPS运行在安全套接字协议(Secure Sockets Layer，SSL )或传输层安全协议（Transport Layer Security，TLS）之上，所有在TCP中传输的内容都需要经过加密。
- 连接方式不同，HTTP的端口是80，HTTPS的端口是443.
- HTTPS可以有效防止运营商劫持。

**注：**
SSL运行在TCP之上

##### （4）HTTP 1.x优化（SPDY）

SPDY 并不是新的一种协议，而是在 HTTP 之前做了一层会话层。为了达到减少页面加载时间的目标，SPDY 引入了一个新的二进制分帧数据层，以实现优先次序、最小化及消除不必要的网络延迟，目的是更有效地利用底层 TCP 连接。

- 多路复用，为多路复用设立了请求优先级。
- 对header部分进行了压缩。
- 引入了HTTPS加密传输。
- 客户端可以在缓存中取到之前请求的内容。

参考博客：[HTTP的前世今生](https://www.sohu.com/a/275505518_497161)

#### 2 HTTP2.0（SPDY的升级版）

- HTTP2.0支持明文传输，而HTTP 1.X强制使用SSL/TLS加密传输。
- 和HTTP 1.x使用的header压缩方法不同。
- HTTP2.0 基于二进制格式进行解析，而HTTP 1.x基于文本格式进行解析。
- 多路复用，HTTP1.1是多个请求串行化单线程处理，HTTP 2.0是并行执行，一个请求超时并不会影响其他请求。

**HTTP2.0的多路复用提升了网页性能：**

- 在 HTTP1 中浏览器限制了同一个域名下的请求数量（Chrome下一般是六个），当在请求很多资源的时候，由于队头阻塞，当浏览器达到最大请求数量时，剩余的资源需等待当前的六个请求完成后才能发起请求。
- HTTP2 中引入了多路复用的技术，这个技术可以只通过一个 TCP连接就可以传输所有的请求数据。多路复用可以绕过浏览器限制同一个域名下的请求数量的问题，进而提高了网页的性能。

**注意：**

- 主流浏览器只支持基于TLS部署的HTTP2.0协议，所以要将网站升级为HTTP 2.0，就需要先升级为HTTPS。
- HTTP 2.0完全兼容HTTP 1.x,所以对于部署了HTTP 2.0的网站可以自动向下兼容HTTP 1.X.

参考博客：[HTTP1.0、HTTP1.1 和 HTTP2.0 的区别](https://www.cnblogs.com/heluan/p/8620312.html)

#### 3 HTTP 3.0 (QUIC)

QUIC (Quick UDP Internet Connections), 快速 UDP 互联网连接。
QUIC是基于UDP协议的。

两个主要特性：
**（1）线头阻塞(HOL)问题的解决更为彻底：**
基于TCP的HTTP/2，尽管从逻辑上来说，不同的流之间相互独立，不会相互影响，但在实际传输方面，数据还是要一帧一帧的发送和接收，一旦某一个流的数据有丢包，则同样会阻塞在它之后传输的流数据传输。而基于UDP的QUIC协议则可以更为彻底地解决这样的问题，让不同的流之间真正的实现相互独立传输，互不干扰。
**（2）切换网络时的连接保持：**
当前移动端的应用环境，用户的网络可能会经常切换，比如从办公室或家里出门，WiFi断开，网络切换为3G或4G。基于TCP的协议，由于切换网络之后，IP会改变，因而之前的连接不可能继续保持。而基于UDP的QUIC协议，则可以内建与TCP中不同的连接标识方法，从而在网络完成切换之后，恢复之前与服务器的连接。

参考博客：
[1] [QUIC协议浅析与HTTP/3.0](https://www.jianshu.com/p/bb3eeb36b479)
[2] [HTTP3.0](https://www.cnblogs.com/chenjinxinlove/p/10104854.html)



---

# HTTP协议

HTTP（超文本传输协议，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。所有的WWW文件都必须遵守这个标准。设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。是用于从WWW服务器传输超文本到本地浏览器的传输协议。默认使用80端口，HTTP客户端发起一个请求，建立一个到服务器指定端口（默认是80端口）的TCP连接。HTTP协议和TCP协议是不冲突的，HTTP定义在七层协议中的应用层，TCP解决的是传输层的逻辑。HTTP使用TCP而不是UDP的原因在于（打开）一个网页必须传送很多数据，而TCP协议提供传输控制，按顺序组织数据，和错误纠正。HTTP协议的瓶颈及其优化技巧都是基于TCP协议本身的特性。如TCP建立连接时三次握手有1.5个RTT（round-trip time）的延迟，为了避免每次请求的都经历握手带来的延迟，应用层会选择不同策略的http长链接方案。又如TCP在建立连接的初期有慢启动（slow start）的特性，所以连接的重用总是比新建连接性能要好。

HTTP连接使用的是“请求—响应”的方式，不仅在请求时需要先建立连接，而且需要客户端向服务器发出请求后，服务器端才能回复数据。HTTP/1.0是第一个在通讯中指定版本号的HTTP 协议版本，至今仍被广泛采用，特别是在代理服务器中。HTTP/1.1是当前版本，持久连接被默认采用，并能很好地配合代理服务器工作，还支持以管道方式同时发送多个请求，以便降低线路负载，提高传输速度。HTTP／2.0在HTTP 1.x的基础上，大幅度的提高了web性能，减少了网络延迟。HTTP1.0和1.1在之后很长的一段时间内会一直并存，这是由于网络基础设施更新缓慢所决定的。

## TCP三次握手&四次分手

### 1建立连接。

客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认；

### 2第二次握手

服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态；

### 3 第三次握手

客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。

### 为什么要三次握手

为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。

具体例子：“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”

## 四次挥手

#### 1第一次分手

主机1（可以使客户端，也可以是服务器端），设置Sequence Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了；

#### 2第二次分手

主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求；

#### 3第三次分手

主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态；

#### 4第四次分手

主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。

#### 为什么要四次分手

TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP是全双工模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回ACK报文段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的；当主机2也发送了FIN报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。

## HTTP1.0

HTTP 协议老的标准是HTTP/1.0，为了提高系统的效率，HTTP 1.0规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求。但是，这也造成了一些性能上的缺陷，例如，一个包含有许多图像的网页文件中并没有包含真正的图像数据内容，而只是指明了这些图像的URL地址，当WEB浏览器访问这个网页文件时，浏览器首先要发出针对该网页文件的请求，当浏览器解析WEB服务器返回的该网页文档中的HTML内容时，发现其中的图像标签后，浏览器将根据标签中的src属性所指定的URL地址再次向服务器发出下载图像数据的请求。显 然，访问一个包含有许多图像的网页文件的整个过程包含了多次请求和响应，每次请求和响应都需要建立一个单独的连接，每次连接只是传输一个文档和图像，上一次和下一次请求完全分离。即使图像文件都很小，但是客户端和服务器端每次建立和关闭连接却是一个相对比较费时的过程，并且会严重影响客户机和服务器的性能。当一个网页文件中包含JavaScript文件，CSS文件等内容时，也会出现类似上述的情况。

同时，带宽和延迟也是影响一个网络请求的重要因素。在网络基础建设已经使得带宽得到极大的提升的当下，大部分时候都是延迟在于响应速度。基于此会发现，http1.0被抱怨最多的就是连接无法复用，和head of line blocking这两个问题。理解这两个问题有一个十分重要的前提：客户端是依据域名来向服务器建立连接，一般PC端浏览器会针对单个域名的server同时建立6～8个连接，手机端的连接数则一般控制在4～6个。显然连接数并不是越多越好，资源开销和整体延迟都会随之增大。连接无法复用会导致每次请求都经历三次握手和慢启动。三次握手在高延迟的场景下影响较明显，慢启动则对文件类大请求影响较大。head of line blocking会导致带宽无法被充分利用，以及后续健康请求被阻塞。

head of line blocking(holb)会导致健康的请求会被不健康的请求影响，而且这种体验的损耗受网络环境影响，出现随机且难以监控。为了解决holb带来的延迟，协议设计者设计了一种新的pipelining机制。pipelining只能适用于http1.1,而且由于使用苛刻，很多浏览器厂商并不支持

## HTTP1.1

为了克服HTTP 1.0的这个缺陷，HTTP 1.1支持持久连接（HTTP/1.1的默认模式使用带流水线的持久连接），在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。一个包含有许多图像的网页文件的多个请求和应答可以在一个连接中传输，但每个单独的网页文件的请求和应答仍然需要使用各自的连接。HTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间。

在http1.1，request和reponse头中都有可能出现一个connection的头，此header的含义是当client和server通信时对于长链接如何进行处理。
在http1.1中，client和server都是默认对方支持长链接的， 如果client使用http1.1协议，但又不希望使用长链接，则需要在header中指明connection的值为close；如果server方也不想支持长链接，则在response中也需要明确说明connection的值为close。不论request还是response的header中包含了值为close的connection，都表明当前正在使用的tcp链接在当天请求处理完毕后会被断掉。以后client再进行新的请求时就必须创建新的tcp链接了。

HTTP 1.1在继承了HTTP 1.0优点的基础上，也克服了HTTP 1.0的性能问题。HTTP 1.1通过增加更多的请求头和响应头来改进和扩充HTTP 1.0的功能。如，HTTP 1.0不支持Host请求头字段，WEB浏览器无法使用主机头名来明确表示要访问服务器上的哪个WEB站点，这样就无法使用WEB服务器在同一个IP地址和端口号上配置多个虚拟WEB站点。在HTTP 1.1中增加Host请求头字段后，WEB浏览器可以使用主机头名来明确表示要访问服务器上的哪个WEB站点，这才实现了在一台WEB服务器上可以在同一个IP地址和端口号上使用不同的主机名来创建多个虚拟WEB站点。HTTP 1.1的持续连接，也需要增加新的请求头来帮助实现，例如，Connection请求头的值为Keep-Alive时，客户端通知服务器返回本次请求结果后保持连接；Connection请求头的值为close时，客户端通知服务器返回本次请求结果后关闭连接。HTTP 1.1还提供了与身份认证、状态管理和Cache缓存等机制相关的请求头和响应头。HTTP/1.0不支持文件断点续传，`RANGE:bytes`是HTTP/1.1新增内容，HTTP/1.0每次传送文件都是从文件头开始，即0字节处开始。`RANGE:bytes=XXXX`表示要求服务器从文件XXXX字节处开始传送，这就是我们平时所说的断点续传！

由上，HTTP/1.1相较于 HTTP/1.0 协议的区别主要体现在：

1 缓存处理

2 带宽优化及网络连接的使用

3 错误通知的管理

4 消息在网络中的发送

5 互联网地址的维护

6 安全性及完整性

常用的请求方式

GET 请求获取Request-URI所标识的资源

POST 在Request-URI所标识的资源后附加新的数据

HEAD 请求获取由Request-URI所标识的资源的响应消息报头

PUT 请求服务器存储一个资源，并用Request-URI作为其标识

DELETE 请求服务器删除Request-URI所标识的资源

TRACE 请求服务器回送收到的请求信息，主要用于测试或诊断

CONNECT 保留将来使用

OPTIONS 请求查询服务器的性能，或者查询与资源相关的选项和需求

## HTTP2.0

使用HTTP2.o测试便可看出HTTP2.0比之前的协议在性能上有很大的提升。下面总结了HTTP2.0协议的几个特性。

多路复用 (Multiplexing)

多路复用允许同时通过单一的 HTTP/2 连接发起多重的请求-响应消息。在 HTTP/1.1 协议中浏览器客户端在同一时间，针对同一域名下的请求有一定数量限制。超过限制数目的请求会被阻塞。这也是为何一些站点会有多个静态资源 CDN 域名的原因之一，拿 Twitter 为例，http://twimg.com，目的就是变相的解决浏览器针对同一域名的请求限制阻塞问题。而 HTTP/2 的多路复用(Multiplexing) 则允许同时通过单一的 HTTP/2 连接发起多重的请求-响应消息。因此 HTTP/2 可以很容易的去实现多流并行而不用依赖建立多个 TCP 连接，HTTP/2 把 HTTP 协议通信的基本单位缩小为一个一个的帧，这些帧对应着逻辑流中的消息。并行地在同一个 TCP 连接上双向交换消息。

二进制分帧

HTTP/2在 应用层(HTTP/2)和传输层(TCP or UDP)之间增加一个二进制分帧层。在不改动 HTTP/1.x 的语义、方法、状态码、URI 以及首部字段的情况下, 解决了HTTP1.1 的性能限制，改进传输性能，实现低延迟和高吞吐量。在二进制分帧层中， HTTP/2 会将所有传输的信息分割为更小的消息和帧（frame）,并对它们采用二进制格式的编码 ，其中 HTTP1.x 的首部信息会被封装到 HEADER frame，而相应的 Request Body 则封装到 DATA frame 里面。

HTTP/2 通信都在一个连接上完成，这个连接可以承载任意数量的双向数据流。在过去， HTTP 性能优化的关键并不在于高带宽，而是低延迟。TCP 连接会随着时间进行自我调谐，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度。这种调谐则被称为 TCP 慢启动。由于这种原因，让原本就具有突发性和短时性的 HTTP 连接变的十分低效。HTTP/2 通过让所有数据流共用同一个连接，可以更有效地使用 TCP 连接，让高带宽也能真正的服务于 HTTP 的性能提升。

这种单连接多资源的方式，减少服务端的链接压力,内存占用更少,连接吞吐量更大；而且由于 TCP 连接的减少而使网络拥塞状况得以改善，同时慢启动时间的减少,使拥塞和丢包恢复速度更快。
首部压缩（Header Compression）

HTTP/1.1并不支持 HTTP 首部压缩，为此 SPDY 和 HTTP/2 应运而生， SPDY 使用的是通用的DEFLATE 算法，而 HTTP/2 则使用了专门为首部压缩而设计的 HPACK 算法。
服务端推送（Server Push）

服务端推送是一种在客户端请求之前发送数据的机制。在 HTTP/2 中，服务器可以对客户端的一个请求发送多个响应。Server Push 让 HTTP1.x 时代使用内嵌资源的优化手段变得没有意义；如果一个请求是由你的主页发起的，服务器很可能会响应主页内容、logo 以及样式表，因为它知道客户端会用到这些东西。这相当于在一个 HTML 文档内集合了所有的资源，不过与之相比，服务器推送还有一个很大的优势：可以缓存！也让在遵循同源的情况下，不同页面之间可以共享缓存资源成为可能。

## https加密

### HTTPS加密请求（一次握手）过程

- 1首先，客户端发起握手请求，以明文传输请求信息，包含版本信息，加密-套件候选列表，压缩算法候选列表，随机数，扩展字段等信息(这个没什么好说的，就是用户在浏览器里输入一个HTTPS网址，然后连接到服务端的443端口。)
- 2服务端的配置，采用HTTPS协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面。这套证书其实就是一对公钥和私钥。如果对公钥不太理解，可以想象成一把钥匙和一个锁头，只是世界上只有你一个人有这把钥匙，你可以把锁头给别人，别人可以用这个锁把重要的东西锁起来，然后发给你，因为只有你一个人有这把钥匙，所以只有你才能看到被这把锁锁起来的东西。
- 3 服务端返回协商的信息结果，包括选择使用的协议版本 version，选择的加密套件 cipher suite，选择的压缩算法 compression method、随机数 random_S 以及证书。(这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等等。)
  客户端验证证书的合法性，包括可信性，是否吊销，过期时间和域名。(这部分工作是由客户端的SSL/TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警示框，提示证书存在的问题。如果证书没有问题，那么就生成一个随机值。然后用证书（也就是公钥）对这个随机值进行加密。就好像上面说的，把随机值用锁头锁起来，这样除非有钥匙，不然看不到被锁住的内容。)
- 4客户端使用公匙对对称密匙加密，发送给服务端。(这部分传送的是用证书加密后的随机值，目的是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。)
  服务器用私钥解密，拿到对称加密的密匙。(服务端用私钥解密后，得到了客户端传过来的随机值，然后把内容通过该随机值进行对称加密，将信息和私钥通过某种算法混合在一起，这样除非知道私钥，不然无法获取内容，而正好客户端和服务端都知道这个私钥，所以只要加密算法够彪悍，私钥够复杂，数据就够安全。)
  5传输加密后的信息，这部分信息就是服务端用私钥加密后的信息，可以在客户端用随机值解密还原。
  客户端解密信息，客户端用之前生产的私钥解密服务端传过来的信息，于是获取了解密后的内容。整个过程第三方即使监听到了数据，也束手无策。



##### HTTP1.0、HTTP1.1、HTTP2.0、HTTP3.0的区别？

```java
（1）HTTP1.0和HTTP1.1的区别：

HTTP1.0默认使用短连接，HTTP1.1开始默认使用长连接
HTTP1.1增加更多的请求头和响应头来改进和扩充HTTP1.0的功能，比如身份认证、状态管理和Cache缓存等

（2）HTTP2.0和HTTP1.X相比的新特性：

新的二进制格式：HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮，不同于HTTP1.x的解析是基于文本
多路复用：连接共享，即每一个request都是是用作连接共享机制的
服务端推送：服务器主动向客户端推送消息
```



#####  HTTP3.0有什么改进

```
尽管HTTP/2解决了很多1.1的问题，但HTTP/2仍然存在一些缺陷，这些缺陷并不是来自于HTTP/2协议本身，而是来源于底层的TCP协议，我们知道TCP链接是可靠的连接，如果出现了丢包，那么整个连接都要等待重传，HTTP/1.1可以同时使用6个TCP连接，一个阻塞另外五个还能工作，但HTTP/2只有一个TCP连接，阻塞的问题便被放大了。

由于TCP协议已经被广泛使用，我们很难直接修改TCP协议，基于此，HTTP/3选择了一个折衷的方法——UDP协议，HTTP/2在UDP的基础上实现多路复用、0-RTT、TLS加密、流量控制、丢包重传等功能。
```



----

#### HTTP2.0性能增强的核心：二进制分帧

HTTP 2.0最大的特点： 不会改动HTTP 的语义，HTTP 方法、状态码、URI 及首部字段，等等这些核心概念上一如往常，却能致力于突破上一代标准的性能限制，改进传输性能，实现低延迟和高吞吐量。而之所以叫2.0，是在于新增的二进制分帧层。

既然又要保证HTTP的各种动词，方法，首部都不受影响，那就需要在应用层(HTTP2.0)和传输层(TCP or UDP)之间增加一个二进制分帧层。

在二进制分帧层上，HTTP 2.0 会将所有传输的信息分割为更小的消息和帧,并对它们采用二进制格式的编码 ，其中HTTP1.x的首部信息会被封装到Headers帧，而我们的request body则封装到Data帧里面。

![img](https://tva1.sinaimg.cn/large/0081Kckwly1glqp5fzl6uj30hd090q3r.jpg)

然后，HTTP 2.0 通信都在一个连接上完成，这个连接可以承载任意数量的双向数据流。相应地，每个数据流以消息的形式发送，而消息由一或多个帧组成，这些帧可以乱序发送，然后再根据每个帧首部的流标识符重新组装。

#### HTTP2.0 首部压缩

HTTP 2.0 在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键-值对，对于相同的数据，不再通过每次请求和响应发送;通信期间几乎不会改变的通用键-值对(用户代理、可接受的媒体类型,等等)只 需发送一次。事实上,如果请求中不包含首部(例如对同一资源的轮询请求),那么 首部开销就是零字节。此时所有首部都自动使用之前请求发送的首部。

如果首部发生变化了，那么只需要发送变化了数据在Headers帧里面，新增或修改的首部帧会被追加到“首部表”。首部表在 HTTP 2.0 的连接存续期内始终存在,由客户端和服务器共同渐进地更新 。

#### **有的HTTP2.0的请求都在一个TCP链接上**

HTTP2.0所有通信都是在一个TCP连接上完成。HTTP 2.0 把 HTTP 协议通信的基本单位缩小为一个一个的帧，这些帧对应 着逻辑流中的消息。并行地在同一个 TCP 连接上双向交换消息。就好比，我请求一个页面[http://www.qq.com](http://www.qq.com/)。页面上所有的资源请求都是客户端与服务器上的一条TCP上请求和响应的！

**有关注TCP性能的同学就会知道，HTTP性能的关键在于低延迟而不是高带宽！**大多数HTTP 连接的时间都很短，而且是突发性的，但TCP 只在长时间连接传输大块数据时效率才最高。HTTP 2.0 通过让所有数据流共用同一个连接，可以更有效地使用TCP 连接，让高带宽也能真正的服务于HTTP的性能提升。

同时，单链接多资源的方式，使到至上而下的层面都得到了好处：

1.可以减少服务链接压力,内存占用少了,连接吞吐量大了

2.由于 TCP 连接减少而使网络拥塞状况得以改观;

3.慢启动时间减少,拥塞和丢包恢复速度更快。

**也就是说，“资源合并减少请求”的优化手段对于HTTP2.0来说是没有效果的，只会增大无用的工作量而已。**

#### **并行双向字节流的请求和响应**

在HTTP2.0上，客户端和服务器可以把HTTP 消息分解为互不依赖的帧，然后乱序发送，最后再在另一端把它们重新组合起来。注意，同一链接上有多个不同方向的数据流在传输。客户端可以一边乱序发送stream，也可以一边接收者服务器的响应，而服务器那端同理。

![img](https://tva1.sinaimg.cn/large/0081Kckwly1glqp5e9o2rj30lv06c3z4.jpg)

把 HTTP 消息分解为独立的帧,交错发送,然后在另一端重新组装是 HTTP 2.0 最 重要的一项增强。事实上,这个机制会在整个 Web 技术栈中引发一系列连锁反应, 从而带来巨大的性能提升,因为:

可以并行交错地发送请求,请求之间互不影响;

可以并行交错地发送响应,响应之间互不干扰;

只使用一个连接即可并行发送多个请求和响应;

消除不必要的延迟,从而减少页面加载的时间;

**那么也就是说“域名分区”这种优化手段对于HTTP2.0是无用的，因为资源都是并行交错发送，且没有限制，不需要额外的多域名并行下载。**

#### **HTTP2.0的请求优先级**

每个HTTP2.0流里面有个优先值，这个优先值确定着客户端和服务器处理不同的流采取不同的优先级策略，高优先级的流都应该优先发送，但又不会绝对的。绝对地准守，可能又会引入首队阻塞的问题：高优先级的请求慢导致阻塞其他资源交付。分配处理资源和客户端与服务器间的带宽，不同优先级的混合也是必须的。

#### HTTP2.0的服务器推送

HTTP 2.0 新增的一个强大的新功能，就是服务器可以对一个客户端请求发送多个响应。换句话说，除了对最初请求的响应外，服务器还可以额外向客户端推送资源，而无需客户端明确地请求。

有了HTTP2.0的服务器推送，HTTP1.x时代的内嵌资源的优化手段也变得没有意义了。而且使用服务器推送的资源的方式更加高效，因为客户端还可以缓存起来，甚至可以由不同的页面共享（依旧遵循同源策略）。