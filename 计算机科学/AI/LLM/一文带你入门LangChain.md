[TOC]

# å¯¼è¯­

åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸æ–­å‘å±•ä¸­ï¼Œè¯­è¨€æ¨¡å‹æ‰®æ¼”ç€é‡è¦çš„è§’è‰²ã€‚ç‰¹åˆ«æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå¦‚ChatGPTï¼Œå·²ç»æˆä¸ºç§‘æŠ€é¢†åŸŸçš„çƒ­é—¨è¯é¢˜ï¼Œå¹¶å—åˆ°å¹¿æ³›è®¤å¯ã€‚åœ¨è¿™ä¸ªèƒŒæ™¯ä¸‹ï¼ŒLangChainä½œä¸ºä¸€ä¸ªä»¥LLMæ¨¡å‹ä¸ºæ ¸å¿ƒçš„å¼€å‘æ¡†æ¶å‡ºç°ï¼Œä¸ºè‡ªç„¶è¯­è¨€å¤„ç†å¼€å¯äº†ä¸€ä¸ªå……æ»¡å¯èƒ½æ€§çš„ä¸–ç•Œã€‚å€ŸåŠ©LangChainï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºå„ç§åº”ç”¨ç¨‹åºï¼ŒåŒ…æ‹¬èŠå¤©æœºå™¨äººå’Œæ™ºèƒ½é—®ç­”å·¥å…·ã€‚

# 1. LangChainç®€ä»‹

## 1.1. LangChainå‘å±•å²

LangChain çš„ä½œè€…æ˜¯Harrison Chaseï¼Œæœ€åˆæ˜¯äº2022å¹´10æœˆå¼€æºçš„ä¸€ä¸ªé¡¹ç›®ï¼Œåœ¨ GitHub ä¸Šè·å¾—å¤§é‡å…³æ³¨ä¹‹åè¿…é€Ÿè½¬å˜ä¸ºä¸€å®¶åˆåˆ›å…¬å¸ã€‚2017 å¹´Harrison Chase è¿˜åœ¨å“ˆä½›ä¸Šå¤§å­¦ï¼Œå¦‚ä»Šå·²æ˜¯ç¡…è°·çš„ä¸€å®¶çƒ­é—¨åˆåˆ›å…¬å¸çš„ CEOï¼Œè¿™å¯¹ä»–æ¥è¯´æ˜¯ä¸€æ¬¡é‡å¤§è€Œè¿…é€Ÿçš„è·ƒè¿ã€‚Insiderç‹¬å®¶æŠ¥é“ï¼Œäººå·¥æ™ºèƒ½åˆåˆ›å…¬å¸ LangChainåœ¨ç§å­è½®ä¸€å‘¨åï¼Œå†æ¬¡è·å¾—çº¢æ‰é¢†æŠ•çš„2000ä¸‡è‡³2500ä¸‡ç¾å…ƒèèµ„ï¼Œä¼°å€¼è¾¾åˆ°2äº¿ç¾å…ƒã€‚ ![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a77ddd18e80748e6b28e5dc840dd1347~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

## 1.2. LangChainä¸ºä»€ä¹ˆè¿™ä¹ˆç«

LangChainç›®å‰æ˜¯æœ‰ä¸¤ä¸ªè¯­è¨€ç‰ˆæœ¬ï¼ˆpythonå’Œnodejsï¼‰,ä»ä¸‹å›¾å¯ä»¥çœ‹å‡ºæ¥ï¼ŒçŸ­çŸ­åŠå¹´çš„æ—¶é—´è¯¥é¡¹ç›®çš„pythonç‰ˆæœ¬å·²ç»è·å¾—äº†54k+çš„starã€‚nodejsç‰ˆæœ¬ä¹Ÿåœ¨çŸ­çŸ­4ä¸ªæœˆæ”¶è´§äº†7k+çš„starï¼Œè¿™æ— ç–‘åˆ©å¥½å‰ç«¯åŒå­¦ï¼Œä¸éœ€è¦ä¼špythonä¹Ÿèƒ½å¿«é€Ÿä¸Šæ‰‹LLMåº”ç”¨å¼€å‘ã€‚ ![img](https://p.ipic.vip/aqk7az.jpg) ç¬”è€…è®¤ä¸ºLangchainä½œä¸ºä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹åº”ç”¨å¼€å‘æ¡†æ¶ï¼Œè§£å†³äº†ç°åœ¨å¼€å‘äººå·¥æ™ºèƒ½åº”ç”¨çš„ä¸€äº›åˆ‡å®ç—›ç‚¹ã€‚ä»¥GPTæ¨¡å‹ä¸ºä¾‹ï¼š

1. æ•°æ®æ»åï¼Œç°åœ¨è®­ç»ƒçš„æ•°æ®æ˜¯åˆ° 2021 å¹´9æœˆã€‚
2. tokenæ•°é‡é™åˆ¶ï¼Œå¦‚æœè®©å®ƒå¯¹ä¸€ä¸ª300é¡µçš„pdfè¿›è¡Œæ€»ç»“ï¼Œç›´æ¥ä½¿ç”¨åˆ™æ— èƒ½ä¸ºåŠ›ã€‚
3. ä¸èƒ½è¿›è¡Œè”ç½‘ï¼Œè·å–ä¸åˆ°æœ€æ–°çš„å†…å®¹ã€‚
4. ä¸èƒ½ä¸å…¶ä»–æ•°æ®æºé“¾æ¥ã€‚ å¦å¤–ä½œä¸ºä¸€ä¸ªèƒ¶æ°´å±‚æ¡†æ¶ï¼Œæå¤§åœ°æé«˜äº†å¼€å‘æ•ˆç‡ï¼Œå®ƒçš„ä½œç”¨å¯ä»¥ç±»æ¯”äºjqueryåœ¨å‰ç«¯å¼€å‘ä¸­çš„è§’è‰²ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥æ›´ä¸“æ³¨äºåˆ›æ–°å’Œä¼˜åŒ–äº§å“åŠŸèƒ½ã€‚

## 1.3.LLMåº”ç”¨æ¶æ„

LangChianä½œä¸ºä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹å¼€å‘æ¡†æ¶ï¼Œæ˜¯LLMåº”ç”¨æ¶æ„çš„é‡è¦ä¸€ç¯ã€‚é‚£ä»€ä¹ˆæ˜¯LLMåº”ç”¨æ¶æ„å‘¢ï¼Ÿå…¶å®å°±æ˜¯æŒ‡åŸºäºè¯­è¨€æ¨¡å‹çš„åº”ç”¨ç¨‹åºè®¾è®¡å’Œå¼€å‘çš„æ¶æ„ã€‚ LangChianå¯ä»¥å°†LLMæ¨¡å‹ã€å‘é‡æ•°æ®åº“ã€äº¤äº’å±‚Promptã€å¤–éƒ¨çŸ¥è¯†ã€å¤–éƒ¨å·¥å…·æ•´åˆåˆ°ä¸€èµ·ï¼Œè¿›è€Œå¯ä»¥è‡ªç”±æ„å»ºLLMåº”ç”¨ã€‚

# 2. LangChainç»„ä»¶

![img](https://p.ipic.vip/s8py4c.jpg) å¦‚ä¸Šå›¾ï¼ŒLangChainåŒ…å«å…­éƒ¨åˆ†ç»„æˆï¼Œåˆ†åˆ«ä¸ºï¼šModelsã€Promptsã€Indexesã€Memoryã€Chainsã€Agentsã€‚

## 2.1. Modelsï¼ˆæ¨¡å‹ï¼‰

ä¸‹é¢æˆ‘ä»¬ä»¥å…·ä½“ç¤ºä¾‹åˆ†åˆ«é˜è¿°ä¸‹Chat Modals, Embeddings, LLMsã€‚

### 2.1.1. èŠå¤©æ¨¡å‹

LangChainä¸ºä½¿ç”¨èŠå¤©æ¨¡å‹æä¾›äº†ä¸€ä¸ªæ ‡å‡†æ¥å£ã€‚èŠå¤©æ¨¡å‹æ˜¯è¯­è¨€æ¨¡å‹çš„ä¸€ç§å˜ä½“ã€‚è™½ç„¶èŠå¤©æ¨¡å‹åœ¨å†…éƒ¨ä½¿ç”¨è¯­è¨€æ¨¡å‹ï¼Œä½†å®ƒä»¬æ‰€æä¾›çš„æ¥å£ç•¥æœ‰ä¸åŒã€‚å®ƒä»¬ä¸æ˜¯æš´éœ²ä¸€ä¸ª "è¾“å…¥æ–‡æœ¬ï¼Œè¾“å‡ºæ–‡æœ¬" çš„APIï¼Œè€Œæ˜¯æä¾›äº†ä¸€ä¸ªä»¥ "èŠå¤©æ¶ˆæ¯" ä½œä¸ºè¾“å…¥å’Œè¾“å‡ºçš„æ¥å£ã€‚ èŠå¤©æ¨¡å‹çš„æ¥å£æ˜¯åŸºäºæ¶ˆæ¯è€Œä¸æ˜¯åŸå§‹æ–‡æœ¬ã€‚LangChain ç›®å‰æ”¯æŒçš„æ¶ˆæ¯ç±»å‹æœ‰ AIMessageã€HumanMessageã€SystemMessage å’Œ ChatMessageï¼Œå…¶ä¸­ ChatMessage æ¥å—ä¸€ä¸ªä»»æ„çš„è§’è‰²å‚æ•°ã€‚å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæ‚¨åªéœ€è¦å¤„ç† HumanMessageã€AIMessage å’Œ SystemMessageã€‚

```python
python
å¤åˆ¶ä»£ç # å¯¼å…¥OpenAIçš„èŠå¤©æ¨¡å‹ï¼ŒåŠæ¶ˆæ¯ç±»å‹
from langchain.chat_models import ChatOpenAI
from langchain.schema import (
    AIMessage,
    HumanMessage,
    SystemMessage
)

# åˆå§‹åŒ–èŠå¤©å¯¹è±¡
chat = ChatOpenAI(openai_api_key="...")

# å‘èŠå¤©æ¨¡å‹å‘é—®
chat([HumanMessage(content="Translate this sentence from English to French: I love programming.")])
```

OpenAIèŠå¤©æ¨¡å¼æ”¯æŒå¤šä¸ªæ¶ˆæ¯ä½œä¸ºè¾“å…¥ã€‚è¿™æ˜¯ä¸€ä¸ªç³»ç»Ÿå’Œç”¨æˆ·æ¶ˆæ¯èŠå¤©æ¨¡å¼çš„ä¾‹å­:

```markdown
markdown
å¤åˆ¶ä»£ç messages = [
    SystemMessage(content="You are a helpful assistant that translates English to French."),
    HumanMessage(content="I love programming.")
]
chat(messages)
```

å½“ç„¶ä¹Ÿå¯ä»¥è¿›è¡Œæ‰¹é‡å¤„ç†ï¼Œæ‰¹é‡è¾“å‡ºã€‚

```python
python
å¤åˆ¶ä»£ç batch_messages = [
    [
        SystemMessage(content="You are a helpful assistant that translates English to French."),
        HumanMessage(content="I love programming.")
    ],
    [
        SystemMessage(content="You are a helpful assistant that translates English to French."),
        HumanMessage(content="I love artificial intelligence.")
    ],
]
result = chat.generate(batch_messages)
result
```

ä¸Šé¢ä»‹ç»äº†èŠå¤©çš„è§’è‰²å¤„ç†ä»¥åŠå¦‚ä½•è¿›è¡Œæ‰¹é‡å¤„ç†æ¶ˆæ¯ã€‚æˆ‘ä»¬éƒ½çŸ¥é“å‘openAIè°ƒç”¨æ¥å£éƒ½æ˜¯è¦èŠ±é’±çš„ï¼Œå¦‚æœç”¨æˆ·é—®åŒä¸€ä¸ªé—®é¢˜ï¼Œå¯¹ç»“æœè¿›è¡Œäº†ç¼“å­˜ï¼Œè¿™æ ·å°±å¯ä»¥å‡å°‘æ¥å£çš„è°ƒç”¨å¹¶ä¸”ä¹Ÿèƒ½åŠ å¿«æ¥å£è¿”å›çš„é€Ÿåº¦ã€‚LangChainä¹Ÿå¾ˆè´´å¿ƒçš„æä¾›äº†ç¼“å­˜çš„åŠŸèƒ½ã€‚å¹¶ä¸”æä¾›äº†ä¸¤ç§ç¼“å­˜æ–¹æ¡ˆï¼Œå†…å­˜ç¼“å­˜æ–¹æ¡ˆå’Œæ•°æ®åº“ç¼“å­˜æ–¹æ¡ˆï¼Œå½“ç„¶æ”¯æŒçš„æ•°æ®åº“ç¼“å­˜æ–¹æ¡ˆæœ‰å¾ˆå¤šç§ã€‚

```python
python
å¤åˆ¶ä»£ç # å¯¼å…¥èŠå¤©æ¨¡å‹ï¼ŒSQLiteCacheæ¨¡å—
import os
os.environ["OPENAI_API_KEY"] = 'your apikey'
import langchain
from langchain.chat_models import ChatOpenAI
from langchain.cache import SQLiteCache

# è®¾ç½®è¯­è¨€æ¨¡å‹çš„ç¼“å­˜æ•°æ®å­˜å‚¨çš„åœ°å€
langchain.llm_cache = SQLiteCache(database_path=".langchain.db")

# åŠ è½½ llm æ¨¡å‹
llm = ChatOpenAI()

# ç¬¬ä¸€æ¬¡å‘æ¨¡å‹æé—®
result = llm.predict('tell me a joke')
print(result)

# ç¬¬äºŒæ¬¡å‘æ¨¡å‹æé—®åŒæ ·çš„é—®é¢˜
result2 = llm.predict('tell me a joke')
print(result2)
```

å¦å¤–èŠå¤©æ¨¡å¼ä¹Ÿæä¾›äº†ä¸€ç§æµåª’ä½“å›åº”ã€‚è¿™æ„å‘³ç€,è€Œä¸æ˜¯ç­‰å¾…æ•´ä¸ªå“åº”è¿”å›,ä½ å°±å¯ä»¥å¼€å§‹å¤„ç†å®ƒå°½å¿«ã€‚

### 2.1.2. åµŒå…¥

è¿™ä¸ªæ›´å¤šçš„æ˜¯ç”¨äºæ–‡æ¡£ã€æ–‡æœ¬æˆ–è€…å¤§é‡æ•°æ®çš„æ€»ç»“ã€é—®ç­”åœºæ™¯ï¼Œä¸€èˆ¬æ˜¯å’Œå‘é‡åº“ä¸€èµ·ä½¿ç”¨ï¼Œå®ç°å‘é‡åŒ¹é…ã€‚å…¶å®å°±æ˜¯æŠŠæ–‡æœ¬ç­‰å†…å®¹è½¬æˆå¤šç»´æ•°ç»„ï¼Œå¯ä»¥åç»­è¿›è¡Œç›¸ä¼¼æ€§çš„è®¡ç®—å’Œæ£€ç´¢ã€‚ä»–ç›¸æ¯” fine-tuning æœ€å¤§çš„ä¼˜åŠ¿å°±æ˜¯ï¼Œä¸ç”¨è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”å¯ä»¥å®æ—¶æ·»åŠ æ–°çš„å†…å®¹ï¼Œè€Œä¸ç”¨åŠ ä¸€æ¬¡æ–°çš„å†…å®¹å°±è®­ç»ƒä¸€æ¬¡ï¼Œå¹¶ä¸”å„æ–¹é¢æˆæœ¬è¦æ¯” fine-tuning ä½å¾ˆå¤šã€‚ ä¸‹é¢ä»¥ä»£ç å±•ç¤ºä¸‹embeddingsæ˜¯ä»€ä¹ˆã€‚

```python
python
å¤åˆ¶ä»£ç # å¯¼å…¥os, è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå¯¼å…¥OpenAIçš„åµŒå…¥æ¨¡å‹
import os
from langchain.embeddings.openai import OpenAIEmbeddings
os.environ["OPENAI_API_KEY"] = 'your apikey'

# åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
embeddings = OpenAIEmbeddings()

# æŠŠæ–‡æœ¬é€šè¿‡åµŒå…¥æ¨¡å‹å‘é‡åŒ–
res = embeddings.embed_query('hello world')
/*
[
   -0.004845875,   0.004899438,  -0.016358767,  -0.024475135, -0.017341806,
    0.012571548,  -0.019156644,   0.009036391,  -0.010227379, -0.026945334,
    0.022861943,   0.010321903,  -0.023479493, -0.0066544134,  0.007977734,
   0.0026371893,   0.025206111,  -0.012048521,   0.012943339,  0.013094575,
   -0.010580265,  -0.003509951,   0.004070787,   0.008639394, -0.020631202,
  -0.0019203906,   0.012161949,  -0.019194454,   0.030373365, -0.031028723,
   0.0036170771,  -0.007813894, -0.0060778237,  -0.017820721, 0.0048647798,
   -0.015640393,   0.001373733,  -0.015552171,   0.019534737, -0.016169721,
    0.007316074,   0.008273906,   0.011418369,   -0.01390117, -0.033347685,
    0.011248227,  0.0042503807,  -0.012792102, -0.0014595914,  0.028356876,
    0.025407761, 0.00076445413,  -0.016308354,   0.017455231, -0.016396577,
    0.008557475,   -0.03312083,   0.031104341,   0.032389853,  -0.02132437,
    0.003324056,  0.0055610985, -0.0078012915,   0.006090427, 0.0062038545,
  ... 1466 more items
]
*/
```

ä¸‹å›¾æ˜¯LangChainä¸¤ç§è¯­è¨€åŒ…æ”¯æŒçš„embeddingsã€‚ ![img](https://p.ipic.vip/sozssp.jpg)

### 2.1.3. å¤§è¯­è¨€æ¨¡å‹

LLMSæ˜¯LangChainçš„æ ¸å¿ƒï¼Œä»å®˜ç½‘å¯ä»¥çœ‹åˆ°LangChainç»§æ‰¿äº†éå¸¸å¤šçš„å¤§è¯­è¨€æ¨¡å‹ã€‚ ![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d4b6e4cb6a8d40af9982e9269d35382e~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

## 2.2. Promptsï¼ˆæç¤ºè¯ï¼‰

### 2.2.1. Prompt Templates

LangChainæä¾›äº†PromptTemplatesï¼Œå…è®¸ä½ å¯ä»¥æ ¹æ®ç”¨æˆ·è¾“å…¥åŠ¨æ€åœ°æ›´æ”¹æç¤ºï¼Œå¦‚æœä½ æœ‰ç¼–ç¨‹åŸºç¡€ï¼Œè¿™åº”è¯¥å¯¹ä½ æ¥è¯´å¾ˆç®€å•ã€‚å½“ç”¨æˆ·éœ€è¦è¾“å…¥å¤šä¸ªç±»ä¼¼çš„ prompt æ—¶ï¼Œç”Ÿæˆä¸€ä¸ª prompt æ¨¡æ¿æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„è§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥èŠ‚çœç”¨æˆ·çš„æ—¶é—´å’Œç²¾åŠ›ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œå°† LLM ä½œä¸ºä¸€ä¸ªç»™æ–°å¼€å•†åº—å‘½åçš„é¡¾é—®ï¼Œç”¨æˆ·åªéœ€å‘Šè¯‰ LLM å•†åº—çš„ä¸»è¦ç‰¹ç‚¹ï¼Œå®ƒå°†è¿”å›10ä¸ªæ–°å¼€å•†åº—çš„åå­—ã€‚

```python
python
å¤åˆ¶ä»£ç from langchain.llms import OpenAI

# å®šä¹‰ç”Ÿæˆå•†åº—çš„æ–¹æ³•
def generate_store_names(store_features):
    prompt_template = "æˆ‘æ­£åœ¨å¼€ä¸€å®¶æ–°çš„å•†åº—ï¼Œå®ƒçš„ä¸»è¦ç‰¹ç‚¹æ˜¯{}ã€‚è¯·å¸®æˆ‘æƒ³å‡º10ä¸ªå•†åº—çš„åå­—ã€‚"
    prompt = prompt_template.format(store_features)

    llm = OpenAI()
    response = llm.generate(prompt, max_tokens=10, temperature=0.8)

    store_names = [gen[0].text.strip() for gen in response.generations]
    return store_names

store_features = "æ—¶å°šã€åˆ›æ„ã€ç‹¬ç‰¹"

store_names = generate_store_names(store_features)
print(store_names)
```

è¿™æ ·ï¼Œç”¨æˆ·åªéœ€å‘Šè¯‰ LLM å•†åº—çš„ä¸»è¦ç‰¹ç‚¹ï¼Œå°±å¯ä»¥è·å¾—10ä¸ªæ–°å¼€å•†åº—çš„åå­—ï¼Œè€Œæ— éœ€é‡å¤è¾“å…¥ç±»ä¼¼çš„ prompt å†…å®¹ã€‚å¦å¤–[LangChainHub](https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2Fhwchase17%2Flangchain-hub%2Ftree%2Fmaster%2Fprompts)åŒ…å«äº†è®¸å¤šå¯ä»¥é€šè¿‡LangChainç›´æ¥åŠ è½½çš„Prompt Templatesã€‚é¡ºä¾¿æˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡å­¦ä¹ ä»–ä»¬çš„Prompt è®¾è®¡æ¥ç»™æˆ‘ä»¬ä»¥å¯å‘ã€‚

### 2.2.2. Few-shot examples

Few-shot examplesæ˜¯ä¸€ç»„å¯ç”¨äºå¸®åŠ©è¯­è¨€æ¨¡å‹ç”Ÿæˆæ›´å¥½å“åº”çš„ç¤ºä¾‹ã€‚ è¦ç”Ÿæˆå…·æœ‰few-shot examplesçš„promptï¼Œå¯ä»¥ä½¿ç”¨FewShotPromptTemplateã€‚è¯¥ç±»æ¥å—ä¸€ä¸ªPromptTemplateå’Œä¸€ç»„few-shot examplesã€‚ç„¶åï¼Œå®ƒä½¿ç”¨è¿™äº›few-shot examplesæ ¼å¼åŒ–promptæ¨¡æ¿ã€‚ æˆ‘ä»¬å†çœ‹ä¸€ä¸ªä¾‹å­ï¼Œéœ€æ±‚æ˜¯æ ¹æ®ç”¨æˆ·è¾“å…¥ï¼Œè®©æ¨¡å‹è¿”å›å¯¹åº”çš„åä¹‰è¯ï¼Œæˆ‘ä»¬è¦é€šè¿‡ç¤ºä¾‹æ¥å‘Šè¯‰æ¨¡å‹ä»€ä¹ˆæ˜¯åä¹‰è¯, è¿™å°±æ˜¯few-shot examplesï¼ˆå°æ ·æœ¬æç¤ºï¼‰

```python
python
å¤åˆ¶ä»£ç import os
os.environ["OPENAI_API_KEY"] = 'your apikey'
from langchain import PromptTemplate, FewShotPromptTemplate
from langchain.llms import OpenAI

examples = [
    {"word": "é»‘", "antonym": "ç™½"},
    {"word": "ä¼¤å¿ƒ", "antonym": "å¼€å¿ƒ"},
]

example_template = """
å•è¯: {word}
åä¹‰è¯: {antonym}\\n
"""

# åˆ›å»ºæç¤ºè¯æ¨¡ç‰ˆ
example_prompt = PromptTemplate(
    input_variables=["word", "antonym"],
    template=example_template,
)

# åˆ›å»ºå°æ ·æœ¬æç¤ºè¯æ¨¡ç‰ˆ
few_shot_prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_prompt,
    prefix="ç»™å‡ºæ¯ä¸ªå•è¯çš„åä¹‰è¯",
    suffix="å•è¯: {input}\\nåä¹‰è¯:",
    input_variables=["input"],
    example_separator="\\n",
)

# æ ¼å¼åŒ–å°æ ·æœ¬æç¤ºè¯
prompt_text = few_shot_prompt.format(input="ç²—")

# è°ƒç”¨OpenAI
llm = OpenAI(temperature=0.9)

print(llm(prompt_text))
```

### 2.2.3. Example Selectors

å¦‚æœä½ æœ‰å¤§é‡çš„ç¤ºä¾‹ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ExampleSelectoræ¥é€‰æ‹©æœ€æœ‰ä¿¡æ¯é‡çš„ä¸€äº›ç¤ºä¾‹ï¼Œä»¥å¸®åŠ©ä½ ç”Ÿæˆæ›´å¯èƒ½äº§ç”Ÿè‰¯å¥½å“åº”çš„æç¤ºã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨LengthBasedExampleSelectorï¼Œæ ¹æ®è¾“å…¥çš„é•¿åº¦é€‰æ‹©ç¤ºä¾‹ã€‚å½“ä½ æ‹…å¿ƒæ„é€ çš„æç¤ºå°†è¶…è¿‡ä¸Šä¸‹æ–‡çª—å£çš„é•¿åº¦æ—¶ï¼Œæ­¤æ–¹æ³•éå¸¸æœ‰ç”¨ã€‚å¯¹äºè¾ƒé•¿çš„è¾“å…¥ï¼Œå®ƒä¼šé€‰æ‹©åŒ…å«è¾ƒå°‘ç¤ºä¾‹çš„æç¤ºï¼Œè€Œå¯¹äºè¾ƒçŸ­çš„è¾“å…¥ï¼Œå®ƒä¼šé€‰æ‹©åŒ…å«æ›´å¤šç¤ºä¾‹ã€‚ å¦å¤–å®˜æ–¹ä¹Ÿæä¾›äº†æ ¹æ®æœ€å¤§è¾¹é™…ç›¸å…³æ€§ã€æ–‡æ³•é‡å ã€è¯­ä¹‰ç›¸ä¼¼æ€§æ¥é€‰æ‹©ç¤ºä¾‹ã€‚

```python
python
å¤åˆ¶ä»£ç import os
os.environ["OPENAI_API_KEY"] = 'your apikey'
from langchain.prompts import PromptTemplate, FewShotPromptTemplate
from langchain.prompts.example_selector import LengthBasedExampleSelector
from langchain.prompts.example_selector import LengthBasedExampleSelector


# These are a lot of examples of a pretend task of creating antonyms.
examples = [
    {"word": "happy", "antonym": "sad"},
    {"word": "tall", "antonym": "short"},
    {"word": "energetic", "antonym": "lethargic"},
    {"word": "sunny", "antonym": "gloomy"},
    {"word": "windy", "antonym": "calm"},
]
# ä¾‹å­æ ¼å¼åŒ–æ¨¡ç‰ˆ
example_formatter_template = """
Word: {word}
Antonym: {antonym}\n
"""
example_prompt = PromptTemplate(
    input_variables=["word", "antonym"],
    template=example_formatter_template,
)

# ä½¿ç”¨ LengthBasedExampleSelectoræ¥é€‰æ‹©ä¾‹å­
example_selector = LengthBasedExampleSelector(
    examples=examples, 
    example_prompt=example_prompt, 
    # æœ€å¤§é•¿åº¦
    max_length=25,
)

# ä½¿ç”¨'example_selector'åˆ›å»ºå°æ ·æœ¬æç¤ºè¯æ¨¡ç‰ˆ
dynamic_prompt = FewShotPromptTemplate(
    example_selector=example_selector,
    example_prompt=example_prompt,
    prefix="Give the antonym of every input",
    suffix="Word: {input}\nAntonym:",
    input_variables=["input"],
    example_separator="\n\n",
)

longString = "big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else"

print(dynamic_prompt.format(input=longString))
```

## 2.3. Indexesï¼ˆç´¢å¼•ï¼‰

ç´¢å¼•æ˜¯æŒ‡å¯¹æ–‡æ¡£è¿›è¡Œç»“æ„åŒ–çš„æ–¹æ³•ï¼Œä»¥ä¾¿LLMèƒ½å¤Ÿæ›´å¥½çš„ä¸ä¹‹äº¤äº’ã€‚è¯¥ç»„ä»¶ä¸»è¦åŒ…æ‹¬ï¼šDocument Loadersï¼ˆæ–‡æ¡£åŠ è½½å™¨ï¼‰ã€Text Splittersï¼ˆæ–‡æœ¬æ‹†åˆ†å™¨ï¼‰ã€VectorStoresï¼ˆå‘é‡å­˜å‚¨å™¨ï¼‰ä»¥åŠRetrieversï¼ˆæ£€ç´¢å™¨ï¼‰ã€‚

### 2.3.1. Document Loaders

æŒ‡å®šæºè¿›è¡ŒåŠ è½½æ•°æ®çš„ã€‚å°†ç‰¹å®šæ ¼å¼çš„æ•°æ®ï¼Œè½¬æ¢ä¸ºæ–‡æœ¬ã€‚å¦‚CSVã€File Directoryã€HTMLã€ JSONã€Markdownã€PDFã€‚å¦å¤–ä½¿ç”¨ç›¸å…³æ¥å£å¤„ç†æœ¬åœ°çŸ¥è¯†ï¼Œæˆ–è€…åœ¨çº¿çŸ¥è¯†ã€‚å¦‚AirbyteJSON Airtableã€Alibaba Cloud MaxComputeã€wikipediaã€BiliBiliã€GitHubã€GitBookç­‰ç­‰ã€‚

### 2.3.2. Text Splitters

ç”±äºæ¨¡å‹å¯¹è¾“å…¥çš„å­—ç¬¦é•¿åº¦æœ‰é™åˆ¶ï¼Œæˆ‘ä»¬åœ¨ç¢°åˆ°å¾ˆé•¿çš„æ–‡æœ¬æ—¶ï¼Œéœ€è¦æŠŠæ–‡æœ¬åˆ†å‰²æˆå¤šä¸ªå°çš„æ–‡æœ¬ç‰‡æ®µã€‚ æ–‡æœ¬åˆ†å‰²æœ€ç®€å•çš„æ–¹å¼æ˜¯æŒ‰ç…§å­—ç¬¦é•¿åº¦è¿›è¡Œåˆ†å‰²ï¼Œä½†æ˜¯è¿™ä¼šå¸¦æ¥å¾ˆå¤šé—®é¢˜ï¼Œæ¯”å¦‚è¯´å¦‚æœæ–‡æœ¬æ˜¯ä¸€æ®µä»£ç ï¼Œä¸€ä¸ªå‡½æ•°è¢«åˆ†å‰²åˆ°ä¸¤æ®µä¹‹åå°±æˆäº†æ²¡æœ‰æ„ä¹‰çš„å­—ç¬¦ï¼Œæ‰€ä»¥æ•´ä½“çš„åŸåˆ™æ˜¯æŠŠè¯­ä¹‰ç›¸å…³çš„æ–‡æœ¬ç‰‡æ®µæ”¾åœ¨ä¸€èµ·ã€‚ LangChainä¸­æœ€åŸºæœ¬çš„æ–‡æœ¬åˆ†å‰²å™¨æ˜¯CharacterTextSplitter ï¼Œå®ƒæŒ‰ç…§æŒ‡å®šçš„åˆ†éš”ç¬¦ï¼ˆé»˜è®¤â€œ\n\nâ€ï¼‰è¿›è¡Œåˆ†å‰²ï¼Œå¹¶ä¸”è€ƒè™‘æ–‡æœ¬ç‰‡æ®µçš„æœ€å¤§é•¿åº¦ã€‚æˆ‘ä»¬çœ‹ä¸ªä¾‹å­ï¼š

```python
python
å¤åˆ¶ä»£ç from langchain.text_splitter import CharacterTextSplitter

# åˆå§‹å­—ç¬¦ä¸²
state_of_the_union = "..."

text_splitter = CharacterTextSplitter(        
    separator = "\\n\\n",
    chunk_size = 1000,
    chunk_overlap  = 200,
    length_function = len,
)

texts = text_splitter.create_documents([state_of_the_union])
```

é™¤äº†CharacterTextSplitter ä»¥å¤–ï¼ŒLangChainè¿˜æ”¯æŒå¤šä¸ªé«˜çº§æ–‡æœ¬åˆ†å‰²å™¨ï¼Œå¦‚ä¸‹ï¼š

| LatexTextSplitter              | æ²¿ç€Latexæ ‡é¢˜ã€æ ‡é¢˜ã€æšä¸¾ç­‰åˆ†å‰²æ–‡æœ¬ã€‚                        |
| ------------------------------ | ------------------------------------------------------------ |
| MarkdownTextSplitter           | æ²¿ç€Markdownçš„æ ‡é¢˜ã€ä»£ç å—æˆ–æ°´å¹³è§„åˆ™æ¥åˆ†å‰²æ–‡æœ¬ã€‚             |
| NLTKTextSplitter               | ä½¿ç”¨NLTKçš„åˆ†å‰²å™¨                                             |
| PythonCodeTextSplitter         | æ²¿ç€Pythonç±»å’Œæ–¹æ³•çš„å®šä¹‰åˆ†å‰²æ–‡æœ¬ã€‚                           |
| RecursiveCharacterTextSplitter | ç”¨äºé€šç”¨æ–‡æœ¬çš„åˆ†å‰²å™¨ã€‚å®ƒä»¥ä¸€ä¸ªå­—ç¬¦åˆ—è¡¨ä¸ºå‚æ•°ï¼Œå°½å¯èƒ½åœ°æŠŠæ‰€æœ‰çš„æ®µè½ï¼ˆç„¶åæ˜¯å¥å­ï¼Œç„¶åæ˜¯å•è¯ï¼‰æ”¾åœ¨ä¸€èµ· |
| SpacyTextSplitter              | ä½¿ç”¨Spacyçš„åˆ†å‰²å™¨                                            |
| TokenTextSplitter              | æ ¹æ®openAIçš„tokenæ•°è¿›è¡Œåˆ†å‰²                                  |

### 2.3.3. VectorStores

å­˜å‚¨æå–çš„æ–‡æœ¬å‘é‡ï¼ŒåŒ…æ‹¬Faissã€Milvusã€Pineconeã€Chromaç­‰ã€‚å¦‚ä¸‹æ˜¯LangChainé›†æˆçš„å‘é‡æ•°æ®åº“ã€‚

| VectorStore            | ä»‹ç»                                                         |
| ---------------------- | ------------------------------------------------------------ |
| AnalyticDB             | é˜¿é‡Œäº‘è‡ªä¸»ç ”å‘çš„äº‘åŸç”Ÿæ•°æ®ä»“åº“                               |
| Annoy                  | ä¸€ä¸ªå¸¦æœ‰Python bindingsçš„C ++åº“ï¼Œç”¨äºæœç´¢ç©ºé—´ä¸­ç»™å®šæŸ¥è¯¢ç‚¹çš„è¿‘é‚»ç‚¹ã€‚ |
| AtlasDB                | ä¸€ä¸ªéç»“æ„åŒ–æ•°æ®é›†å¹³å°                                       |
| Chroma                 | ä¸€ä¸ªå¼€æºåµŒå…¥å¼æ•°æ®åº“                                         |
| Deep Lake              | å¤šæ¨¡å‘é‡å­˜å‚¨ï¼Œå¯ä»¥å­˜å‚¨åµŒå…¥åŠå…¶å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬æ–‡æœ¬ã€jsonsã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ç­‰ã€‚ |
| DocArrayHnswSearch     | ä¸€ä¸ªè½»é‡çº§çš„æ–‡æ¡£ç´¢å¼•å®ç°                                     |
| DocArrayInMemorySearch | ä¸€ä¸ªç”±Docarrayæä¾›çš„æ–‡æ¡£ç´¢å¼•ï¼Œå°†æ–‡æ¡£å­˜å‚¨åœ¨å†…å­˜ä¸­             |
| ElasticSearch          | ElasticSearch                                                |
| FAISS                  | Facebook AIç›¸ä¼¼æ€§æœç´¢æœåŠ¡                                    |
| LanceDB                | ä¸€ä¸ªç”¨äºå‘é‡æœç´¢çš„å¼€æºæ•°æ®åº“ï¼Œå®ƒé‡‡ç”¨æŒä¹…æ€§å­˜å‚¨               |
| Milvus                 | ç”¨äºå­˜å‚¨ã€ç´¢å¼•å’Œç®¡ç†ç”±æ·±åº¦ç¥ç»ç½‘ç»œå’Œå…¶ä»–æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰æ¨¡å‹äº§ç”Ÿçš„å¤§é‡åµŒå…¥å‘é‡çš„æ•°æ®åº“ |
| MyScale                | ä¸€ä¸ªåŸºäºäº‘çš„æ•°æ®åº“ï¼Œä¸ºäººå·¥æ™ºèƒ½åº”ç”¨å’Œè§£å†³æ–¹æ¡ˆè€Œä¼˜åŒ–           |
| OpenSearch             | ä¸€ä¸ªå¯æ‰©å±•çš„ã€çµæ´»çš„ã€å¯å»¶ä¼¸çš„å¼€æºè½¯ä»¶å¥—ä»¶ï¼Œç”¨äºæœç´¢ã€åˆ†æå’Œå¯è§‚å¯Ÿæ€§åº”ç”¨ |
| PGVector               | ä¸€ä¸ªç”¨äºPostgresçš„å¼€æºå‘é‡ç›¸ä¼¼æ€§æœç´¢æœåŠ¡                     |
| Pinecone               | ä¸€ä¸ªå…·æœ‰å¹¿æ³›åŠŸèƒ½çš„å‘é‡æ•°æ®åº“                                 |
| Qdrant                 | ä¸€ä¸ªå‘é‡ç›¸ä¼¼æ€§æœç´¢å¼•æ“                                       |
| Redis                  | åŸºäºredisçš„æ£€ç´¢å™¨                                            |
| SupabaseVectorStore    | ä¸€ä¸ªå¼€æºçš„Firebase æ›¿ä»£å“ï¼Œæä¾›ä¸€ç³»åˆ—åç«¯åŠŸèƒ½                |
| Tair                   | ä¸€ä¸ªKey/Valueç»“æ„æ•°æ®çš„è§£å†³æ–¹æ¡ˆ                              |
| Weaviate               | ä¸€ä¸ªå¼€æºçš„å‘é‡æœç´¢å¼•æ“                                       |
| Zilliz                 | æ•°æ®å¤„ç†å’Œåˆ†æå¹³å°                                           |

### 2.3.4. Retrievers

æ£€ç´¢å™¨æ˜¯ä¸€ç§ä¾¿äºæ¨¡å‹æŸ¥è¯¢çš„å­˜å‚¨æ•°æ®çš„æ–¹å¼ï¼ŒLangChainçº¦å®šæ£€ç´¢å™¨ç»„ä»¶è‡³å°‘æœ‰ä¸€ä¸ªæ–¹æ³•get_relevant_textsï¼Œè¿™ä¸ªæ–¹æ³•æ¥æ”¶æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œè¿”å›ä¸€ç»„æ–‡æ¡£ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„åˆ—å­ï¼š

```python
python
å¤åˆ¶ä»£ç from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
from langchain.document_loaders import TextLoader
from langchain.indexes import VectorstoreIndexCreator
loader = TextLoader('../state_of_the_union.txt', encoding='utf8')

# å¯¹åŠ è½½çš„å†…å®¹è¿›è¡Œç´¢å¼•
index = VectorstoreIndexCreator().from_loaders([loader])

query = "What did the president say about Ketanji Brown Jackson"

# é€šè¿‡queryçš„æ–¹å¼æ‰¾åˆ°è¯­ä¹‰æ£€ç´¢çš„ç»“æœ
index.query(query)
```

## 2.4. Chainsï¼ˆé“¾ï¼‰

é“¾å…è®¸æˆ‘ä»¬å°†å¤šä¸ªç»„ä»¶ç»„åˆåœ¨ä¸€èµ·ä»¥åˆ›å»ºä¸€ä¸ªå•ä¸€çš„ã€è¿è´¯çš„ä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªé“¾ï¼Œå®ƒæ¥å—ç”¨æˆ·è¾“å…¥ï¼Œä½¿ç”¨ PromptTemplate å¯¹å…¶è¿›è¡Œæ ¼å¼åŒ–ï¼Œç„¶åå°†æ ¼å¼åŒ–çš„å“åº”ä¼ é€’ç»™ LLMã€‚å¦å¤–æˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡å°†å¤šä¸ªé“¾ç»„åˆåœ¨ä¸€èµ·ï¼Œæˆ–è€…å°†é“¾ä¸å…¶ä»–ç»„ä»¶ç»„åˆæ¥æ„å»ºæ›´å¤æ‚çš„é“¾ã€‚

### 2.4.1. LLMChain

LLMChain æ˜¯ä¸€ä¸ªç®€å•çš„é“¾ï¼Œå®ƒå›´ç»•è¯­è¨€æ¨¡å‹æ·»åŠ äº†ä¸€äº›åŠŸèƒ½ã€‚å®ƒåœ¨æ•´ä¸ªLangChainä¸­å¹¿æ³›ä½¿ç”¨ï¼ŒåŒ…æ‹¬åœ¨å…¶ä»–é“¾å’Œä»£ç†ä¸­ã€‚å®ƒæ¥å—ä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œå°†å…¶ä¸ç”¨æˆ·è¾“å…¥è¿›è¡Œæ ¼å¼åŒ–ï¼Œå¹¶è¿”å› LLM çš„å“åº”ã€‚

```python
python
å¤åˆ¶ä»£ç from langchain import PromptTemplate, OpenAI, LLMChain

prompt_template = "What is a good name for a company that makes {product}?"

llm = OpenAI(temperature=0)
llm_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate.from_template(prompt_template)
)
llm_chain("colorful socks")
```

é™¤äº†æ‰€æœ‰Chainå¯¹è±¡å…±äº«çš„__call__å’Œrunæ–¹æ³•å¤–ï¼ŒLLMChainè¿˜æä¾›äº†ä¸€äº›è°ƒç”¨å¾—æ–¹æ³•ï¼Œå¦‚ä¸‹æ˜¯ä¸åŒè°ƒç”¨æ–¹æ³•çš„è¯´æ˜.

- __call__æ–¹æ³•è¿”å›è¾“å…¥å’Œè¾“å‡ºé”®å€¼ã€‚ å¦å¤–å¯ä»¥é€šè¿‡å°†return_only_outputsè®¾ç½®ä¸ºTrueï¼Œå¯ä»¥å°†å…¶é…ç½®ä¸ºåªè¿”å›è¾“å‡ºé”®å€¼ã€‚

```python
python
å¤åˆ¶ä»£ç llm_chain("corny", return_only_outputs=True)
python
å¤åˆ¶ä»£ç {'text': 'Why did the tomato turn red? Because it saw the salad dressing!'}
```

- runæ–¹æ³•è¿”å›çš„æ˜¯å­—ç¬¦ä¸²è€Œä¸æ˜¯å­—å…¸ã€‚

```python
python
å¤åˆ¶ä»£ç llm_chain.run({"adjective": "corny"})
python
å¤åˆ¶ä»£ç 'Why did the tomato turn red? Because it saw the salad dressing!'
```

- apply æ–¹æ³•å…è®¸ä½ å¯¹ä¸€ä¸ªè¾“å…¥åˆ—è¡¨è¿›è¡Œè°ƒç”¨

```python
python
å¤åˆ¶ä»£ç input_list = [
    {"product": "socks"},
    {"product": "computer"},
    {"product": "shoes"}
]

llm_chain.apply(input_list)
python
å¤åˆ¶ä»£ç [{'text': '\n\nSocktastic!'},
 {'text': '\n\nTechCore Solutions.'},
 {'text': '\n\nFootwear Factory.'}]
```

- generateæ–¹æ³•ç±»ä¼¼äº applyæ–¹æ³•ï¼Œä½†å®ƒè¿”å›çš„æ˜¯ LLMResult è€Œä¸æ˜¯å­—ç¬¦ä¸²ã€‚LLMResult é€šå¸¸åŒ…å«æœ‰ç”¨çš„ç”Ÿæˆä¿¡æ¯ï¼Œä¾‹å¦‚ä»¤ç‰Œä½¿ç”¨æƒ…å†µå’Œå®ŒæˆåŸå› ã€‚

```python
python
å¤åˆ¶ä»£ç llm_chain.generate(input_list)
python
å¤åˆ¶ä»£ç LLMResult(generations=[[Generation(text='\n\nSocktastic!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\nTechCore Solutions.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\nFootwear Factory.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'prompt_tokens': 36, 'total_tokens': 55, 'completion_tokens': 19}, 'model_name': 'text-davinci-003'})
```

- predict æ–¹æ³•ç±»ä¼¼äº run æ–¹æ³•ï¼Œä¸åŒä¹‹å¤„åœ¨äºè¾“å…¥é”®è¢«æŒ‡å®šä¸ºå…³é”®å­—å‚æ•°ï¼Œè€Œä¸æ˜¯ä¸€ä¸ª Python å­—å…¸ã€‚

```python
python
å¤åˆ¶ä»£ç # Single input example
llm_chain.predict(product="colorful socks")
```

### 2.4.2. SimpleSequentialChain

é¡ºåºé“¾çš„æœ€ç®€å•å½¢å¼ï¼Œå…¶ä¸­æ¯ä¸ªæ­¥éª¤éƒ½æœ‰ä¸€ä¸ªå•ä¸€çš„è¾“å…¥/è¾“å‡ºï¼Œå¹¶ä¸”ä¸€ä¸ªæ­¥éª¤çš„è¾“å‡ºæ˜¯ä¸‹ä¸€æ­¥çš„è¾“å…¥ã€‚ ![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/146a68c3321e4d14a37ae9213bf5972e~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp) å¦‚ä¸‹å°±æ˜¯å°†ä¸¤ä¸ªLLMChainè¿›è¡Œç»„åˆæˆé¡ºåºé“¾è¿›è¡Œè°ƒç”¨çš„æ¡ˆä¾‹ã€‚

```python
python
å¤åˆ¶ä»£ç from langchain.llms import OpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.chains import SimpleSequentialChain

# å®šä¹‰ç¬¬ä¸€ä¸ªchain
llm = OpenAI(temperature=.7)
template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.

Title: {title}
Playwright: This is a synopsis for the above play:"""
prompt_template = PromptTemplate(input_variables=["title"], template=template)
synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)

# å®šä¹‰ç¬¬äºŒä¸ªchain

llm = OpenAI(temperature=.7)
template = """You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.

Play Synopsis:
{synopsis}
Review from a New York Times play critic of the above play:"""
prompt_template = PromptTemplate(input_variables=["synopsis"], template=template)
review_chain = LLMChain(llm=llm, prompt=prompt_template)

# é€šè¿‡ç®€å•é¡ºåºé“¾ç»„åˆä¸¤ä¸ªLLMChain
overall_chain = SimpleSequentialChain(chains=[synopsis_chain, review_chain], verbose=True)

# æ‰§è¡Œé¡ºåºé“¾
review = overall_chain.run("Tragedy at sunset on the beach")
```

### 2.4.3. SequentialChain

ç›¸æ¯”SimpleSequentialChainåªå…è®¸æœ‰å•ä¸ªè¾“å…¥è¾“å‡ºï¼Œå®ƒæ˜¯ä¸€ç§æ›´é€šç”¨çš„é¡ºåºé“¾å½¢å¼ï¼Œå…è®¸å¤šä¸ªè¾“å…¥/è¾“å‡ºã€‚ ç‰¹åˆ«é‡è¦çš„æ˜¯ï¼š æˆ‘ä»¬å¦‚ä½•å‘½åè¾“å…¥/è¾“å‡ºå˜é‡åç§°ã€‚åœ¨ä¸Šé¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä¸å¿…è€ƒè™‘è¿™ä¸€ç‚¹ï¼Œå› ä¸ºæˆ‘ä»¬åªæ˜¯å°†ä¸€ä¸ªé“¾çš„è¾“å‡ºç›´æ¥ä½œä¸ºè¾“å…¥ä¼ é€’ç»™ä¸‹ä¸€ä¸ªé“¾ï¼Œä½†åœ¨è¿™é‡Œæˆ‘ä»¬ç¡®å®éœ€è¦æ‹…å¿ƒè¿™ä¸€ç‚¹ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰å¤šä¸ªè¾“å…¥ã€‚ ç¬¬ä¸€ä¸ªLLMChainï¼š

```python
python
å¤åˆ¶ä»£ç # è¿™æ˜¯ä¸€ä¸ª LLMChainï¼Œæ ¹æ®æˆå‰§çš„æ ‡é¢˜å’Œè®¾å®šçš„æ—¶ä»£ï¼Œç”Ÿæˆä¸€ä¸ªç®€ä»‹ã€‚
llm = OpenAI(temperature=.7)
template = """You are a playwright. Given the title of play and the era it is set in, it is your job to write a synopsis for that title.
# è¿™é‡Œå®šä¹‰äº†ä¸¤ä¸ªè¾“å…¥å˜é‡titleå’Œeraï¼Œå¹¶å®šä¹‰ä¸€ä¸ªè¾“å‡ºå˜é‡ï¼šsynopsis
Title: {title}
Era: {era}
Playwright: This is a synopsis for the above play:"""
prompt_template = PromptTemplate(input_variables=["title", "era"], template=template)
synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, output_key="synopsis")
```

ç¬¬äºŒä¸ªLLMChainï¼š

```python
python
å¤åˆ¶ä»£ç # è¿™æ˜¯ä¸€ä¸ª LLMChainï¼Œæ ¹æ®å‰§æƒ…ç®€ä»‹æ’°å†™ä¸€ç¯‡æˆå‰§è¯„è®ºã€‚
llm = OpenAI(temperature=.7)
template = """You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.
# å®šä¹‰äº†ä¸€ä¸ªè¾“å…¥å˜é‡ï¼šsynopsisï¼Œè¾“å‡ºå˜é‡ï¼šreview
Play Synopsis:
{synopsis}
Review from a New York Times play critic of the above play:"""
prompt_template = PromptTemplate(input_variables=["synopsis"], template=template)
review_chain = LLMChain(llm=llm, prompt=prompt_template, output_key="review")
```

æ‰§è¡Œé¡ºåºé“¾

```python
python
å¤åˆ¶ä»£ç overall_chain({"title":"Tragedy at sunset on the beach", "era": "Victorian England"})
```

æ‰§è¡Œç»“æœï¼Œå¯ä»¥çœ‹åˆ°ä¼šæŠŠæ¯ä¸€æ­¥çš„è¾“å‡ºéƒ½èƒ½æ‰“å°å‡ºæ¥ã€‚

```python
python
å¤åˆ¶ä»£ç     > Entering new SequentialChain chain...
    
    > Finished chain.

    {'title': 'Tragedy at sunset on the beach',
     'era': 'Victorian England',
     'synopsis': "xxxxxx",
     'review': "xxxxxxx"}
```

### 2.4.4. TransformChain

è½¬æ¢é“¾å…è®¸æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„è½¬æ¢å‡½æ•°æ¥å¤„ç†è¾“å…¥ï¼Œå°†å¤„ç†åçš„ç»“æœç”¨ä½œä¸‹ä¸€ä¸ªé“¾çš„è¾“å…¥ã€‚å¦‚ä¸‹ç¤ºä¾‹æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªè½¬æ¢å‡½æ•°ï¼Œå®ƒæ¥å—è¶…é•¿æ–‡æœ¬ï¼Œå°†æ–‡æœ¬è¿‡æ»¤ä¸ºä»…å‰ 3 æ®µï¼Œç„¶åå°†å…¶ä¼ é€’åˆ° LLMChain ä¸­ä»¥æ€»ç»“è¿™äº›å†…å®¹ã€‚

```python
python
å¤åˆ¶ä»£ç from langchain.chains import TransformChain, LLMChain, SimpleSequentialChain
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate

# æ¨¡æ‹Ÿè¶…é•¿æ–‡æœ¬
with open("../../state_of_the_union.txt") as f:
    state_of_the_union = f.read()

# å®šä¹‰è½¬æ¢æ–¹æ³•ï¼Œå…¥å‚å’Œå‡ºå‚éƒ½æ˜¯å­—å…¸ï¼Œå–å‰ä¸‰æ®µ
def transform_func(inputs: dict) -> dict:
    text = inputs["text"]
    shortened_text = "\n\n".join(text.split("\n\n")[:3])
    return {"output_text": shortened_text}

# è½¬æ¢é“¾ï¼šè¾“å…¥å˜é‡ï¼štextï¼Œè¾“å‡ºå˜é‡ï¼šoutput_text
transform_chain = TransformChain(
    input_variables=["text"], output_variables=["output_text"], transform=transform_func
)
# promptæ¨¡æ¿æè¿°
template = """Summarize this text:

{output_text}

Summary:"""
# promptæ¨¡æ¿
prompt = PromptTemplate(input_variables=["output_text"], template=template)
# llmé“¾
llm_chain = LLMChain(llm=OpenAI(), prompt=prompt)
# ä½¿ç”¨é¡ºåºé“¾
sequential_chain = SimpleSequentialChain(chains=[transform_chain, llm_chain])
# å¼€å§‹æ‰§è¡Œ
sequential_chain.run(state_of_the_union)
# ç»“æœ
""" 
    ' The speaker addresses the nation, noting that while last year they were kept apart due to COVID-19, this year they are together again. 
    They are reminded that regardless of their political affiliations, they are all Americans.'

"""
```

## 2.5. Memoryï¼ˆè®°å¿†ï¼‰

ç†Ÿæ‚‰openaiçš„éƒ½çŸ¥é“,openaiæä¾›çš„èŠå¤©æ¥å£apiï¼Œæœ¬èº«æ˜¯ä¸å…·å¤‡â€œè®°å¿†çš„â€èƒ½åŠ›ã€‚å¦‚æœæƒ³è¦ä½¿èŠå¤©å…·æœ‰è®°å¿†åŠŸèƒ½ï¼Œåˆ™éœ€è¦æˆ‘ä»¬è‡ªè¡Œç»´æŠ¤èŠå¤©è®°å½•ï¼Œå³æ¯æ¬¡æŠŠèŠå¤©è®°å½•å‘ç»™gptã€‚å…·ä½“è¿‡ç¨‹å¦‚ä¸‹ ç¬¬ä¸€æ¬¡å‘é€

```python
python
å¤åˆ¶ä»£ç import openai

openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
  messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello"},
    ]
)
```

ç¬¬äºŒæ¬¡å‘é€å°±è¦å¸¦ä¸Šæˆ‘ä»¬ç¬¬ä¸€æ¬¡çš„è®°å½•å³

```python
python
å¤åˆ¶ä»£ç import openai

openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
  messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello"},
        {"role": "assistant", "content": "Hello, how can I help you?"},
        {"role": "user", "content": "who is more stylish Pikachu or Neo"},
    ]
)
```

é‚£å¦‚æœæˆ‘ä»¬ä¸€ç›´èŠå¤©ä¸‹å»ï¼Œå‘é€çš„å†…å®¹ä¹Ÿè¶Šæ¥è¶Šå¤šï¼Œé‚£å¾ˆå¯èƒ½å°±ç¢°åˆ°tokençš„é™åˆ¶ã€‚èªæ˜çš„åŒå­¦ä¼šå‘ç°ï¼Œå…¶å®æˆ‘ä»¬åªä¿ç•™æœ€è¿‘å‡ æ¬¡çš„èŠå¤©è®°å½•å°±å¯ä»¥äº†ã€‚æ²¡é”™ï¼Œå…¶å®LangChainä¹Ÿæ˜¯è¿™æ ·å®ç°çš„ï¼Œä¸è¿‡LangChainæä¾›äº†æ›´å¤šçš„æ–¹æ³•ã€‚ langchainæä¾›äº†ä¸åŒçš„Memoryç»„ä»¶å®Œæˆå†…å®¹è®°å¿†ï¼Œå¦‚ä¸‹æ˜¯ç›®å‰æä¾›çš„ç»„ä»¶ã€‚

### 2.5.1. ConversationBufferMemory

è¯¥ç»„ä»¶ç±»ä¼¼æˆ‘ä»¬ä¸Šé¢çš„æè¿°ï¼Œåªä¸è¿‡å®ƒä¼šå°†èŠå¤©å†…å®¹è®°å½•åœ¨å†…å­˜ä¸­ï¼Œè€Œä¸éœ€è¦æ¯æ¬¡å†æ‰‹åŠ¨æ‹¼æ¥èŠå¤©è®°å½•ã€‚

### 2.5.2. ConversationBufferWindowMemory

ç›¸æ¯”è¾ƒç¬¬ä¸€ä¸ªè®°å¿†ç»„ä»¶ï¼Œè¯¥ç»„ä»¶å¢åŠ äº†ä¸€ä¸ªçª—å£å‚æ•°ï¼Œä¼šä¿å­˜æœ€è¿‘çœ‹kè®ºçš„èŠå¤©å†…å®¹ã€‚

### 2.5.3. ConversationTokenBufferMemory

åœ¨å†…å­˜ä¸­ä¿ç•™æœ€è¿‘äº¤äº’çš„ç¼“å†²åŒºï¼Œå¹¶ä½¿ç”¨tokené•¿åº¦è€Œä¸æ˜¯äº¤äº’æ¬¡æ•°æ¥ç¡®å®šä½•æ—¶åˆ·æ–°äº¤äº’ã€‚

### 2.5.4. ConversationSummaryMemory

ç›¸æ¯”ç¬¬ä¸€ä¸ªè®°å¿†ç»„ä»¶ï¼Œè¯¥ç»„ä»¶åªä¼šå­˜å‚¨ä¸€ä¸ªç”¨æˆ·å’Œæœºå™¨äººä¹‹é—´çš„èŠå¤©å†…å®¹çš„æ‘˜è¦ã€‚

### 2.5.5. ConversationSummaryBufferMemory

ç»“åˆäº†ä¸Šé¢ä¸¤ä¸ªæ€è·¯ï¼Œå­˜å‚¨ä¸€ä¸ªç”¨æˆ·å’Œæœºå™¨äººä¹‹é—´çš„èŠå¤©å†…å®¹çš„æ‘˜è¦å¹¶ä½¿ç”¨tokené•¿åº¦æ¥ç¡®å®šä½•æ—¶åˆ·æ–°äº¤äº’ã€‚

### 2.5.6. VectorStoreRetrieverMemory

å®ƒæ˜¯å°†æ‰€æœ‰ä¹‹å‰çš„å¯¹è¯é€šè¿‡å‘é‡çš„æ–¹å¼å­˜å‚¨åˆ°VectorDBï¼ˆå‘é‡æ•°æ®åº“ï¼‰ä¸­ï¼Œåœ¨æ¯ä¸€è½®æ–°çš„å¯¹è¯ä¸­ï¼Œä¼šæ ¹æ®ç”¨æˆ·çš„è¾“å…¥ä¿¡æ¯ï¼ŒåŒ¹é…å‘é‡æ•°æ®åº“ä¸­æœ€ç›¸ä¼¼çš„Kç»„å¯¹è¯ã€‚

## 2.6. Agentsï¼ˆä»£ç†ï¼‰

ä¸€äº›åº”ç”¨ç¨‹åºéœ€è¦æ ¹æ®ç”¨æˆ·è¾“å…¥çµæ´»åœ°è°ƒç”¨LLMå’Œå…¶ä»–å·¥å…·çš„é“¾ã€‚ä»£ç†æ¥å£ä¸ºè¿™æ ·çš„åº”ç”¨ç¨‹åºæä¾›äº†çµæ´»æ€§ã€‚ä»£ç†å¯ä»¥è®¿é—®ä¸€å¥—å·¥å…·ï¼Œå¹¶æ ¹æ®ç”¨æˆ·è¾“å…¥ç¡®å®šè¦ä½¿ç”¨å“ªäº›å·¥å…·ã€‚æˆ‘ä»¬å¯ä»¥ç®€å•çš„ç†è§£ä¸ºä»–å¯ä»¥åŠ¨æ€çš„å¸®æˆ‘ä»¬é€‰æ‹©å’Œè°ƒç”¨chainæˆ–è€…å·²æœ‰çš„å·¥å…·ã€‚ä»£ç†ä¸»è¦æœ‰ä¸¤ç§ç±»å‹Action agentså’ŒPlan-and-execute agentsã€‚

### 2.6.1. Action agents

è¡Œä¸ºä»£ç†: åœ¨æ¯ä¸ªæ—¶é—´æ­¥ï¼Œä½¿ç”¨æ‰€æœ‰å…ˆå‰åŠ¨ä½œçš„è¾“å‡ºæ¥å†³å®šä¸‹ä¸€ä¸ªåŠ¨ä½œã€‚ä¸‹å›¾å±•ç¤ºäº†è¡Œä¸ºä»£ç†æ‰§è¡Œçš„æµç¨‹ã€‚ ![img](https://p.ipic.vip/pgl4ji.jpg)

### 2.6.2. Plan-and-execute agents

é¢„å…ˆå†³å®šå®Œæ•´çš„æ“ä½œé¡ºåºï¼Œç„¶åæ‰§è¡Œæ‰€æœ‰æ“ä½œè€Œä¸æ›´æ–°è®¡åˆ’ï¼Œä¸‹é¢æ˜¯å…¶æµç¨‹ã€‚

- æ¥æ”¶ç”¨æˆ·è¾“å…¥
- è®¡åˆ’è¦é‡‡å–çš„å®Œæ•´æ­¥éª¤é¡ºåº
- æŒ‰é¡ºåºæ‰§è¡Œæ­¥éª¤ï¼Œå°†è¿‡å»æ­¥éª¤çš„è¾“å‡ºä½œä¸ºæœªæ¥æ­¥éª¤çš„è¾“å…¥ä¼ é€’

# 3. LangChainå®æˆ˜

## 3.1. å®Œæˆä¸€æ¬¡é—®ç­”

LangChain åŠ è½½ OpenAI çš„æ¨¡å‹ï¼Œå¹¶ä¸”å®Œæˆä¸€æ¬¡é—®ç­”ã€‚ å…ˆè®¾ç½®æˆ‘ä»¬çš„ openai çš„ keyï¼Œç„¶åï¼Œæˆ‘ä»¬è¿›è¡Œå¯¼å…¥å’Œæ‰§è¡Œã€‚

```python
python
å¤åˆ¶ä»£ç # å¯¼å…¥os, è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå¯¼å…¥OpenAIæ¨¡å‹
import os
os.environ["OPENAI_API_KEY"] = 'ä½ çš„api key'
from langchain.llms import OpenAI

# åŠ è½½ OpenAI æ¨¡å‹ï¼Œå¹¶æŒ‡å®šæ¨¡å‹åå­—
llm = OpenAI(model_name="text-davinci-003",max_tokens=1024)

# å‘æ¨¡å‹æé—®
result = llm("æ€ä¹ˆè¯„ä»·äººå·¥æ™ºèƒ½")
```

## 3.2. é€šè¿‡è°·æ­Œæœç´¢å¹¶è¿”å›ç­”æ¡ˆ

ä¸ºäº†å®ç°æˆ‘ä»¬çš„é¡¹ç›®ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ Serpapi æä¾›çš„ Google æœç´¢ API æ¥å£ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åœ¨ Serpapi å®˜ç½‘ä¸Šæ³¨å†Œä¸€ä¸ªç”¨æˆ·ï¼Œå¹¶å¤åˆ¶ç”± Serpapi ç”Ÿæˆçš„ API å¯†é’¥ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å°†è¿™ä¸ª API å¯†é’¥è®¾ç½®ä¸ºç¯å¢ƒå˜é‡ï¼Œå°±åƒæˆ‘ä»¬ä¹‹å‰è®¾ç½® OpenAI API å¯†é’¥ä¸€æ ·ã€‚

```python
python
å¤åˆ¶ä»£ç # å¯¼å…¥os, è®¾ç½®ç¯å¢ƒå˜é‡
import os
os.environ["OPENAI_API_KEY"] = 'ä½ çš„api key'
os.environ["SERPAPI_API_KEY"] = 'ä½ çš„api key'
```

ç„¶åï¼Œå¼€å§‹ç¼–å†™æˆ‘çš„ä»£ç ã€‚

```python
python
å¤åˆ¶ä»£ç # å¯¼å…¥åŠ è½½å·¥å…·ã€åˆå§‹åŒ–ä»£ç†ã€ä»£ç†ç±»å‹åŠOpenAIæ¨¡å‹
from langchain.agents import load_tools
from langchain.agents import initialize_agent
from langchain.agents import AgentType
from langchain.llms import OpenAI

# åŠ è½½ OpenAI æ¨¡å‹
llm = OpenAI(temperature=0)

# åŠ è½½ serpapiã€è¯­è¨€æ¨¡å‹çš„æ•°å­¦å·¥å…·
tools = load_tools(["serpapi", "llm-math"], llm=llm)

# å·¥å…·åŠ è½½åéƒ½éœ€è¦åˆå§‹åŒ–ï¼Œverbose å‚æ•°ä¸º Trueï¼Œä¼šæ‰“å°å…¨éƒ¨çš„æ‰§è¡Œè¯¦æƒ…
agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)

# æ‰§è¡Œä»£ç†
agent.run("ä»Šå¤©æ˜¯å‡ å·ï¼Ÿå†å²ä¸Šçš„ä»Šå¤©å‘ç”Ÿäº†ä»€ä¹ˆäº‹æƒ…")
```

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/49eca989b3114527b1c87e4f5303478c~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp) å¯ä»¥çœ‹åˆ°ï¼Œæ­£ç¡®çš„è¿”å›äº†æ—¥æœŸï¼ˆæœ‰æ—¶å·®ï¼‰ï¼Œå¹¶ä¸”è¿”å›äº†å†å²ä¸Šçš„ä»Šå¤©ã€‚å¹¶ä¸”é€šè¿‡è®¾ç½®verboseè¿™ä¸ªå‚æ•°ä¸ºTrue,å¯ä»¥çœ‹åˆ°å®Œæ•´çš„ chain æ‰§è¡Œè¿‡ç¨‹ã€‚å°†æˆ‘ä»¬çš„é—®é¢˜æ‹†åˆ†æˆäº†å‡ ä¸ªæ­¥éª¤ï¼Œç„¶åä¸€æ­¥ä¸€æ­¥å¾—åˆ°æœ€ç»ˆçš„ç­”æ¡ˆã€‚

## 3.3. å¯¹è¶…é•¿æ–‡æœ¬è¿›è¡Œæ€»ç»“

å‡å¦‚æˆ‘ä»¬æƒ³è¦ç”¨ openai api å¯¹ä¸€ä¸ªæ®µæ–‡æœ¬è¿›è¡Œæ€»ç»“ï¼Œæˆ‘ä»¬é€šå¸¸çš„åšæ³•å°±æ˜¯ç›´æ¥å‘ç»™ api è®©ä»–æ€»ç»“ã€‚ä½†æ˜¯å¦‚æœæ–‡æœ¬è¶…è¿‡äº† api æœ€å¤§çš„ token é™åˆ¶å°±ä¼šæŠ¥é”™ã€‚è¿™æ—¶ï¼Œæˆ‘ä»¬ä¸€èˆ¬ä¼šè¿›è¡Œå¯¹æ–‡ç« è¿›è¡Œåˆ†æ®µï¼Œæ¯”å¦‚é€šè¿‡ tiktoken è®¡ç®—å¹¶åˆ†å‰²ï¼Œç„¶åå°†å„æ®µå‘é€ç»™ api è¿›è¡Œæ€»ç»“ï¼Œæœ€åå°†å„æ®µçš„æ€»ç»“å†è¿›è¡Œä¸€ä¸ªå…¨éƒ¨çš„æ€»ç»“ã€‚ LangChainå¾ˆå¥½çš„å¸®æˆ‘ä»¬å¤„ç†äº†è¿™ä¸ªè¿‡ç¨‹ï¼Œä½¿å¾—æˆ‘ä»¬ç¼–å†™ä»£ç å˜çš„éå¸¸ç®€å•ã€‚

```python
python
å¤åˆ¶ä»£ç # å¯¼å…¥os,è®¾ç½®ç¯å¢ƒå˜é‡ã€‚å¯¼å…¥æ–‡æœ¬åŠ è½½å™¨ã€æ€»ç»“é“¾ã€æ–‡æœ¬åˆ†å‰²å™¨åŠOpenAIæ¨¡å‹
import os
os.environ["OPENAI_API_KEY"] = 'ä½ çš„api key'
from langchain.document_loaders import TextLoader
from langchain.chains.summarize import load_summarize_chain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain import OpenAI

# è·å–å½“å‰è„šæœ¬æ‰€åœ¨çš„ç›®å½•
base_dir = os.path.dirname(os.path.abspath(__file__))

# æ„å»ºdoc.txtæ–‡ä»¶çš„è·¯å¾„
doc_path = os.path.join(base_dir, 'static', 'open.txt')

# é€šè¿‡æ–‡æœ¬åŠ è½½å™¨åŠ è½½æ–‡æœ¬
loader = TextLoader(doc_path)

# å°†æ–‡æœ¬è½¬æˆ Document å¯¹è±¡
document = loader.load()

# åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size = 800,
    chunk_overlap = 0
)

# åˆ‡åˆ†æ–‡æœ¬
split_documents = text_splitter.split_documents(document)

# åŠ è½½ llm æ¨¡å‹
llm = OpenAI(model_name="text-davinci-003", max_tokens=1500)

# åˆ›å»ºæ€»ç»“é“¾
chain = load_summarize_chain(llm, chain_type="refine", verbose=True)

# æ‰§è¡Œæ€»ç»“é“¾
chain.run(split_documents)
```

è¿™é‡Œè§£é‡Šä¸‹æ–‡æœ¬åˆ†å‰²å™¨çš„ chunk_overlap å‚æ•°å’Œchain çš„ chain_type å‚æ•°ã€‚ chunk_overlap æ˜¯æŒ‡åˆ‡å‰²åçš„æ¯ä¸ª document é‡ŒåŒ…å«å‡ ä¸ªä¸Šä¸€ä¸ª document ç»“å°¾çš„å†…å®¹ï¼Œä¸»è¦ä½œç”¨æ˜¯ä¸ºäº†å¢åŠ æ¯ä¸ª document çš„ä¸Šä¸‹æ–‡å…³è”ã€‚æ¯”å¦‚ï¼Œchunk_overlap=0æ—¶ï¼Œ ç¬¬ä¸€ä¸ª document ä¸º aaaaaaï¼Œç¬¬äºŒä¸ªä¸º bbbbbbï¼›å½“ chunk_overlap=2 æ—¶ï¼Œç¬¬ä¸€ä¸ª document ä¸º aaaaaaï¼Œç¬¬äºŒä¸ªä¸º aabbbbbbã€‚ chain_typeä¸»è¦æ§åˆ¶äº†å°† document ä¼ é€’ç»™ llm æ¨¡å‹çš„æ–¹å¼ï¼Œä¸€å…±æœ‰ 4 ç§æ–¹å¼ï¼š stuff: è¿™ç§æœ€ç®€å•ç²—æš´ï¼Œä¼šæŠŠæ‰€æœ‰çš„ document ä¸€æ¬¡å…¨éƒ¨ä¼ ç»™ llm æ¨¡å‹è¿›è¡Œæ€»ç»“ã€‚å¦‚æœdocumentå¾ˆå¤šçš„è¯ï¼ŒåŠ¿å¿…ä¼šæŠ¥è¶…å‡ºæœ€å¤§ token é™åˆ¶çš„é”™ï¼Œæ‰€ä»¥æ€»ç»“æ–‡æœ¬çš„æ—¶å€™ä¸€èˆ¬ä¸ä¼šé€‰ä¸­è¿™ä¸ªã€‚ map_reduce: è¿™ä¸ªæ–¹å¼ä¼šå…ˆå°†æ¯ä¸ª document è¿›è¡Œæ€»ç»“ï¼Œæœ€åå°†æ‰€æœ‰ document æ€»ç»“å‡ºçš„ç»“æœå†è¿›è¡Œä¸€æ¬¡æ€»ç»“ã€‚ ![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dfeb17acc6914a3d8b2807b663e44d22~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp) refine: è¿™ç§æ–¹å¼ä¼šå…ˆæ€»ç»“ç¬¬ä¸€ä¸ª documentï¼Œç„¶ååœ¨å°†ç¬¬ä¸€ä¸ª document æ€»ç»“å‡ºçš„å†…å®¹å’Œç¬¬äºŒä¸ª document ä¸€èµ·å‘ç»™ llm æ¨¡å‹åœ¨è¿›è¡Œæ€»ç»“ï¼Œä»¥æ­¤ç±»æ¨ã€‚è¿™ç§æ–¹å¼çš„å¥½å¤„å°±æ˜¯åœ¨æ€»ç»“åä¸€ä¸ª document çš„æ—¶å€™ï¼Œä¼šå¸¦ç€å‰ä¸€ä¸ªçš„ document è¿›è¡Œæ€»ç»“ï¼Œç»™éœ€è¦æ€»ç»“çš„ document æ·»åŠ äº†ä¸Šä¸‹æ–‡ï¼Œå¢åŠ äº†æ€»ç»“å†…å®¹çš„è¿è´¯æ€§ã€‚ ![img](https://p.ipic.vip/waiuaq.jpg) map_rerank: è¿™ç§ä¸€èˆ¬ä¸ä¼šç”¨åœ¨æ€»ç»“çš„ chain ä¸Šï¼Œè€Œæ˜¯ä¼šç”¨åœ¨é—®ç­”çš„ chain ä¸Šï¼Œä»–å…¶å®æ˜¯ä¸€ç§æœç´¢ç­”æ¡ˆçš„åŒ¹é…æ–¹å¼ã€‚é¦–å…ˆä½ è¦ç»™å‡ºä¸€ä¸ªé—®é¢˜ï¼Œä»–ä¼šæ ¹æ®é—®é¢˜ç»™æ¯ä¸ª document è®¡ç®—ä¸€ä¸ªè¿™ä¸ª document èƒ½å›ç­”è¿™ä¸ªé—®é¢˜çš„æ¦‚ç‡åˆ†æ•°ï¼Œç„¶åæ‰¾åˆ°åˆ†æ•°æœ€é«˜çš„é‚£ä¸ª document ï¼Œåœ¨é€šè¿‡æŠŠè¿™ä¸ª document è½¬åŒ–ä¸ºé—®é¢˜çš„ prompt çš„ä¸€éƒ¨åˆ†ï¼ˆé—®é¢˜+documentï¼‰å‘é€ç»™ llm æ¨¡å‹ï¼Œæœ€å llm æ¨¡å‹è¿”å›å…·ä½“ç­”æ¡ˆã€‚

## 3.4. æ„å»ºæœ¬åœ°çŸ¥è¯†åº“é—®ç­”æœºå™¨äºº

é€šè¿‡è¿™ä¸ªå¯ä»¥å¾ˆæ–¹ä¾¿çš„åšä¸€ä¸ªå¯ä»¥ä»‹ç»å…¬å¸ä¸šåŠ¡çš„æœºå™¨äººï¼Œæˆ–æ˜¯ä»‹ç»ä¸€ä¸ªäº§å“çš„æœºå™¨äººã€‚è¿™é‡Œä¸»è¦ä½¿ç”¨äº†Embeddingï¼ˆç›¸å…³æ€§ï¼‰çš„èƒ½åŠ›ã€‚

```python
python
å¤åˆ¶ä»£ç 
å¯¼å…¥os,è®¾ç½®ç¯å¢ƒå˜é‡ã€‚å¯¼å…¥OpenAIåµŒå…¥æ¨¡å‹ã€Chromaå‘é‡æ•°æ®åº“ã€æ–‡æœ¬åˆ†å‰²å™¨ã€OpenAIæ¨¡å‹ã€å‘é‡æ•°æ®åº“æ•°æ®æŸ¥è¯¢æ¨¡å—åŠæ–‡ä»¶å¤¹æ–‡æ¡£åŠ è½½å™¨


import os
os.environ["OPENAI_API_KEY"] = 'ä½ çš„api key'
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain import OpenAI,VectorDBQA
from langchain.document_loaders import DirectoryLoader

# è·å–å½“å‰è„šæœ¬æ‰€åœ¨çš„ç›®å½•
base_dir = os.path.dirname(os.path.abspath(__file__))

# æ„å»ºdoc.txtæ–‡ä»¶çš„è·¯å¾„
doc_Directory = os.path.join(base_dir, 'static')

# åŠ è½½æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰txtç±»å‹çš„æ–‡ä»¶
loader = DirectoryLoader(doc_Directory, glob='**/*.txt')

# å°†æ•°æ®è½¬æˆ document å¯¹è±¡ï¼Œæ¯ä¸ªæ–‡ä»¶ä¼šä½œä¸ºä¸€ä¸ª document
documents = loader.load()

# åˆå§‹åŒ–åŠ è½½å™¨
text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)

# åˆ‡å‰²åŠ è½½çš„ document
split_docs = text_splitter.split_documents(documents)

# åˆå§‹åŒ– openai çš„ embeddings å¯¹è±¡
embeddings = OpenAIEmbeddings()

# å°† document é€šè¿‡ openai çš„ embeddings å¯¹è±¡è®¡ç®— embedding å‘é‡ä¿¡æ¯å¹¶ä¸´æ—¶å­˜å…¥ Chroma å‘é‡æ•°æ®åº“ï¼Œç”¨äºåç»­åŒ¹é…æŸ¥è¯¢
docsearch = Chroma.from_documents(split_docs, embeddings)

# åˆ›å»ºé—®ç­”å¯¹è±¡
qa = VectorDBQA.from_chain_type(llm=OpenAI(), chain_type="stuff", vectorstore=docsearch,return_source_documents=True)

# è¿›è¡Œé—®ç­”
result = qa({"query": "ä¸€å¹´æ”¶å…¥æ˜¯å¤šå°‘ï¼Ÿ"})
```

![img](https://p.ipic.vip/hts0xe.jpg) ä¸Šå›¾ä¸­æˆåŠŸçš„ä»æˆ‘ä»¬çš„ç»™åˆ°çš„æ•°æ®ä¸­è·å–äº†æ­£ç¡®çš„ç­”æ¡ˆã€‚

## 3.5. æ„å»ºå‘é‡ç´¢å¼•æ•°æ®åº“

[ğŸ¡ Home | Chroma](https://link.juejin.cn?target=https%3A%2F%2Fdocs.trychroma.com%2F) æˆ‘ä»¬ä¸Šä¸ªæ¡ˆä¾‹é‡Œé¢æœ‰ä¸€æ­¥æ˜¯å°† document ä¿¡æ¯è½¬æ¢æˆå‘é‡ä¿¡æ¯å’Œembeddingsçš„ä¿¡æ¯å¹¶ä¸´æ—¶å­˜å…¥ Chroma æ•°æ®åº“ã€‚ å› ä¸ºæ˜¯ä¸´æ—¶å­˜å…¥ï¼Œæ‰€ä»¥å½“æˆ‘ä»¬ä¸Šé¢çš„ä»£ç æ‰§è¡Œå®Œæˆåï¼Œä¸Šé¢çš„å‘é‡åŒ–åçš„æ•°æ®å°†ä¼šä¸¢å¤±ã€‚å¦‚æœæƒ³ä¸‹æ¬¡ä½¿ç”¨ï¼Œé‚£ä¹ˆå°±è¿˜éœ€è¦å†è®¡ç®—ä¸€æ¬¡embeddingsï¼Œè¿™è‚¯å®šä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ã€‚ LangChain æ”¯æŒçš„æ•°æ®åº“æœ‰å¾ˆå¤šï¼Œè¿™ä¸ªæ¡ˆä¾‹ä»‹ç»ä¸‹é€šè¿‡ Chroma ä¸ªæ•°æ®åº“æ¥è®²ä¸€ä¸‹å¦‚ä½•åšå‘é‡æ•°æ®æŒä¹…åŒ–ã€‚ chroma æ˜¯ä¸ªæœ¬åœ°çš„å‘é‡æ•°æ®åº“ï¼Œä»–æä¾›çš„ä¸€ä¸ª persist_directory æ¥è®¾ç½®æŒä¹…åŒ–ç›®å½•è¿›è¡ŒæŒä¹…åŒ–ã€‚è¯»å–æ—¶ï¼Œåªéœ€è¦è°ƒå– from_document æ–¹æ³•åŠ è½½å³å¯ã€‚

```python
python
å¤åˆ¶ä»£ç from langchain.vectorstores import Chroma

# æŒä¹…åŒ–æ•°æ®
docsearch = Chroma.from_documents(documents, embeddings, persist_directory="D:/vector_store")
docsearch.persist()

# ä»å·²æœ‰æ–‡ä»¶ä¸­åŠ è½½æ•°æ®
docsearch = Chroma(persist_directory="D:/vector_store", embedding_function=embeddings)
```

## 3.6. åŸºäºLangChainæ„å»ºçš„å¼€æºåº”ç”¨

[åŸºäºLangChainçš„ä¼˜ç§€é¡¹ç›®èµ„æºåº“](https://link.juejin.cn?target=https%3A%2F%2Fblog.csdn.net%2Fqq_56591814%2Farticle%2Fdetails%2F131346819) [åŸºäºLangChainå’ŒChatGLM-6Bç­‰ç³»åˆ—LLMçš„é’ˆå¯¹æœ¬åœ°çŸ¥è¯†åº“çš„è‡ªåŠ¨é—®ç­”](https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2Fthomas-yanxin%2FLangChain-ChatGLM-Webui)

# 4. æ€»ç»“

éšç€LangChainä¸æ–­è¿­ä»£å’Œä¼˜åŒ–ï¼Œå®ƒçš„åŠŸèƒ½å°†å˜å¾—è¶Šæ¥è¶Šå¼ºå¤§ï¼Œæ”¯æŒçš„èŒƒå›´ä¹Ÿå°†æ›´å¹¿æ³›ã€‚æ— è®ºæ˜¯å¤„ç†å¤æ‚çš„è¯­è¨€æ¨¡å‹è¿˜æ˜¯è§£å†³å„ç§å®é™…é—®é¢˜ï¼ŒLangChainéƒ½å°†å±•ç°å‡ºæ›´é«˜çš„å®åŠ›å’Œçµæ´»æ€§ã€‚ç„¶è€Œï¼Œæˆ‘å¿…é¡»æ‰¿è®¤ï¼Œæˆ‘çš„ç†è§£èƒ½åŠ›å’Œè§£é‡Šèƒ½åŠ›æ˜¯æœ‰é™çš„ï¼Œå¯èƒ½ä¼šå‡ºç°é”™è¯¯æˆ–è€…è§£é‡Šä¸å¤Ÿæ¸…æ™°ã€‚å› æ­¤ï¼Œæ³è¯·è¯»è€…ä»¬è°…è§£ã€‚

# 5. å‚è€ƒæ–‡çŒ®

- [LangChain | ï¸ LangChain](https://link.juejin.cn?target=https%3A%2F%2Fpython.langchain.com%2F)
- [LangChain ä¸­æ–‡å…¥é—¨æ•™ç¨‹ - LangChain çš„ä¸­æ–‡å…¥é—¨æ•™ç¨‹](https://link.juejin.cn?target=https%3A%2F%2Fliaokong.gitbook.io%2Fllm-kai-fa-jiao-cheng%2F)

ä½œè€…ï¼šMoonWebTeam
é“¾æ¥ï¼šhttps://juejin.cn/post/7262010787228090426
æ¥æºï¼šç¨€åœŸæ˜é‡‘
è‘—ä½œæƒå½’ä½œè€…æ‰€æœ‰ã€‚å•†ä¸šè½¬è½½è¯·è”ç³»ä½œè€…è·å¾—æˆæƒï¼Œéå•†ä¸šè½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚