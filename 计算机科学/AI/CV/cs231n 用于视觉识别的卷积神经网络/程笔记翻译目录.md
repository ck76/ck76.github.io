[TOC]

知乎上[CS231n课程翻译系列](https://zhuanlan.zhihu.com/p/22339097) 翻译的笔记

### Python Numpy教程（[全篇](https://zhuanlan.zhihu.com/p/20878530?refer=intelligentunit)）

1. Python
   - 基本数据类型
   - 容器(列表, 字典, 集合, 元组)
   - 函数
   - 类
2. Numpy
   - 数组
   - 访问数组
   - 数据类型
   - 数组计算
   - 广播
3. SciPy
   - 图像操作
   - MATLAB文件
   - 点之间的距离
4. Matplotlib
   - 绘制图形
   - 绘制多个图形
   - 图像

### 图像分类笔记

1. 图像分类、数据驱动方法和流程（[上篇](https://zhuanlan.zhihu.com/p/20894041?refer=intelligentunit)）
2. Nearest Neighbor分类器
   - k-Nearest Neighbor
3. 验证集、交叉验证集和超参数调参（[下篇](https://zhuanlan.zhihu.com/p/20900216?refer=intelligentunit)）
4. Nearest Neighbor的优劣
5. 小结
6. 小结：应用kNN实践
7. 拓展阅读

### 线性分类笔记

1. 线性分类器简介（[上篇](https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit)）

2. 线性评分函数

3. 阐明线性分类器

4. 损失函数（[中篇](https://zhuanlan.zhihu.com/p/20945670)）

   - 多类SVM
- Softmax分类器（[下篇](https://zhuanlan.zhihu.com/p/21102293?refer=intelligentunit)）
   - SVM和Softmax的比较

5. 基于Web的可交互线性分类器原型

6. 小结

### 最优化笔记

1. 简介（[上篇](https://zhuanlan.zhihu.com/p/21360434?refer=intelligentunit)）

2. 损失函数可视化

3. 最优化

   - 策略#1：随机搜索
   - 策略#2：随机局部搜索
   - 策略#3：跟随梯度

4. 梯度计算（

   下篇

   ）

   - 使用有限差值进行数值计算
   - 微分计算梯度

5. 梯度下降

6. 小结

### 反向传播笔记 （[全篇](https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit)）

1. 简介
2. 简单表达式和理解梯度
3. 复合表达式，链式法则，反向传播
4. 直观理解反向传播
5. 模块：Sigmoid例子
6. 反向传播实践：分段计算
7. 回传流中的模式
8. 用户向量化操作的梯度
9. 小结

### 神经网络笔记1

1. 不用大脑做类比的快速简介（[上篇](https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit)）

2. 单个神经元建模

   - 生物动机和连接
   - 作为线性分类器的单个神经元
   - 常用的激活函数

3. 神经网络结构（[下篇](https://zhuanlan.zhihu.com/p/21513367?refer=intelligentunit)）

   - 层组织
- 前向传播计算例子
   - 表达能力
- 设置层的数量和尺寸
  
4. 小节

5. 参考文献

### 神经网络笔记2（[全篇](https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit)）

1. 设置数据和模型
   - 数据预处理
   - 权重初始化
   - 批量归一化（Batch Normalization）
   - 正则化（L2/L1/Maxnorm/Dropout）
2. 损失函数
3. 小结

### 神经网络笔记3

1. 梯度检查（[上篇](https://zhuanlan.zhihu.com/p/21741716?refer=intelligentunit)）
2. 合理性（Sanity）检查
3. 检查学习过程

   1. 损失函数
   2. 训练集与验证集准确率
   3. 权重：更新比例
   4. 每层的激活数据与梯度分布
   5. 可视化
4. 参数更新（[下篇](https://zhuanlan.zhihu.com/p/21798784?refer=intelligentunit)）

   1. 一阶（随机梯度下降）方法，动量方法，Nesterov动量方法
   2. 学习率退火
   3. 二阶方法
   4. 逐参数适应学习率方法（Adagrad，RMSProp）
5. 超参数调优
6. 评价
   1. 模型集成
7. 总结
8. 拓展引用

### 卷积神经网络笔记 （[全篇](https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit)）

1. 构概述
2. 用来构建卷积神经网络的各种层
   - 卷积层
   - 汇聚层
   - 归一化层
   - 全连接层
   - 将全连接层转化成卷积层
3. 卷积神经网络的结构
   - 层的排列规律
   - 层的尺寸设置规律
   - 案例学习（LeNet / AlexNet / ZFNet / GoogLeNet / VGGNet）
   - 计算上的考量
4. 拓展资源